{
  "filename": "expansion-reduction.md",
  "__html": "<h1>DolphinScheduler扩容/缩容 文档</h1>\n<h2>1. DolphinScheduler扩容文档</h2>\n<p>本文扩容是针对现有的DolphinScheduler集群添加新的master或者worker节点的操作说明.</p>\n<pre><code> 注意： 一台物理机上不能存在多个master服务进程或者worker服务进程.\n       如果扩容master或者worker节点所在的物理机已经安装了调度的服务,请直接跳到 [1.4.修改配置]. 编辑 ** 所有 ** 节点上的配置文件 `conf/config/install_config.conf`. 新增masters或者workers参数,重启调度集群即可.\n</code></pre>\n<h3>1.1. 基础软件安装(必装项请自行安装)</h3>\n<ul>\n<li>[必装] <a href=\"https://www.oracle.com/technetwork/java/javase/downloads/index.html\">JDK</a> (1.8+) :  必装，请安装好后在/etc/profile下配置 JAVA_HOME 及 PATH 变量</li>\n<li>[可选] 如果扩容的是worker类型的节点,需要考虑是否要安装外部客户端,比如Hadoop、Hive、Spark 的Client.</li>\n</ul>\n<pre><code class=\"language-markdown\"> 注意：DolphinScheduler本身不依赖Hadoop、Hive、Spark,仅是会调用他们的Client，用于对应任务的提交。\n</code></pre>\n<h3>1.2. 获取安装包</h3>\n<ul>\n<li>确认现有环境使用的DolphinScheduler是哪个版本,获取对应版本的安装包,如果版本不同,可能存在兼容性的问题.</li>\n<li>确认其他节点的统一安装目录,本文假设DolphinScheduler统一安装在 /opt/ 目录中,安装全路径为/opt/dolphinscheduler.</li>\n<li>请下载对应版本的安装包至服务器安装目录,解压并重名为dolphinscheduler存放在/opt目录中.</li>\n<li>添加数据库依赖包,本文使用Mysql数据库,添加mysql-connector-java驱动包到/opt/dolphinscheduler/lib目录中</li>\n</ul>\n<pre><code class=\"language-shell\"><span class=\"hljs-meta\">#</span><span class=\"bash\"> 创建安装目录,安装目录请不要创建在/root、/home等高权限目录</span> \nmkdir -p /opt\ncd /opt\n<span class=\"hljs-meta\">#</span><span class=\"bash\"> 解压缩</span>\ntar -zxvf apache-dolphinscheduler-incubating-1.3.3-dolphinscheduler-bin.tar.gz -C /opt \ncd /opt\nmv apache-dolphinscheduler-incubating-1.3.3-dolphinscheduler-bin  dolphinscheduler\n</code></pre>\n<pre><code class=\"language-markdown\"> 注意：安装包可以从现有的环境直接复制到扩容的物理机上使用.\n</code></pre>\n<h3>1.3. 创建部署用户</h3>\n<ul>\n<li>在<strong>所有</strong>扩容的机器上创建部署用户，并且一定要配置sudo免密。假如我们计划在ds1,ds2,ds3,ds4这四台扩容机器上部署调度，首先需要在每台机器上都创建部署用户</li>\n</ul>\n<pre><code class=\"language-shell\"><span class=\"hljs-meta\">#</span><span class=\"bash\"> 创建用户需使用root登录，设置部署用户名，请自行修改，后面以dolphinscheduler为例</span>\nuseradd dolphinscheduler;\n<span class=\"hljs-meta\">\n#</span><span class=\"bash\"> 设置用户密码，请自行修改，后面以dolphinscheduler123为例</span>\necho &quot;dolphinscheduler123&quot; | passwd --stdin dolphinscheduler\n<span class=\"hljs-meta\">\n#</span><span class=\"bash\"> 配置sudo免密</span>\necho &#x27;dolphinscheduler  ALL=(ALL)  NOPASSWD: NOPASSWD: ALL&#x27; &gt;&gt; /etc/sudoers\nsed -i &#x27;s/Defaults    requirett/#Defaults    requirett/g&#x27; /etc/sudoers\n\n</code></pre>\n<pre><code class=\"language-markdown\"> 注意：\n<span class=\"hljs-bullet\"> -</span> 因为是以 sudo -u {linux-user} 切换不同linux用户的方式来实现多租户运行作业，所以部署用户需要有 sudo 权限，而且是免密的。\n<span class=\"hljs-bullet\"> -</span> 如果发现/etc/sudoers文件中有&quot;Default requiretty&quot;这行，也请注释掉\n<span class=\"hljs-bullet\"> -</span> 如果用到资源上传的话，还需要在<span class=\"hljs-code\">`HDFS或者MinIO`</span>上给该部署用户分配读写的权限\n</code></pre>\n<h3>1.4. 修改配置</h3>\n<ul>\n<li>\n<p>从现有的节点比如Master/Worker节点,直接拷贝conf目录替换掉新增节点中的conf目录.拷贝之后检查一下配置项是否正确.</p>\n<pre><code class=\"language-markdown\">重点检查:\ndatasource.properties 中的数据库连接信息. \nzookeeper.properties 中的连接zk的信息.\ncommon.properties 中关于资源存储的配置信息(如果设置了hadoop,请检查是否存在core-site.xml和hdfs-site.xml配置文件).\nenv/dolphinscheduler<span class=\"hljs-emphasis\">_env.sh 中的环境变量\n</span></code></pre>\n</li>\n<li>\n<p>根据机器配置,修改 conf/env 目录下的 <code>dolphinscheduler_env.sh</code> 环境变量(以相关用到的软件都安装在/opt/soft下为例)</p>\n<pre><code class=\"language-shell\">    export HADOOP_HOME=/opt/soft/hadoop\n    export HADOOP_CONF_DIR=/opt/soft/hadoop/etc/hadoop\n    #export SPARK_HOME1=/opt/soft/spark1\n    export SPARK_HOME2=/opt/soft/spark2\n    export PYTHON_HOME=/opt/soft/python\n    export JAVA_HOME=/opt/soft/java\n    export HIVE_HOME=/opt/soft/hive\n    export FLINK_HOME=/opt/soft/flink\n    export DATAX_HOME=/opt/soft/datax/bin/datax.py\n    export PATH=$HADOOP_HOME/bin:$SPARK_HOME2/bin:$PYTHON_HOME:$JAVA_HOME/bin:$HIVE_HOME/bin:$PATH:$FLINK_HOME/bin:$DATAX_HOME:$PATH\n\n    ```\n\n `注: 这一步非常重要,例如 JAVA_HOME 和 PATH 是必须要配置的，没有用到的可以忽略或者注释掉`\n\n\n</code></pre>\n</li>\n<li>\n<p>将jdk软链到/usr/bin/java下(仍以 JAVA_HOME=/opt/soft/java 为例)</p>\n<pre><code class=\"language-shell\">sudo ln -s /opt/soft/java/bin/java /usr/bin/java\n</code></pre>\n</li>\n<li>\n<p>修改 <strong>所有</strong> 节点上的配置文件 <code>conf/config/install_config.conf</code>, 同步修改以下配置.</p>\n<ul>\n<li>新增的master节点, 需要修改 ips 和 masters 参数.</li>\n<li>新增的worker节点, 需要修改 ips 和  workers 参数.</li>\n</ul>\n</li>\n</ul>\n<pre><code class=\"language-shell\"><span class=\"hljs-meta\">#</span><span class=\"bash\">在哪些机器上新增部署DS服务,多个物理机之间用逗号隔开.</span>\nips=&quot;ds1,ds2,ds3,ds4&quot;\n<span class=\"hljs-meta\">\n#</span><span class=\"bash\">ssh端口,默认22</span>\nsshPort=&quot;22&quot;\n<span class=\"hljs-meta\">\n#</span><span class=\"bash\">master服务部署在哪台机器上</span>\nmasters=&quot;现有master01,现有master02,ds1,ds2&quot;\n<span class=\"hljs-meta\">\n#</span><span class=\"bash\">worker服务部署在哪台机器上,并指定此worker属于哪一个worker组,下面示例的default即为组名</span>\nworkers=&quot;现有worker01:default,现有worker02:default,ds3:default,ds4:default&quot;\n\n</code></pre>\n<ul>\n<li>\n<p>如果扩容的是worker节点,需要设置worker分组.请参考用户手册<a href=\"./system-manual.md\">5.7 创建worker分组 </a></p>\n</li>\n<li>\n<p>在所有的新增节点上，修改目录权限，使得部署用户对dolphinscheduler目录有操作权限</p>\n</li>\n</ul>\n<pre><code class=\"language-shell\">sudo chown -R dolphinscheduler:dolphinscheduler dolphinscheduler\n</code></pre>\n<h3>1.4. 重启集群&amp;验证</h3>\n<ul>\n<li>重启集群</li>\n</ul>\n<pre><code class=\"language-shell\">停止命令:\nbin/stop-all.sh 停止所有服务\n\nsh bin/dolphinscheduler-daemon.sh stop master-server  停止 master 服务\nsh bin/dolphinscheduler-daemon.sh stop worker-server  停止 worker 服务\nsh bin/dolphinscheduler-daemon.sh stop logger-server  停止 logger  服务\nsh bin/dolphinscheduler-daemon.sh stop api-server     停止 api    服务\nsh bin/dolphinscheduler-daemon.sh stop alert-server   停止 alert  服务\n\n\n启动命令:\nbin/start-all.sh 启动所有服务\n\nsh bin/dolphinscheduler-daemon.sh start master-server  启动 master 服务\nsh bin/dolphinscheduler-daemon.sh start worker-server  启动 worker 服务\nsh bin/dolphinscheduler-daemon.sh start logger-server  启动 logger  服务\nsh bin/dolphinscheduler-daemon.sh start api-server     启动 api    服务\nsh bin/dolphinscheduler-daemon.sh start alert-server   启动 alert  服务\n\n</code></pre>\n<pre><code> 注意： 使用stop-all.sh或者stop-all.sh的时候,如果执行该命令的物理机没有配置到所有机器的ssh免登陆的话,会提示输入密码\n</code></pre>\n<ul>\n<li>脚本完成后，使用<code>jps</code>命令查看各个节点服务是否启动(<code>jps</code>为<code>java JDK</code>自带)</li>\n</ul>\n<pre><code>    MasterServer         ----- master服务\n    WorkerServer         ----- worker服务\n    LoggerServer         ----- logger服务\n    ApiApplicationServer ----- api服务\n    AlertServer          ----- alert服务\n</code></pre>\n<p>启动成功后，可以进行日志查看，日志统一存放于logs文件夹内</p>\n<pre><code class=\"language-日志路径\"> logs/\n    ├── dolphinscheduler-alert-server.log\n    ├── dolphinscheduler-master-server.log\n    |—— dolphinscheduler-worker-server.log\n    |—— dolphinscheduler-api-server.log\n    |—— dolphinscheduler-logger-server.log\n</code></pre>\n<p>如果以上服务都正常启动且调度系统页面正常,在web系统的[监控中心]查看是否有扩容的Master或者Worker服务.如果存在,则扩容完成</p>\n<hr>\n<h2>2. 缩容</h2>\n<p>缩容是针对现有的DolphinScheduler集群减少master或者worker服务,\n缩容一共分两个步骤,执行完以下两步,即可完成缩容操作.</p>\n<h3>2.1 停止缩容节点上的服务</h3>\n<ul>\n<li>如果缩容master节点,要确定要缩容master服务所在的物理机,并在物理机上停止该master服务.</li>\n<li>如果缩容worker节点,要确定要缩容worker服务所在的物理机,并在物理机上停止worker和logger服务.</li>\n</ul>\n<pre><code class=\"language-shell\">停止命令:\nbin/stop-all.sh 停止所有服务\n\nsh bin/dolphinscheduler-daemon.sh stop master-server  停止 master 服务\nsh bin/dolphinscheduler-daemon.sh stop worker-server  停止 worker 服务\nsh bin/dolphinscheduler-daemon.sh stop logger-server  停止 logger  服务\nsh bin/dolphinscheduler-daemon.sh stop api-server     停止 api    服务\nsh bin/dolphinscheduler-daemon.sh stop alert-server   停止 alert  服务\n\n\n启动命令:\nbin/start-all.sh 启动所有服务\n\nsh bin/dolphinscheduler-daemon.sh start master-server  启动 master 服务\nsh bin/dolphinscheduler-daemon.sh start worker-server  启动 worker 服务\nsh bin/dolphinscheduler-daemon.sh start logger-server  启动 logger  服务\nsh bin/dolphinscheduler-daemon.sh start api-server     启动 api    服务\nsh bin/dolphinscheduler-daemon.sh start alert-server   启动 alert  服务\n\n</code></pre>\n<pre><code> 注意： 使用stop-all.sh或者stop-all.sh的时候,如果没有执行该命令的机器没有配置到所有机器的ssh免登陆的话,会提示输入密码\n</code></pre>\n<ul>\n<li>脚本完成后，使用<code>jps</code>命令查看各个节点服务是否成功关闭(<code>jps</code>为<code>java JDK</code>自带)</li>\n</ul>\n<pre><code>    MasterServer         ----- master服务\n    WorkerServer         ----- worker服务\n    LoggerServer         ----- logger服务\n    ApiApplicationServer ----- api服务\n    AlertServer          ----- alert服务\n</code></pre>\n<p>如果对应的master服务或者worker服务不存在,则代表master/worker服务成功关闭.</p>\n<h3>2.2 修改配置文件</h3>\n<ul>\n<li>\n<p>修改 <strong>所有</strong> 节点上的配置文件 <code>conf/config/install_config.conf</code>, 同步修改以下配置.</p>\n<ul>\n<li>缩容master节点, 需要修改 ips 和 masters 参数.</li>\n<li>缩容worker节点, 需要修改 ips 和  workers 参数.</li>\n</ul>\n</li>\n</ul>\n<pre><code class=\"language-shell\"><span class=\"hljs-meta\">#</span><span class=\"bash\">在哪些机器上部署DS服务，本机选localhost</span>\nips=&quot;ds1,ds2,ds3,ds4&quot;\n<span class=\"hljs-meta\">\n#</span><span class=\"bash\">ssh端口,默认22</span>\nsshPort=&quot;22&quot;\n<span class=\"hljs-meta\">\n#</span><span class=\"bash\">master服务部署在哪台机器上</span>\nmasters=&quot;现有master01,现有master02,ds1,ds2&quot;\n<span class=\"hljs-meta\">\n#</span><span class=\"bash\">worker服务部署在哪台机器上,并指定此worker属于哪一个worker组,下面示例的default即为组名</span>\nworkers=&quot;现有worker01:default,现有worker02:default,ds3:default,ds4:default&quot;\n\n</code></pre>\n",
  "link": "/dist/zh-cn/docs/1.3.3/user_doc/expansion-reduction.html",
  "meta": {}
}