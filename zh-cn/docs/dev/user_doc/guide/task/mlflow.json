{
  "filename": "mlflow.md",
  "__html": "<h1>MLflow节点</h1>\n<h2>综述</h2>\n<p><a href=\"https://mlflow.org\">MLflow</a> 是一个MLops领域一个优秀的开源项目， 用于管理机器学习的生命周期，包括实验、可再现性、部署和中心模型注册。</p>\n<p>MLflow 组件用于执行 MLflow 任务，目前包含Mlflow Projects, 和MLflow Models。（Model Registry将在不就的将来支持）。</p>\n<ul>\n<li>MLflow Projects: 将代码打包，并可以运行到任务的平台上。</li>\n<li>MLflow Models: 在不同的服务环境中部署机器学习模型。</li>\n<li>Model Registry: 在一个中央存储库中存储、注释、发现和管理模型 (你也可以在你的MLflow project 里面自行注册模型)。</li>\n</ul>\n<p>目前 Mlflow 组件支持的和即将支持的内容如下中：</p>\n<ul>\n<li>[x] MLflow Projects\n<ul>\n<li>[x] BasicAlgorithm: 基础算法，包含LogisticRegression, svm, lightgbm, xgboost</li>\n<li>[x] AutoML: AutoML工具，包含autosklean, flaml</li>\n<li>[x] Custom projects: 支持运行自己的MLflow Projects项目</li>\n</ul>\n</li>\n<li>[ ] MLflow Models\n<ul>\n<li>[x] MLFLOW: 直接使用 <code>mlflow models serve</code> 部署模型。</li>\n<li>[x] Docker: 打包 DOCKER 镜像后部署模型。</li>\n<li>[x] Docker Compose: 使用Docker Compose 部署模型，将会取代上面的Docker部署。</li>\n<li>[ ] Seldon core: 构建完镜像后，使用Seldon Core 部署到k8s集群上, 可以使用Seldon Core的生成模型管理能力。</li>\n<li>[ ] k8s: 构建完镜像后， 部署到k8s集群上。</li>\n<li>[ ] MLflow deployments: 内置的允许MLflow 部署模块, 如内置的部署到Sagemaker等。</li>\n</ul>\n</li>\n<li>[ ] Model Registry\n<ul>\n<li>[ ] Register Model: 注册相关工件(模型以及相关的参数，指标)到模型中心</li>\n</ul>\n</li>\n</ul>\n<h2>创建任务</h2>\n<ul>\n<li>点击项目管理-项目名称-工作流定义，点击“创建工作流”按钮，进入 DAG 编辑页面；</li>\n<li>拖动工具栏的 <img src=\"/img/tasks/icons/mlflow.png\" width=\"15\"/> 任务节点到画板中。</li>\n</ul>\n<h2>任务样例</h2>\n<p>首先介绍一些DS通用参数</p>\n<ul>\n<li><strong>节点名称</strong> ：设置任务的名称。一个工作流定义中的节点名称是唯一的。</li>\n<li><strong>运行标志</strong> ：标识这个节点是否能正常调度,如果不需要执行，可以打开禁止执行开关。</li>\n<li><strong>描述</strong> ：描述该节点的功能。</li>\n<li><strong>任务优先级</strong> ：worker 线程数不足时，根据优先级从高到低依次执行，优先级一样时根据先进先出原则执行。</li>\n<li><strong>Worker 分组</strong> ：任务分配给 worker 组的机器执行，选择 Default，会随机选择一台 worker 机执行。</li>\n<li><strong>环境名称</strong> ：配置运行脚本的环境。</li>\n<li><strong>失败重试次数</strong> ：任务失败重新提交的次数。</li>\n<li><strong>失败重试间隔</strong> ：任务失败重新提交任务的时间间隔，以分钟为单位。</li>\n<li><strong>延迟执行时间</strong> ：任务延迟执行的时间，以分钟为单位。</li>\n<li><strong>超时告警</strong> ：勾选超时告警、超时失败，当任务超过&quot;超时时长&quot;后，会发送告警邮件并且任务执行失败。</li>\n<li><strong>前置任务</strong> ：选择当前任务的前置任务，会将被选择的前置任务设置为当前任务的上游。</li>\n</ul>\n<p>以下是一些MLflow 组件的常用参数</p>\n<ul>\n<li><strong>MLflow Tracking Server URI</strong> ：MLflow Tracking Server 的连接, 默认 <a href=\"http://localhost:5000\">http://localhost:5000</a>。</li>\n<li><strong>实验名称</strong> ：任务运行时所在的实验，若实验不存在，则创建。若实验名称为空，则设置为<code>Default</code>, 与 MLflow 一样。</li>\n</ul>\n<h3>MLflow Projects</h3>\n<h4>BasicAlgorithm</h4>\n<p><img src=\"/img/tasks/demo/mlflow-basic-algorithm.png\" alt=\"mlflow-conda-env\"></p>\n<p><strong>任务参数</strong></p>\n<ul>\n<li><strong>注册模型</strong> ：是否注册模型，若选择注册，则会展开以下参数。\n<ul>\n<li><strong>注册的模型名称</strong> : 注册的模型名称，会在原来的基础上加上一个模型版本，并注册为Production。</li>\n</ul>\n</li>\n<li><strong>数据路径</strong> : 文件/文件夹的绝对路径, 若文件需以.csv结尾（自动切分训练集与测试集）, 文件夹需包含train.csv和test.csv（建议方式，用户应自行构建测试集用于模型评估）。\n详细的参数列表如下:\n<ul>\n<li><a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression\">LogisticRegression</a></li>\n<li><a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html?highlight=svc#sklearn.svm.SVC\">SVM</a></li>\n<li><a href=\"https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMClassifier.html#lightgbm.LGBMClassifier\">lightgbm</a></li>\n<li><a href=\"https://xgboost.readthedocs.io/en/stable/python/python_api.html#xgboost.XGBClassifier\">xgboost</a></li>\n</ul>\n</li>\n<li><strong>算法</strong> ：选择的算法，目前基于 <a href=\"https://scikit-learn.org/\">scikit-learn</a> 形式支持 <code>lr</code>, <code>svm</code>, <code>lightgbm</code>, <code>xgboost</code>。</li>\n<li><strong>参数搜索空间</strong> : 运行对应算法的参数搜索空间, 可为空。如针对lightgbm 的 <code>max_depth=[5, 10];n_estimators=[100, 200]</code> 则会进行对应搜索。约定传入后会以;切分各个参数，等号前的名字作为参数名，等号后的名字将以python eval执行得到对应的参数值</li>\n</ul>\n<h4>AutoML</h4>\n<p><img src=\"/img/tasks/demo/mlflow-automl.png\" alt=\"mlflow-automl\"></p>\n<p><strong>任务参数</strong></p>\n<ul>\n<li><strong>注册模型</strong> ：是否注册模型，若选择注册，则会展开以下参数。\n<ul>\n<li><strong>注册的模型名称</strong> : 注册的模型名称，会在原来的基础上加上一个模型版本，并注册为Production。</li>\n</ul>\n</li>\n<li><strong>数据路径</strong> : 文件/文件夹的绝对路径, 若文件需以.csv结尾（自动切分训练集与测试集）, 文件夹需包含train.csv和test.csv（建议方式，用户应自行构建测试集用于模型评估）。</li>\n<li><strong>参数</strong> : 初始化AutoML训练器时的参数，可为空, 如针对 flaml 设置<code>time_budget=30;estimator_list=['lgbm']</code>。约定传入后会以; 切分各个参数，等号前的名字作为参数名，等号后的名字将以python eval执行得到对应的参数值。详细的参数列表如下:\n<ul>\n<li><a href=\"https://microsoft.github.io/FLAML/docs/reference/automl#automl-objects\">flaml</a></li>\n<li><a href=\"https://automl.github.io/auto-sklearn/master/api.html\">autosklearn</a></li>\n</ul>\n</li>\n<li><strong>AutoML工具</strong> : 使用的AutoML工具，目前支持 <a href=\"https://github.com/automl/auto-sklearn\">autosklearn</a>\n, <a href=\"https://github.com/microsoft/FLAML\">flaml</a>。</li>\n</ul>\n<h4>Custom projects</h4>\n<p><img src=\"/img/tasks/demo/mlflow-custom-project.png\" alt=\"mlflow-custom-project.png\"></p>\n<p><strong>任务参数</strong></p>\n<ul>\n<li><strong>参数</strong> : <code>mlflow run</code>中的 --param-list 如 <code>-P learning_rate=0.2 -P colsample_bytree=0.8 -P subsample=0.9</code></li>\n<li><strong>运行仓库</strong> : MLflow Project的仓库地址，可以为github地址，或者worker上的目录, 如MLflow project位于子目录，可以添加 <code>#</code> 隔开, 如 <code>https://github.com/mlflow/mlflow#examples/xgboost/xgboost_native</code></li>\n<li><strong>项目版本</strong> : 对应项目中git版本管理中的版本，默认 master</li>\n</ul>\n<p>现在你可以使用这个功能来运行github上所有的MLflow Projects (如 <a href=\"https://github.com/mlflow/mlflow/tree/master/examples\">MLflow examples</a> )了。你也可以创建自己的机器学习库，用来复用你的研究成果，以后你就可以使用DolphinScheduler来一键操作使用你的算法库。</p>\n<h3>MLflow Models</h3>\n<p>常用参数:</p>\n<ul>\n<li><strong>部署模型的URI</strong> ：MLflow 服务里面模型对应的URI, 支持 <code>models:/&lt;model_name&gt;/suffix</code> 格式 和 <code>runs:/</code> 格式。</li>\n<li><strong>监听端口</strong> ：部署服务时的端口。</li>\n</ul>\n<h4>MLFLOW</h4>\n<p><img src=\"/img/tasks/demo/mlflow-models-mlflow.png\" alt=\"mlflow-models-mlflow\"></p>\n<h4>Docker</h4>\n<p><img src=\"/img/tasks/demo/mlflow-models-docker.png\" alt=\"mlflow-models-docker\"></p>\n<h4>DOCKER COMPOSE</h4>\n<p><img src=\"/img/tasks/demo/mlflow-models-docker-compose.png\" alt=\"mlflow-models-docker-compose\"></p>\n<ul>\n<li><strong>最大CPU限制</strong> ：如 <code>1.0</code> 或者 <code>0.5</code>, 与 docker compose 一致。</li>\n<li><strong>最大内存限制</strong> ：如 <code>1G</code> 或者 <code>500M</code>, 与 docker compose 一致。</li>\n</ul>\n<h2>环境准备</h2>\n<h3>conda 环境配置</h3>\n<p>你需要进入admin账户配置一个conda环境变量（请提前<a href=\"https://docs.continuum.io/anaconda/install/\">安装anaconda</a>\n或者<a href=\"https://docs.conda.io/en/latest/miniconda.html#installing\">安装miniconda</a> )。</p>\n<p><img src=\"/img/tasks/demo/mlflow-conda-env.png\" alt=\"mlflow-conda-env\"></p>\n<p>后续注意配置任务时，环境选择上面创建的conda环境，否则程序会找不到conda环境。</p>\n<p><img src=\"/img/tasks/demo/mlflow-set-conda-env.png\" alt=\"mlflow-set-conda-env\"></p>\n<h3>MLflow service 启动</h3>\n<p>确保你已经安装MLflow，可以使用<code>pip install mlflow</code>进行安装。</p>\n<p>在你想保存实验和模型的地方建立一个文件夹，然后启动 mlflow service。</p>\n<pre><code class=\"language-sh\">mkdir mlflow\n<span class=\"hljs-built_in\">cd</span> mlflow\nmlflow server -h 0.0.0.0 -p 5000 --serve-artifacts --backend-store-uri sqlite:///mlflow.db\n</code></pre>\n<p>运行后会启动一个MLflow服务。</p>\n<p>可以通过访问 MLflow service (<code>http://localhost:5000</code>) 页面查看实验与模型。</p>\n<p><img src=\"/img/tasks/demo/mlflow-server.png\" alt=\"mlflow-server\"></p>\n",
  "link": "/dist/zh-cn/docs/dev/user_doc/guide/task/mlflow.html",
  "meta": {}
}