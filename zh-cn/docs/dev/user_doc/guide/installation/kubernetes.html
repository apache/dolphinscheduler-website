<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
  <meta name="keywords" content="kubernetes">
  <meta name="description" content="kubernetes">
  <title>kubernetes</title>
  <link rel="shortcut icon" href="/img/favicon.ico">
  <link rel="stylesheet" href="/build/vendor.eeae4ed.css">
</head>
<body>
  <div id="root"><div class="md2html docs-page" data-reactroot=""><header class="header-container header-container-dark"><div class="banner-tips"><div>ğŸ¤” æœ‰å…³äº Apache DolphinScheduler çš„ç–‘é—®ï¼ŒåŠ å…¥ Slack é¢‘é“æ¥è®¨è®ºä»–ä»¬ <a class="link-tips" href="https://s.apache.org/dolphinscheduler-slack">join #dolphinscheduler channel</a>! ğŸŒŸ</div></div><div class="header-body"><span class="mobile-menu-btn mobile-menu-btn-dark"></span><a href="/zh-cn/index.html"><img class="logo" src="/img/hlogo_white.svg"/></a><div class="search search-dark"><span class="icon-search"></span></div><span class="language-switch language-switch-dark">En</span><div class="header-menu"><div><ul class="ant-menu whiteClass ant-menu-light ant-menu-root ant-menu-horizontal" role="menu"><li class="ant-menu-submenu ant-menu-submenu-horizontal ant-menu-overflowed-submenu" style="display:none" role="menuitem"><div class="ant-menu-submenu-title" aria-expanded="false" aria-haspopup="true"><span>Â·Â·Â·</span><i class="ant-menu-submenu-arrow"></i></div></li><li class="ant-menu-item" role="menuitem"><a href="/zh-cn/index.html" target="_self">é¦–é¡µ</a></li><li class="ant-menu-submenu ant-menu-submenu-horizontal ant-menu-overflowed-submenu" style="display:none" role="menuitem"><div class="ant-menu-submenu-title" aria-expanded="false" aria-haspopup="true"><span>Â·Â·Â·</span><i class="ant-menu-submenu-arrow"></i></div></li><li class="ant-menu-submenu ant-menu-submenu-horizontal ant-menu-item-selected" role="menuitem"><div class="ant-menu-submenu-title" aria-expanded="false" aria-haspopup="true"><span class="submenu-title-wrapper"><a href="/zh-cn/docs/latest/user_doc/about/introduction.html" target="_self">æ–‡æ¡£</a></span><i class="ant-menu-submenu-arrow"></i></div></li><li class="ant-menu-submenu ant-menu-submenu-horizontal ant-menu-overflowed-submenu" style="display:none" role="menuitem"><div class="ant-menu-submenu-title" aria-expanded="false" aria-haspopup="true"><span>Â·Â·Â·</span><i class="ant-menu-submenu-arrow"></i></div></li><li class="ant-menu-item" role="menuitem"><a href="/zh-cn/download/download.html" target="_self">ä¸‹è½½</a></li><li class="ant-menu-submenu ant-menu-submenu-horizontal ant-menu-overflowed-submenu" style="display:none" role="menuitem"><div class="ant-menu-submenu-title" aria-expanded="false" aria-haspopup="true"><span>Â·Â·Â·</span><i class="ant-menu-submenu-arrow"></i></div></li><li class="ant-menu-item" role="menuitem"><a href="/zh-cn/blog/index.html" target="_self">åšå®¢</a></li><li class="ant-menu-submenu ant-menu-submenu-horizontal ant-menu-overflowed-submenu" style="display:none" role="menuitem"><div class="ant-menu-submenu-title" aria-expanded="false" aria-haspopup="true"><span>Â·Â·Â·</span><i class="ant-menu-submenu-arrow"></i></div></li><li class="ant-menu-item" role="menuitem"><a href="/zh-cn/development/development-environment-setup.html" target="_self">å¼€å‘è€…</a></li><li class="ant-menu-submenu ant-menu-submenu-horizontal ant-menu-overflowed-submenu" style="display:none" role="menuitem"><div class="ant-menu-submenu-title" aria-expanded="false" aria-haspopup="true"><span>Â·Â·Â·</span><i class="ant-menu-submenu-arrow"></i></div></li><li class="ant-menu-item" role="menuitem"><a href="/zh-cn/community/team.html" target="_self">ç¤¾åŒº</a></li><li class="ant-menu-submenu ant-menu-submenu-horizontal ant-menu-overflowed-submenu" style="display:none" role="menuitem"><div class="ant-menu-submenu-title" aria-expanded="false" aria-haspopup="true"><span>Â·Â·Â·</span><i class="ant-menu-submenu-arrow"></i></div></li><li class="ant-menu-submenu ant-menu-submenu-horizontal" role="menuitem"><div class="ant-menu-submenu-title" aria-expanded="false" aria-haspopup="true"><span class="submenu-title-wrapper"><a href="https://www.apache.org/" target="_blank">ASF</a></span><i class="ant-menu-submenu-arrow"></i></div></li><li class="ant-menu-submenu ant-menu-submenu-horizontal ant-menu-overflowed-submenu" style="display:none" role="menuitem"><div class="ant-menu-submenu-title" aria-expanded="false" aria-haspopup="true"><span>Â·Â·Â·</span><i class="ant-menu-submenu-arrow"></i></div></li><li class="ant-menu-item" role="menuitem"><a href="/zh-cn/user/index.html" target="_self">ç”¨æˆ·</a></li><li class="ant-menu-submenu ant-menu-submenu-horizontal ant-menu-overflowed-submenu" style="visibility:hidden;position:absolute" role="menuitem"><div class="ant-menu-submenu-title" aria-expanded="false" aria-haspopup="true"><span>Â·Â·Â·</span><i class="ant-menu-submenu-arrow"></i></div></li></ul></div></div><div class="mobile-menu"><div class="mobile-menu-content"><div class="mobile-menu-list"><div class="mobile-menu-item"><a class="mobile-menu-title" href="/zh-cn/index.html" target="_self">é¦–é¡µ</a></div><div class="mobile-menu-item"><a class="mobile-menu-title" href="/zh-cn/docs/latest/user_doc/about/introduction.html" target="_self">æ–‡æ¡£</a><em class="mobile-menu-icon"></em><div class="mobile-sub-menus"><div class="mobile-sub-menu-item"><a href="/zh-cn/docs/latest/user_doc/about/introduction.html" target="_self">æœ€æ–°ç‰ˆæœ¬latest(3.0.0-beta-2)</a></div><div class="mobile-sub-menu-item"><a href="/zh-cn/docs/1.3.9/user_doc/quick-start.html" target="_self">1.3.9</a></div><div class="mobile-sub-menu-item"><a href="/zh-cn/docs/release/history-versions.html" target="_self">å†å²ç‰ˆæœ¬</a></div></div></div><div class="mobile-menu-item"><a class="mobile-menu-title" href="/zh-cn/download/download.html" target="_self">ä¸‹è½½</a></div><div class="mobile-menu-item"><a class="mobile-menu-title" href="/zh-cn/blog/index.html" target="_self">åšå®¢</a></div><div class="mobile-menu-item"><a class="mobile-menu-title" href="/zh-cn/development/development-environment-setup.html" target="_self">å¼€å‘è€…</a></div><div class="mobile-menu-item"><a class="mobile-menu-title" href="/zh-cn/community/team.html" target="_self">ç¤¾åŒº</a></div><div class="mobile-menu-item"><a class="mobile-menu-title" href="https://www.apache.org/" target="_blank">ASF</a><em class="mobile-menu-icon"></em><div class="mobile-sub-menus"><div class="mobile-sub-menu-item"><a href="https://www.apache.org/" target="_blank">Foundation</a></div><div class="mobile-sub-menu-item"><a href="https://www.apache.org/licenses/" target="_blank">License</a></div><div class="mobile-sub-menu-item"><a href="https://www.apache.org/events/current-event" target="_blank">Events</a></div><div class="mobile-sub-menu-item"><a href="https://www.apache.org/security/" target="_blank">Security</a></div><div class="mobile-sub-menu-item"><a href="https://www.apache.org/foundation/sponsorship.html" target="_blank">Sponsorship</a></div><div class="mobile-sub-menu-item"><a href="https://www.apache.org/foundation/thanks.html" target="_blank">Thanks</a></div></div></div><div class="mobile-menu-item"><a class="mobile-menu-title" href="/zh-cn/user/index.html" target="_self">ç”¨æˆ·</a></div></div></div><div class="mobile-menu-dummy"></div></div></div></header><section class="content-section"><div class="sidemenu"><div class="sidemenu-toggle"><img src="https://img.alicdn.com/tfs/TB1E6apXHGYBuNjy0FoXXciBFXa-200-200.png"/></div><ul><li class="menu-item menu-item-level-1"><span>å…³äºApache DolphinScheduler</span><ul><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/zh-cn/docs/dev/user_doc/about/introduction.html" target="_self">ç®€ä»‹</a></li><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/zh-cn/docs/dev/user_doc/about/hardware.html" target="_self">å»ºè®®é…ç½®</a></li><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/zh-cn/docs/dev/user_doc/about/glossary.html" target="_self">åè¯è§£é‡Š</a></li></ul></li><li class="menu-item menu-item-level-1"><span>å¿«é€Ÿä¸Šæ‰‹</span><ul><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/zh-cn/docs/dev/user_doc/guide/start/quick-start.html" target="_self">å¿«é€Ÿä¸Šæ‰‹</a></li><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/zh-cn/docs/dev/user_doc/guide/start/docker.html" target="_self">Dockeréƒ¨ç½²(Docker)</a></li></ul></li><li class="menu-item menu-item-level-1"><span>åŠŸèƒ½ä»‹ç»</span><ul><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/zh-cn/docs/dev/user_doc/guide/homepage.html" target="_self">åº”ç”¨é¦–é¡µ</a></li><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><span>é¡¹ç›®ç®¡ç†<img style="transform:rotate(-90deg)" class="menu-toggle" src="/img/system/arrow_down.png"/></span><ul><li class="menu-item menu-item-level-3"><a href="/zh-cn/docs/dev/user_doc/guide/project/project-list.html" target="_self">é¡¹ç›®åˆ—è¡¨</a></li><li class="menu-item menu-item-level-3"><a href="/zh-cn/docs/dev/user_doc/guide/project/workflow-definition.html" target="_self">å·¥ä½œæµå®šä¹‰</a></li><li class="menu-item menu-item-level-3"><a href="/zh-cn/docs/dev/user_doc/guide/project/workflow-instance.html" target="_self">å·¥ä½œæµå®ä¾‹</a></li><li class="menu-item menu-item-level-3"><a href="/zh-cn/docs/dev/user_doc/guide/project/task-instance.html" target="_self">ä»»åŠ¡å®ä¾‹</a></li><li class="menu-item menu-item-level-3"><a href="/zh-cn/docs/dev/user_doc/guide/project/task-definition.html" target="_self">ä»»åŠ¡å®šä¹‰</a></li></ul></li><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><span>ä»»åŠ¡ç±»å‹<img style="transform:rotate(-90deg)" class="menu-toggle" src="/img/system/arrow_down.png"/></span><ul><li class="menu-item menu-item-level-3"><a href="/zh-cn/docs/dev/user_doc/guide/task/shell.html" target="_self">Shell</a></li><li class="menu-item menu-item-level-3"><a href="/zh-cn/docs/dev/user_doc/guide/task/sub-process.html" target="_self">SubProcess</a></li><li class="menu-item menu-item-level-3"><a href="/zh-cn/docs/dev/user_doc/guide/task/dependent.html" target="_self">Dependent</a></li><li class="menu-item menu-item-level-3"><a href="/zh-cn/docs/dev/user_doc/guide/task/stored-procedure.html" target="_self">Stored Procedure</a></li><li class="menu-item menu-item-level-3"><a href="/zh-cn/docs/dev/user_doc/guide/task/sql.html" target="_self">SQL</a></li><li class="menu-item menu-item-level-3"><a href="/zh-cn/docs/dev/user_doc/guide/task/spark.html" target="_self">Spark</a></li><li class="menu-item menu-item-level-3"><a href="/zh-cn/docs/dev/user_doc/guide/task/map-reduce.html" target="_self">MapReduce</a></li><li class="menu-item menu-item-level-3"><a href="/zh-cn/docs/dev/user_doc/guide/task/python.html" target="_self">Python</a></li><li class="menu-item menu-item-level-3"><a href="/zh-cn/docs/dev/user_doc/guide/task/flink.html" target="_self">Flink</a></li><li class="menu-item menu-item-level-3"><a href="/zh-cn/docs/dev/user_doc/guide/task/http.html" target="_self">HTTP</a></li><li class="menu-item menu-item-level-3"><a href="/zh-cn/docs/dev/user_doc/guide/task/datax.html" target="_self">DataX</a></li><li class="menu-item menu-item-level-3"><a href="/zh-cn/docs/dev/user_doc/guide/task/pigeon.html" target="_self">Pigeon</a></li><li class="menu-item menu-item-level-3"><a href="/zh-cn/docs/dev/user_doc/guide/task/conditions.html" target="_self">Conditions</a></li><li class="menu-item menu-item-level-3"><a href="/zh-cn/docs/dev/user_doc/guide/task/switch.html" target="_self">Switch</a></li><li class="menu-item menu-item-level-3"><a href="/zh-cn/docs/dev/user_doc/guide/task/emr.html" target="_self">Amazon EMR</a></li><li class="menu-item menu-item-level-3"><a href="/zh-cn/docs/dev/user_doc/guide/task/zeppelin.html" target="_self">Apache Zeppelin</a></li><li class="menu-item menu-item-level-3"><a href="/zh-cn/docs/dev/user_doc/guide/task/jupyter.html" target="_self">Jupyter</a></li><li class="menu-item menu-item-level-3"><a href="/zh-cn/docs/dev/user_doc/guide/task/kubernetes.html" target="_self">Kubernetes</a></li><li class="menu-item menu-item-level-3"><a href="/zh-cn/docs/dev/user_doc/guide/task/mlflow.html" target="_self">MLflow</a></li><li class="menu-item menu-item-level-3"><a href="/zh-cn/docs/dev/user_doc/guide/task/openmldb.html" target="_self">Openmldb</a></li><li class="menu-item menu-item-level-3"><a href="/zh-cn/docs/dev/user_doc/guide/task/dvc.html" target="_self">DVC</a></li></ul></li><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><span>å‚æ•°<img style="transform:rotate(-90deg)" class="menu-toggle" src="/img/system/arrow_down.png"/></span><ul><li class="menu-item menu-item-level-3"><a href="/zh-cn/docs/dev/user_doc/guide/parameter/built-in.html" target="_self">å†…ç½®å‚æ•°</a></li><li class="menu-item menu-item-level-3"><a href="/zh-cn/docs/dev/user_doc/guide/parameter/global.html" target="_self">å…¨å±€å‚æ•°</a></li><li class="menu-item menu-item-level-3"><a href="/zh-cn/docs/dev/user_doc/guide/parameter/local.html" target="_self">æœ¬åœ°å‚æ•°</a></li><li class="menu-item menu-item-level-3"><a href="/zh-cn/docs/dev/user_doc/guide/parameter/context.html" target="_self">å‚æ•°ä¼ é€’</a></li><li class="menu-item menu-item-level-3"><a href="/zh-cn/docs/dev/user_doc/guide/parameter/priority.html" target="_self">å‚æ•°ä¼˜å…ˆçº§</a></li></ul></li><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><span>æ•°æ®æºä¸­å¿ƒ<img style="transform:rotate(-90deg)" class="menu-toggle" src="/img/system/arrow_down.png"/></span><ul><li class="menu-item menu-item-level-3"><a href="/zh-cn/docs/dev/user_doc/guide/datasource/introduction.html" target="_self">ç®€ä»‹</a></li><li class="menu-item menu-item-level-3"><a href="/zh-cn/docs/dev/user_doc/guide/datasource/mysql.html" target="_self">MySQL</a></li><li class="menu-item menu-item-level-3"><a href="/zh-cn/docs/dev/user_doc/guide/datasource/postgresql.html" target="_self">PostgreSQL</a></li><li class="menu-item menu-item-level-3"><a href="/zh-cn/docs/dev/user_doc/guide/datasource/hive.html" target="_self">HIVE</a></li><li class="menu-item menu-item-level-3"><a href="/zh-cn/docs/dev/user_doc/guide/datasource/spark.html" target="_self">Spark</a></li></ul></li><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><span>å‘Šè­¦<img style="transform:rotate(-90deg)" class="menu-toggle" src="/img/system/arrow_down.png"/></span><ul><li class="menu-item menu-item-level-3"><a href="/zh-cn/docs/dev/user_doc/guide/alert/alert_plugin_user_guide.html" target="_self">å‘Šè­¦ç»„ä»¶å‘å¯¼</a></li><li class="menu-item menu-item-level-3"><a href="/zh-cn/docs/dev/user_doc/guide/alert/telegram.html" target="_self">Telegram</a></li><li class="menu-item menu-item-level-3"><a href="/zh-cn/docs/dev/user_doc/guide/alert/dingtalk.html" target="_self">é’‰é’‰å‘Šè­¦</a></li><li class="menu-item menu-item-level-3"><a href="/zh-cn/docs/dev/user_doc/guide/alert/enterprise-wechat.html" target="_self">ä¼ä¸šå¾®ä¿¡</a></li><li class="menu-item menu-item-level-3"><a href="/zh-cn/docs/dev/user_doc/guide/alert/enterprise-webexteams.html" target="_self">Webexteams</a></li><li class="menu-item menu-item-level-3"><a href="/zh-cn/docs/dev/user_doc/guide/alert/script.html" target="_self">è„šæœ¬å‘Šè­¦</a></li><li class="menu-item menu-item-level-3"><a href="/zh-cn/docs/dev/user_doc/guide/alert/http.html" target="_self">Httpå‘Šè­¦</a></li></ul></li><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><span>èµ„æºä¸­å¿ƒ<img style="transform:rotate(-90deg)" class="menu-toggle" src="/img/system/arrow_down.png"/></span><ul><li class="menu-item menu-item-level-3"><a href="/zh-cn/docs/dev/user_doc/guide/resource/configuration.html" target="_self">é…ç½®è¯¦æƒ…</a></li><li class="menu-item menu-item-level-3"><a href="/zh-cn/docs/dev/user_doc/guide/resource/file-manage.html" target="_self">æ–‡ä»¶ç®¡ç†</a></li><li class="menu-item menu-item-level-3"><a href="/zh-cn/docs/dev/user_doc/guide/resource/udf-manage.html" target="_self">UDF ç®¡ç†</a></li><li class="menu-item menu-item-level-3"><a href="/zh-cn/docs/dev/user_doc/guide/resource/task-group.html" target="_self">ä»»åŠ¡ç»„ç®¡ç†</a></li></ul></li><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/zh-cn/docs/dev/user_doc/guide/monitor.html" target="_self">ç›‘æ§ä¸­å¿ƒ</a></li><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/zh-cn/docs/dev/user_doc/guide/security.html" target="_self">å®‰å…¨ä¸­å¿ƒ</a></li><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><span>æŒ‡æ ‡ç›¸å…³<img style="transform:rotate(-90deg)" class="menu-toggle" src="/img/system/arrow_down.png"/></span><ul><li class="menu-item menu-item-level-3"><a href="/zh-cn/docs/dev/user_doc/guide/metrics/metrics.html" target="_self">æŒ‡æ ‡</a></li></ul></li><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/zh-cn/docs/dev/user_doc/guide/data-quality.html" target="_self">æ•°æ®è´¨é‡</a></li><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/zh-cn/docs/dev/user_doc/guide/upgrade.html" target="_self">å‡çº§</a></li><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/zh-cn/docs/dev/user_doc/guide/expansion-reduction.html" target="_self">æ‰©/ç¼©å®¹</a></li></ul></li><li class="menu-item menu-item-level-1"><span>éƒ¨ç½²æŒ‡å—</span><ul><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/zh-cn/docs/dev/user_doc/guide/installation/standalone.html" target="_self">å•æœºéƒ¨ç½²(Standalone)</a></li><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/zh-cn/docs/dev/user_doc/guide/installation/pseudo-cluster.html" target="_self">ä¼ªé›†ç¾¤éƒ¨ç½²(Pseudo-Cluster)</a></li><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/zh-cn/docs/dev/user_doc/guide/installation/cluster.html" target="_self">é›†ç¾¤éƒ¨ç½²(Cluster)</a></li><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/zh-cn/docs/dev/user_doc/guide/installation/kubernetes.html" target="_self">Kuberneteséƒ¨ç½²(Kubernetes)</a></li></ul></li><li class="menu-item menu-item-level-1"><span>æ¶æ„è®¾è®¡</span><ul><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/zh-cn/docs/dev/user_doc/architecture/metadata.html" target="_self">å…ƒæ•°æ®æ–‡æ¡£</a></li><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/zh-cn/docs/dev/user_doc/architecture/design.html" target="_self">æ¶æ„è®¾è®¡</a></li><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/zh-cn/docs/dev/user_doc/architecture/configuration.html" target="_self">é…ç½®æ–‡ä»¶</a></li><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/zh-cn/docs/dev/user_doc/architecture/task-structure.html" target="_self">ä»»åŠ¡ç»“æ„</a></li><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/zh-cn/docs/dev/user_doc/architecture/load-balance.html" target="_self">è´Ÿè½½å‡è¡¡</a></li><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/zh-cn/docs/dev/user_doc/architecture/cache.html" target="_self">ç¼“å­˜</a></li></ul></li><li class="menu-item menu-item-level-1"><span>API</span><ul><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/zh-cn/docs/dev/user_doc/guide/open-api.html" target="_self">APIè°ƒç”¨</a></li><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/python/index.html" target="_self">PyDolphinScheduler</a></li><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/zh-cn/docs/dev/user_doc/guide/healthcheck.html" target="_self">å¥åº·æ£€æŸ¥</a></li></ul></li><li class="menu-item menu-item-level-1"><span>FAQ</span><ul><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/zh-cn/docs/dev/user_doc/guide/howto/general-setting.html" target="_self">é€šç”¨è®¾ç½®</a></li><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/zh-cn/docs/release/faq.html" target="_self">å…¶ä»–</a></li></ul></li><li class="menu-item menu-item-level-1"><span>å†å²ç‰ˆæœ¬</span><ul><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/zh-cn/docs/release/history-versions.html" target="_self">å†å²ç‰ˆæœ¬</a></li></ul></li></ul></div><div class="doc-content markdown-body"><h1>å¿«é€Ÿè¯•ç”¨ Kubernetes éƒ¨ç½²</h1>
<p>Kuberneteséƒ¨ç½²ç›®çš„æ˜¯åœ¨Kubernetesé›†ç¾¤ä¸­éƒ¨ç½² DolphinScheduler æœåŠ¡ï¼Œèƒ½è°ƒåº¦å¤§é‡ä»»åŠ¡ï¼Œå¯ç”¨äºåœ¨ç”Ÿäº§ä¸­éƒ¨ç½²ã€‚</p>
<p>å¦‚æœä½ æ˜¯æ–°æ‰‹ï¼Œæƒ³è¦ä½“éªŒ DolphinScheduler çš„åŠŸèƒ½ï¼Œæ¨èä½¿ç”¨<a href="standalone.md">Standalone</a>æ–¹å¼ä½“æ£€ã€‚å¦‚æœä½ æƒ³ä½“éªŒæ›´å®Œæ•´çš„åŠŸèƒ½ï¼Œæˆ–è€…æ›´å¤§çš„ä»»åŠ¡é‡ï¼Œæ¨èä½¿ç”¨<a href="pseudo-cluster.md">ä¼ªé›†ç¾¤éƒ¨ç½²</a>ã€‚å¦‚æœä½ æ˜¯åœ¨ç”Ÿäº§ä¸­ä½¿ç”¨ï¼Œæ¨èä½¿ç”¨<a href="cluster.md">é›†ç¾¤éƒ¨ç½²</a>æˆ–è€…<a href="kubernetes.md">kubernetes</a></p>
<h2>å…ˆå†³æ¡ä»¶</h2>
<ul>
<li><a href="https://helm.sh/">Helm</a> 3.1.0+</li>
<li><a href="https://kubernetes.io/">Kubernetes</a> 1.12+</li>
<li>PV ä¾›åº”(éœ€è¦åŸºç¡€è®¾æ–½æ”¯æŒ)</li>
</ul>
<h2>å®‰è£… dolphinscheduler</h2>
<p>è¯·ä¸‹è½½æºç åŒ… apache-dolphinscheduler-<version>-src.tar.gzï¼Œä¸‹è½½åœ°å€: <a href="/zh-cn/download/download.html">ä¸‹è½½</a></p>
<p>å‘å¸ƒä¸€ä¸ªåä¸º <code>dolphinscheduler</code> çš„ç‰ˆæœ¬(release)ï¼Œè¯·æ‰§è¡Œä»¥ä¸‹å‘½ä»¤ï¼š</p>
<pre><code>$ tar -zxvf apache-dolphinscheduler-&lt;version&gt;-src.tar.gz
$ cd apache-dolphinscheduler-&lt;version&gt;-src/deploy/kubernetes/dolphinscheduler
$ helm repo add bitnami https://charts.bitnami.com/bitnami
$ helm dependency update .
$ helm install dolphinscheduler . --set image.tag=&lt;version&gt;
</code></pre>
<p>å°†åä¸º <code>dolphinscheduler</code> çš„ç‰ˆæœ¬(release) å‘å¸ƒåˆ° <code>test</code> çš„å‘½åç©ºé—´ä¸­ï¼š</p>
<pre><code class="language-bash">$ helm install dolphinscheduler . -n <span class="hljs-built_in">test</span>
</code></pre>
<blockquote>
<p><strong>æç¤º</strong>: å¦‚æœåä¸º <code>test</code> çš„å‘½åç©ºé—´è¢«ä½¿ç”¨, é€‰é¡¹å‚æ•° <code>-n test</code> éœ€è¦æ·»åŠ åˆ° <code>helm</code> å’Œ <code>kubectl</code> å‘½ä»¤ä¸­</p>
</blockquote>
<p>è¿™äº›å‘½ä»¤ä»¥é»˜è®¤é…ç½®åœ¨ Kubernetes é›†ç¾¤ä¸Šéƒ¨ç½² DolphinSchedulerï¼Œ<a href="#appendix-configuration">é™„å½•-é…ç½®</a>éƒ¨åˆ†åˆ—å‡ºäº†å¯ä»¥åœ¨å®‰è£…è¿‡ç¨‹ä¸­é…ç½®çš„å‚æ•°  <!-- markdown-link-check-disable-line --></p>
<blockquote>
<p><strong>æç¤º</strong>: åˆ—å‡ºæ‰€æœ‰å·²å‘å¸ƒçš„ç‰ˆæœ¬ï¼Œä½¿ç”¨ <code>helm list</code></p>
</blockquote>
<p><strong>PostgreSQL</strong> (ç”¨æˆ· <code>root</code>, å¯†ç  <code>root</code>, æ•°æ®åº“ <code>dolphinscheduler</code>) å’Œ <strong>ZooKeeper</strong> æœåŠ¡å°†ä¼šé»˜è®¤å¯åŠ¨</p>
<h2>è®¿é—® DolphinScheduler å‰ç«¯é¡µé¢</h2>
<p>å¦‚æœ <code>values.yaml</code> æ–‡ä»¶ä¸­çš„ <code>ingress.enabled</code> è¢«è®¾ç½®ä¸º <code>true</code>, åœ¨æµè§ˆå™¨ä¸­è®¿é—® <code>http://${ingress.host}/dolphinscheduler</code> å³å¯</p>
<blockquote>
<p><strong>æç¤º</strong>: å¦‚æœ ingress è®¿é—®é‡åˆ°é—®é¢˜ï¼Œè¯·è”ç³» Kubernetes ç®¡ç†å‘˜å¹¶æŸ¥çœ‹ <a href="https://kubernetes.io/docs/concepts/services-networking/ingress/">Ingress</a></p>
</blockquote>
<p>å¦åˆ™ï¼Œå½“ <code>api.service.type=ClusterIP</code> æ—¶ï¼Œä½ éœ€è¦æ‰§è¡Œ port-forward ç«¯å£è½¬å‘å‘½ä»¤ï¼š</p>
<pre><code class="language-bash">$ kubectl port-forward --address 0.0.0.0 svc/dolphinscheduler-api 12345:12345
$ kubectl port-forward --address 0.0.0.0 -n <span class="hljs-built_in">test</span> svc/dolphinscheduler-api 12345:12345 <span class="hljs-comment"># ä½¿ç”¨ test å‘½åç©ºé—´</span>
</code></pre>
<blockquote>
<p><strong>æç¤º</strong>: å¦‚æœå‡ºç° <code>unable to do port forwarding: socat not found</code> é”™è¯¯, éœ€è¦å…ˆå®‰è£… <code>socat</code></p>
</blockquote>
<p>è®¿é—®å‰ç«¯é¡µé¢ï¼š<a href="http://localhost:12345/dolphinscheduler/ui%EF%BC%8C%E5%A6%82%E6%9E%9C%E6%9C%89%E9%9C%80%E8%A6%81%E8%AF%B7%E4%BF%AE%E6%94%B9%E6%88%90%E5%AF%B9%E5%BA%94%E7%9A%84">http://localhost:12345/dolphinscheduler/uiï¼Œå¦‚æœæœ‰éœ€è¦è¯·ä¿®æ”¹æˆå¯¹åº”çš„</a> IP åœ°å€</p>
<p>æˆ–è€…å½“ <code>api.service.type=NodePort</code> æ—¶ï¼Œä½ éœ€è¦æ‰§è¡Œå‘½ä»¤ï¼š</p>
<pre><code class="language-bash">NODE_IP=$(kubectl get no -n {{ .Release.Namespace }} -o jsonpath=<span class="hljs-string">&quot;{.items[0].status.addresses[0].address}&quot;</span>)
NODE_PORT=$(kubectl get svc {{ template <span class="hljs-string">&quot;dolphinscheduler.fullname&quot;</span> . }}-api -n {{ .Release.Namespace }} -o jsonpath=<span class="hljs-string">&quot;{.spec.ports[0].nodePort}&quot;</span>)
<span class="hljs-built_in">echo</span> http://<span class="hljs-variable">$NODE_IP</span>:<span class="hljs-variable">$NODE_PORT</span>/dolphinscheduler
</code></pre>
<p>ç„¶åè®¿é—®å‰ç«¯é¡µé¢: <a href="http://localhost:12345/dolphinscheduler/ui">http://localhost:12345/dolphinscheduler/ui</a></p>
<p>é»˜è®¤çš„ç”¨æˆ·æ˜¯<code>admin</code>ï¼Œé»˜è®¤çš„å¯†ç æ˜¯<code>dolphinscheduler123</code></p>
<p>è¯·å‚è€ƒç”¨æˆ·æ‰‹å†Œç« èŠ‚çš„<a href="../start/quick-start.md">å¿«é€Ÿä¸Šæ‰‹</a>æŸ¥çœ‹å¦‚ä½•ä½¿ç”¨DolphinScheduler</p>
<h2>å¸è½½ dolphinscheduler</h2>
<p>å¸è½½åä¸º <code>dolphinscheduler</code> çš„ç‰ˆæœ¬(release)ï¼Œè¯·æ‰§è¡Œï¼š</p>
<pre><code class="language-bash">$ helm uninstall dolphinscheduler
</code></pre>
<p>è¯¥å‘½ä»¤å°†åˆ é™¤ä¸ <code>dolphinscheduler</code> ç›¸å…³çš„æ‰€æœ‰ Kubernetes ç»„ä»¶ï¼ˆä½†PVCé™¤å¤–ï¼‰ï¼Œå¹¶åˆ é™¤ç‰ˆæœ¬(release)</p>
<p>è¦åˆ é™¤ä¸ <code>dolphinscheduler</code> ç›¸å…³çš„PVCï¼Œè¯·æ‰§è¡Œï¼š</p>
<pre><code class="language-bash">$ kubectl delete pvc -l app.kubernetes.io/instance=dolphinscheduler
</code></pre>
<blockquote>
<p><strong>æ³¨æ„</strong>: åˆ é™¤PVCä¹Ÿä¼šåˆ é™¤æ‰€æœ‰æ•°æ®ï¼Œè¯·è°¨æ…æ“ä½œï¼</p>
</blockquote>
<h2>é…ç½®</h2>
<p>é…ç½®æ–‡ä»¶ä¸º <code>values.yaml</code>ï¼Œ<a href="#appendix-configuration">é™„å½•-é…ç½®</a> è¡¨æ ¼åˆ—å‡ºäº† DolphinScheduler çš„å¯é…ç½®å‚æ•°åŠå…¶é»˜è®¤å€¼  <!-- markdown-link-check-disable-line --></p>
<h2>æ”¯æŒçŸ©é˜µ</h2>
<table>
<thead>
<tr>
<th>Type</th>
<th>æ”¯æŒ</th>
<th>å¤‡æ³¨</th>
</tr>
</thead>
<tbody>
<tr>
<td>Shell</td>
<td>æ˜¯</td>
<td></td>
</tr>
<tr>
<td>Python2</td>
<td>æ˜¯</td>
<td></td>
</tr>
<tr>
<td>Python3</td>
<td>é—´æ¥æ”¯æŒ</td>
<td>è¯¦è§ FAQ</td>
</tr>
<tr>
<td>Hadoop2</td>
<td>é—´æ¥æ”¯æŒ</td>
<td>è¯¦è§ FAQ</td>
</tr>
<tr>
<td>Hadoop3</td>
<td>å°šæœªç¡®å®š</td>
<td>å°šæœªæµ‹è¯•</td>
</tr>
<tr>
<td>Spark-Local(client)</td>
<td>é—´æ¥æ”¯æŒ</td>
<td>è¯¦è§ FAQ</td>
</tr>
<tr>
<td>Spark-YARN(cluster)</td>
<td>é—´æ¥æ”¯æŒ</td>
<td>è¯¦è§ FAQ</td>
</tr>
<tr>
<td>Spark-Standalone(cluster)</td>
<td>å°šä¸</td>
<td></td>
</tr>
<tr>
<td>Spark-Kubernetes(cluster)</td>
<td>å°šä¸</td>
<td></td>
</tr>
<tr>
<td>Flink-Local(local&gt;=1.11)</td>
<td>å°šä¸</td>
<td>Generic CLI æ¨¡å¼å°šæœªæ”¯æŒ</td>
</tr>
<tr>
<td>Flink-YARN(yarn-cluster)</td>
<td>é—´æ¥æ”¯æŒ</td>
<td>è¯¦è§ FAQ</td>
</tr>
<tr>
<td>Flink-YARN(yarn-session/yarn-per-job/yarn-application&gt;=1.11)</td>
<td>å°šä¸</td>
<td>Generic CLI æ¨¡å¼å°šæœªæ”¯æŒ</td>
</tr>
<tr>
<td>Flink-Standalone(default)</td>
<td>å°šä¸</td>
<td></td>
</tr>
<tr>
<td>Flink-Standalone(remote&gt;=1.11)</td>
<td>å°šä¸</td>
<td>Generic CLI æ¨¡å¼å°šæœªæ”¯æŒ</td>
</tr>
<tr>
<td>Flink-Kubernetes(default)</td>
<td>å°šä¸</td>
<td></td>
</tr>
<tr>
<td>Flink-Kubernetes(remote&gt;=1.11)</td>
<td>å°šä¸</td>
<td>Generic CLI æ¨¡å¼å°šæœªæ”¯æŒ</td>
</tr>
<tr>
<td>Flink-NativeKubernetes(kubernetes-session/application&gt;=1.11)</td>
<td>å°šä¸</td>
<td>Generic CLI æ¨¡å¼å°šæœªæ”¯æŒ</td>
</tr>
<tr>
<td>MapReduce</td>
<td>é—´æ¥æ”¯æŒ</td>
<td>è¯¦è§ FAQ</td>
</tr>
<tr>
<td>Kerberos</td>
<td>é—´æ¥æ”¯æŒ</td>
<td>è¯¦è§ FAQ</td>
</tr>
<tr>
<td>HTTP</td>
<td>æ˜¯</td>
<td></td>
</tr>
<tr>
<td>DataX</td>
<td>é—´æ¥æ”¯æŒ</td>
<td>è¯¦è§ FAQ</td>
</tr>
<tr>
<td>Sqoop</td>
<td>é—´æ¥æ”¯æŒ</td>
<td>è¯¦è§ FAQ</td>
</tr>
<tr>
<td>SQL-MySQL</td>
<td>é—´æ¥æ”¯æŒ</td>
<td>è¯¦è§ FAQ</td>
</tr>
<tr>
<td>SQL-PostgreSQL</td>
<td>æ˜¯</td>
<td></td>
</tr>
<tr>
<td>SQL-Hive</td>
<td>é—´æ¥æ”¯æŒ</td>
<td>è¯¦è§ FAQ</td>
</tr>
<tr>
<td>SQL-Spark</td>
<td>é—´æ¥æ”¯æŒ</td>
<td>è¯¦è§ FAQ</td>
</tr>
<tr>
<td>SQL-ClickHouse</td>
<td>é—´æ¥æ”¯æŒ</td>
<td>è¯¦è§ FAQ</td>
</tr>
<tr>
<td>SQL-Oracle</td>
<td>é—´æ¥æ”¯æŒ</td>
<td>è¯¦è§ FAQ</td>
</tr>
<tr>
<td>SQL-SQLServer</td>
<td>é—´æ¥æ”¯æŒ</td>
<td>è¯¦è§ FAQ</td>
</tr>
<tr>
<td>SQL-DB2</td>
<td>é—´æ¥æ”¯æŒ</td>
<td>è¯¦è§ FAQ</td>
</tr>
</tbody>
</table>
<h2>FAQ</h2>
<h3>å¦‚ä½•æŸ¥çœ‹ä¸€ä¸ª pod å®¹å™¨çš„æ—¥å¿—ï¼Ÿ</h3>
<p>åˆ—å‡ºæ‰€æœ‰ pods (åˆ«å <code>po</code>):</p>
<pre><code>kubectl get po
kubectl get po -n test # with test namespace
</code></pre>
<p>æŸ¥çœ‹åä¸º dolphinscheduler-master-0 çš„ pod å®¹å™¨çš„æ—¥å¿—:</p>
<pre><code>kubectl logs dolphinscheduler-master-0
kubectl logs -f dolphinscheduler-master-0 # è·Ÿéšæ—¥å¿—è¾“å‡º
kubectl logs --tail 10 dolphinscheduler-master-0 -n test # æ˜¾ç¤ºå€’æ•°10è¡Œæ—¥å¿—
</code></pre>
<h3>å¦‚ä½•åœ¨ Kubernetes ä¸Šæ‰©ç¼©å®¹ api, master å’Œ workerï¼Ÿ</h3>
<p>åˆ—å‡ºæ‰€æœ‰ deployments (åˆ«å <code>deploy</code>):</p>
<pre><code>kubectl get deploy
kubectl get deploy -n test # with test namespace
</code></pre>
<p>æ‰©ç¼©å®¹ api è‡³ 3 ä¸ªå‰¯æœ¬:</p>
<pre><code>kubectl scale --replicas=3 deploy dolphinscheduler-api
kubectl scale --replicas=3 deploy dolphinscheduler-api -n test # with test namespace
</code></pre>
<p>åˆ—å‡ºæ‰€æœ‰ statefulsets (åˆ«å <code>sts</code>):</p>
<pre><code>kubectl get sts
kubectl get sts -n test # with test namespace
</code></pre>
<p>æ‰©ç¼©å®¹ master è‡³ 2 ä¸ªå‰¯æœ¬:</p>
<pre><code>kubectl scale --replicas=2 sts dolphinscheduler-master
kubectl scale --replicas=2 sts dolphinscheduler-master -n test # with test namespace
</code></pre>
<p>æ‰©ç¼©å®¹ worker è‡³ 6 ä¸ªå‰¯æœ¬:</p>
<pre><code>kubectl scale --replicas=6 sts dolphinscheduler-worker
kubectl scale --replicas=6 sts dolphinscheduler-worker -n test # with test namespace
</code></pre>
<h3>å¦‚ä½•ç”¨ MySQL æ›¿ä»£ PostgreSQL ä½œä¸º DolphinScheduler çš„æ•°æ®åº“ï¼Ÿ</h3>
<blockquote>
<p>ç”±äºå•†ä¸šè®¸å¯è¯çš„åŸå› ï¼Œæˆ‘ä»¬ä¸èƒ½ç›´æ¥ä½¿ç”¨ MySQL çš„é©±åŠ¨åŒ….</p>
<p>å¦‚æœä½ è¦ä½¿ç”¨ MySQL, ä½ å¯ä»¥åŸºäºå®˜æ–¹é•œåƒ <code>apache/dolphinscheduler-&lt;service&gt;</code> è¿›è¡Œæ„å»º.</p>
<p>ä»3.0.0ç‰ˆæœ¬èµ·ï¼Œdolphinschedulerå·²ç»å¾®æœåŠ¡åŒ–ï¼Œæ›´æ”¹å…ƒæ•°æ®å­˜å‚¨éœ€è¦å¯¹æŠŠæ‰€æœ‰çš„æœåŠ¡éƒ½æ›¿æ¢ä¸º MySQL é©±åŠ¨åŒ…ï¼ŒåŒ…æ‹¬ dolphinscheduler-tools, dolphinscheduler-master, dolphinscheduler-worker, dolphinscheduler-api, dolphinscheduler-alert-server .</p>
</blockquote>
<ol>
<li>
<p>ä¸‹è½½ MySQL é©±åŠ¨åŒ… <a href="https://repo1.maven.org/maven2/mysql/mysql-connector-java/8.0.16/mysql-connector-java-8.0.16.jar">mysql-connector-java-8.0.16.jar</a></p>
</li>
<li>
<p>åˆ›å»ºä¸€ä¸ªæ–°çš„ <code>Dockerfile</code>ï¼Œç”¨äºæ·»åŠ  MySQL çš„é©±åŠ¨åŒ…:</p>
</li>
</ol>
<pre><code>FROM dolphinscheduler.docker.scarf.sh/apache/dolphinscheduler-&lt;service&gt;:&lt;version&gt;
# For example
# FROM dolphinscheduler.docker.scarf.sh/apache/dolphinscheduler-tools:&lt;version&gt;

COPY mysql-connector-java-8.0.16.jar /opt/dolphinscheduler/lib
</code></pre>
<ol start="3">
<li>æ„å»ºä¸€ä¸ªåŒ…å« MySQL é©±åŠ¨åŒ…çš„æ–°é•œåƒ:</li>
</ol>
<pre><code>docker build -t apache/dolphinscheduler-&lt;service&gt;:mysql-driver .
</code></pre>
<ol start="4">
<li>
<p>æ¨é€ docker é•œåƒ <code>apache/dolphinscheduler-&lt;service&gt;:mysql-driver</code> åˆ°ä¸€ä¸ª docker registry ä¸­</p>
</li>
<li>
<p>ä¿®æ”¹ <code>values.yaml</code> æ–‡ä»¶ä¸­ image çš„ <code>repository</code> å­—æ®µï¼Œå¹¶æ›´æ–° <code>tag</code> ä¸º <code>mysql-driver</code></p>
</li>
<li>
<p>ä¿®æ”¹ <code>values.yaml</code> æ–‡ä»¶ä¸­ postgresql çš„ <code>enabled</code> ä¸º <code>false</code></p>
</li>
<li>
<p>ä¿®æ”¹ <code>values.yaml</code> æ–‡ä»¶ä¸­çš„ externalDatabase é…ç½® (å°¤å…¶ä¿®æ”¹ <code>host</code>, <code>username</code> å’Œ <code>password</code>)</p>
</li>
</ol>
<pre><code class="language-yaml"><span class="hljs-attr">externalDatabase:</span>
  <span class="hljs-attr">type:</span> <span class="hljs-string">&quot;mysql&quot;</span>
  <span class="hljs-attr">host:</span> <span class="hljs-string">&quot;localhost&quot;</span>
  <span class="hljs-attr">port:</span> <span class="hljs-string">&quot;3306&quot;</span>
  <span class="hljs-attr">username:</span> <span class="hljs-string">&quot;root&quot;</span>
  <span class="hljs-attr">password:</span> <span class="hljs-string">&quot;root&quot;</span>
  <span class="hljs-attr">database:</span> <span class="hljs-string">&quot;dolphinscheduler&quot;</span>
  <span class="hljs-attr">params:</span> <span class="hljs-string">&quot;useUnicode=true&amp;characterEncoding=UTF-8&quot;</span>
</code></pre>
<ol start="8">
<li>éƒ¨ç½² dolphinscheduler (è¯¦è§<strong>å®‰è£… dolphinscheduler</strong>)</li>
</ol>
<h3>å¦‚ä½•åœ¨æ•°æ®æºä¸­å¿ƒæ”¯æŒ MySQL æˆ–è€… Oracle æ•°æ®æºï¼Ÿ</h3>
<blockquote>
<p>ç”±äºå•†ä¸šè®¸å¯è¯çš„åŸå› ï¼Œæˆ‘ä»¬ä¸èƒ½ç›´æ¥ä½¿ç”¨ MySQL æˆ–è€… Oracle çš„é©±åŠ¨åŒ….</p>
<p>å¦‚æœä½ è¦æ·»åŠ  MySQL æˆ–è€… Oracle, ä½ å¯ä»¥åŸºäºå®˜æ–¹é•œåƒ <code>apache/dolphinscheduler-&lt;service&gt;</code> è¿›è¡Œæ„å»º.</p>
<p>éœ€è¦æ›´æ”¹ dolphinscheduler-worker, dolphinscheduler-api ä¸¤ä¸ªæœåŠ¡çš„é•œåƒ.</p>
</blockquote>
<ol>
<li>
<p>ä¸‹è½½ MySQL é©±åŠ¨åŒ… <a href="https://repo1.maven.org/maven2/mysql/mysql-connector-java/8.0.16/mysql-connector-java-8.0.16.jar">mysql-connector-java-8.0.16.jar</a>
æˆ–è€… Oracle é©±åŠ¨åŒ… <a href="https://repo1.maven.org/maven2/com/oracle/database/jdbc/ojdbc8/">ojdbc8.jar</a> (ä¾‹å¦‚ <code>ojdbc8-19.9.0.0.jar</code>)</p>
</li>
<li>
<p>åˆ›å»ºä¸€ä¸ªæ–°çš„ <code>Dockerfile</code>ï¼Œç”¨äºæ·»åŠ  MySQL æˆ–è€… Oracle é©±åŠ¨åŒ…:</p>
</li>
</ol>
<pre><code>FROM dolphinscheduler.docker.scarf.sh/apache/dolphinscheduler-&lt;service&gt;:&lt;version&gt;
# For example
# FROM dolphinscheduler.docker.scarf.sh/apache/dolphinscheduler-worker:&lt;version&gt;

# If you want to support MySQL Datasource
COPY mysql-connector-java-8.0.16.jar /opt/dolphinscheduler/lib

# If you want to support Oracle Datasource
COPY ojdbc8-19.9.0.0.jar /opt/dolphinscheduler/lib
</code></pre>
<ol start="3">
<li>æ„å»ºä¸€ä¸ªåŒ…å« MySQL æˆ–è€… Oracle é©±åŠ¨åŒ…çš„æ–°é•œåƒ:</li>
</ol>
<pre><code>docker build -t apache/dolphinscheduler-&lt;service&gt;:new-driver .
</code></pre>
<ol start="4">
<li>
<p>æ¨é€ docker é•œåƒ <code>apache/dolphinscheduler-&lt;service&gt;:new-driver</code> åˆ°ä¸€ä¸ª docker registry ä¸­</p>
</li>
<li>
<p>ä¿®æ”¹ <code>values.yaml</code> æ–‡ä»¶ä¸­ image çš„ <code>repository</code> å­—æ®µï¼Œå¹¶æ›´æ–° <code>tag</code> ä¸º <code>new-driver</code></p>
</li>
<li>
<p>éƒ¨ç½² dolphinscheduler (è¯¦è§<strong>å®‰è£… dolphinscheduler</strong>)</p>
</li>
<li>
<p>åœ¨æ•°æ®æºä¸­å¿ƒæ·»åŠ ä¸€ä¸ª MySQL æˆ–è€… Oracle æ•°æ®æº</p>
</li>
</ol>
<h3>å¦‚ä½•æ”¯æŒ Python 2 pip ä»¥åŠè‡ªå®šä¹‰ requirements.txtï¼Ÿ</h3>
<blockquote>
<p>åªéœ€è¦æ›´æ”¹ dolphinscheduler-worker æœåŠ¡çš„é•œåƒ.</p>
</blockquote>
<ol>
<li>åˆ›å»ºä¸€ä¸ªæ–°çš„ <code>Dockerfile</code>ï¼Œç”¨äºå®‰è£… pip:</li>
</ol>
<pre><code>FROM dolphinscheduler.docker.scarf.sh/apache/dolphinscheduler-worker:&lt;version&gt;
COPY requirements.txt /tmp
RUN apt-get update &amp;&amp; \
    apt-get install -y --no-install-recommends python-pip &amp;&amp; \
    pip install --no-cache-dir -r /tmp/requirements.txt &amp;&amp; \
    rm -rf /var/lib/apt/lists/*
</code></pre>
<p>è¿™ä¸ªå‘½ä»¤ä¼šå®‰è£…é»˜è®¤çš„ <strong>pip 18.1</strong>. å¦‚æœä½ æƒ³å‡çº§ pip, åªéœ€æ·»åŠ ä¸€è¡Œ</p>
<pre><code>pip install --no-cache-dir -U pip &amp;&amp; \
</code></pre>
<ol start="2">
<li>æ„å»ºä¸€ä¸ªåŒ…å« pip çš„æ–°é•œåƒ:</li>
</ol>
<pre><code>docker build -t apache/dolphinscheduler-worker:pip .
</code></pre>
<ol start="3">
<li>
<p>æ¨é€ docker é•œåƒ <code>apache/dolphinscheduler-worker:pip</code> åˆ°ä¸€ä¸ª docker registry ä¸­</p>
</li>
<li>
<p>ä¿®æ”¹ <code>values.yaml</code> æ–‡ä»¶ä¸­ image çš„ <code>repository</code> å­—æ®µï¼Œå¹¶æ›´æ–° <code>tag</code> ä¸º <code>pip</code></p>
</li>
<li>
<p>éƒ¨ç½² dolphinscheduler (è¯¦è§<strong>å®‰è£… dolphinscheduler</strong>)</p>
</li>
<li>
<p>åœ¨ä¸€ä¸ªæ–° Python ä»»åŠ¡ä¸‹éªŒè¯ pip</p>
</li>
</ol>
<h3>å¦‚ä½•æ”¯æŒ Python 3ï¼Ÿ</h3>
<blockquote>
<p>åªéœ€è¦æ›´æ”¹ dolphinscheduler-worker æœåŠ¡çš„é•œåƒ.</p>
</blockquote>
<ol>
<li>åˆ›å»ºä¸€ä¸ªæ–°çš„ <code>Dockerfile</code>ï¼Œç”¨äºå®‰è£… Python 3:</li>
</ol>
<pre><code>FROM dolphinscheduler.docker.scarf.sh/apache/dolphinscheduler-worker:&lt;version&gt;
RUN apt-get update &amp;&amp; \
    apt-get install -y --no-install-recommends python3 &amp;&amp; \
    rm -rf /var/lib/apt/lists/*
</code></pre>
<p>è¿™ä¸ªå‘½ä»¤ä¼šå®‰è£…é»˜è®¤çš„ <strong>Python 3.7.3</strong>. å¦‚æœä½ ä¹Ÿæƒ³å®‰è£… <strong>pip3</strong>, å°† <code>python3</code> æ›¿æ¢ä¸º <code>python3-pip</code> å³å¯</p>
<pre><code>apt-get install -y --no-install-recommends python3-pip &amp;&amp; \
</code></pre>
<ol start="2">
<li>æ„å»ºä¸€ä¸ªåŒ…å« Python 3 çš„æ–°é•œåƒ:</li>
</ol>
<pre><code>docker build -t apache/dolphinscheduler-worker:python3 .
</code></pre>
<ol start="3">
<li>
<p>æ¨é€ docker é•œåƒ <code>apache/dolphinscheduler-worker:python3</code> åˆ°ä¸€ä¸ª docker registry ä¸­</p>
</li>
<li>
<p>ä¿®æ”¹ <code>values.yaml</code> æ–‡ä»¶ä¸­ image çš„ <code>repository</code> å­—æ®µï¼Œå¹¶æ›´æ–° <code>tag</code> ä¸º <code>python3</code></p>
</li>
<li>
<p>ä¿®æ”¹ <code>values.yaml</code> æ–‡ä»¶ä¸­çš„ <code>PYTHON_HOME</code> ä¸º <code>/usr/bin/python3</code></p>
</li>
<li>
<p>éƒ¨ç½² dolphinscheduler (è¯¦è§<strong>å®‰è£… dolphinscheduler</strong>)</p>
</li>
<li>
<p>åœ¨ä¸€ä¸ªæ–° Python ä»»åŠ¡ä¸‹éªŒè¯ Python 3</p>
</li>
</ol>
<h3>å¦‚ä½•æ”¯æŒ Hadoop, Spark, Flink, Hive æˆ– DataXï¼Ÿ</h3>
<p>ä»¥ Spark 2.4.7 ä¸ºä¾‹:</p>
<ol>
<li>
<p>ä¸‹è½½ Spark 2.4.7 å‘å¸ƒçš„äºŒè¿›åˆ¶åŒ… <code>spark-2.4.7-bin-hadoop2.7.tgz</code></p>
</li>
<li>
<p>ç¡®ä¿ <code>common.sharedStoragePersistence.enabled</code> å¼€å¯</p>
</li>
<li>
<p>éƒ¨ç½² dolphinscheduler (è¯¦è§<strong>å®‰è£… dolphinscheduler</strong>)</p>
</li>
<li>
<p>å¤åˆ¶ Spark 3.1.1 äºŒè¿›åˆ¶åŒ…åˆ° Docker å®¹å™¨ä¸­</p>
</li>
</ol>
<pre><code class="language-bash">kubectl cp spark-2.4.7-bin-hadoop2.7.tgz dolphinscheduler-worker-0:/opt/soft
kubectl cp -n <span class="hljs-built_in">test</span> spark-2.4.7-bin-hadoop2.7.tgz dolphinscheduler-worker-0:/opt/soft <span class="hljs-comment"># with test namespace</span>
</code></pre>
<p>å› ä¸ºå­˜å‚¨å· <code>sharedStoragePersistence</code> è¢«æŒ‚è½½åˆ° <code>/opt/soft</code>, å› æ­¤ <code>/opt/soft</code> ä¸­çš„æ‰€æœ‰æ–‡ä»¶éƒ½ä¸ä¼šä¸¢å¤±</p>
<ol start="5">
<li>ç™»å½•åˆ°å®¹å™¨å¹¶ç¡®ä¿ <code>SPARK_HOME2</code> å­˜åœ¨</li>
</ol>
<pre><code class="language-bash">kubectl <span class="hljs-built_in">exec</span> -it dolphinscheduler-worker-0 bash
kubectl <span class="hljs-built_in">exec</span> -n <span class="hljs-built_in">test</span> -it dolphinscheduler-worker-0 bash <span class="hljs-comment"># with test namespace</span>
<span class="hljs-built_in">cd</span> /opt/soft
tar zxf spark-2.4.7-bin-hadoop2.7.tgz
rm -f spark-2.4.7-bin-hadoop2.7.tgz
ln -s spark-2.4.7-bin-hadoop2.7 spark2 <span class="hljs-comment"># or just mv</span>
<span class="hljs-variable">$SPARK_HOME2</span>/bin/spark-submit --version
</code></pre>
<p>å¦‚æœä¸€åˆ‡æ‰§è¡Œæ­£å¸¸ï¼Œæœ€åä¸€æ¡å‘½ä»¤å°†ä¼šæ‰“å° Spark ç‰ˆæœ¬ä¿¡æ¯</p>
<ol start="6">
<li>åœ¨ä¸€ä¸ª Shell ä»»åŠ¡ä¸‹éªŒè¯ Spark</li>
</ol>
<pre><code>$SPARK_HOME2/bin/spark-submit --class org.apache.spark.examples.SparkPi $SPARK_HOME2/examples/jars/spark-examples_2.11-2.4.7.jar
</code></pre>
<p>æ£€æŸ¥ä»»åŠ¡æ—¥å¿—æ˜¯å¦åŒ…å«è¾“å‡º <code>Pi is roughly 3.146015</code></p>
<ol start="7">
<li>åœ¨ä¸€ä¸ª Spark ä»»åŠ¡ä¸‹éªŒè¯ Spark</li>
</ol>
<p>æ–‡ä»¶ <code>spark-examples_2.11-2.4.7.jar</code> éœ€è¦å…ˆè¢«ä¸Šä¼ åˆ°èµ„æºä¸­å¿ƒï¼Œç„¶ååˆ›å»ºä¸€ä¸ª Spark ä»»åŠ¡å¹¶è®¾ç½®:</p>
<ul>
<li>Sparkç‰ˆæœ¬: <code>SPARK2</code></li>
<li>ä¸»å‡½æ•°çš„Class: <code>org.apache.spark.examples.SparkPi</code></li>
<li>ä¸»ç¨‹åºåŒ…: <code>spark-examples_2.11-2.4.7.jar</code></li>
<li>éƒ¨ç½²æ–¹å¼: <code>local</code></li>
</ul>
<p>åŒæ ·åœ°, æ£€æŸ¥ä»»åŠ¡æ—¥å¿—æ˜¯å¦åŒ…å«è¾“å‡º <code>Pi is roughly 3.146015</code></p>
<ol start="8">
<li>éªŒè¯ Spark on YARN</li>
</ol>
<p>Spark on YARN (éƒ¨ç½²æ–¹å¼ä¸º <code>cluster</code> æˆ– <code>client</code>) éœ€è¦ Hadoop æ”¯æŒ. ç±»ä¼¼äº Spark æ”¯æŒ, æ”¯æŒ Hadoop çš„æ“ä½œå‡ ä¹å’Œå‰é¢çš„æ­¥éª¤ç›¸åŒ</p>
<p>ç¡®ä¿ <code>$HADOOP_HOME</code> å’Œ <code>$HADOOP_CONF_DIR</code> å­˜åœ¨</p>
<h3>å¦‚ä½•æ”¯æŒ Spark 3ï¼Ÿ</h3>
<p>äº‹å®ä¸Šï¼Œä½¿ç”¨ <code>spark-submit</code> æäº¤åº”ç”¨çš„æ–¹å¼æ˜¯ç›¸åŒçš„, æ— è®ºæ˜¯ Spark 1, 2 æˆ– 3. æ¢å¥è¯è¯´ï¼Œ<code>SPARK_HOME2</code> çš„è¯­ä¹‰æ˜¯ç¬¬äºŒä¸ª <code>SPARK_HOME</code>, è€Œé <code>SPARK2</code> çš„ <code>HOME</code>, å› æ­¤åªéœ€è®¾ç½® <code>SPARK_HOME2=/path/to/spark3</code> å³å¯</p>
<p>ä»¥ Spark 3.1.1 ä¸ºä¾‹:</p>
<ol>
<li>
<p>ä¸‹è½½ Spark 3.1.1 å‘å¸ƒçš„äºŒè¿›åˆ¶åŒ… <code>spark-3.1.1-bin-hadoop2.7.tgz</code></p>
</li>
<li>
<p>ç¡®ä¿ <code>common.sharedStoragePersistence.enabled</code> å¼€å¯</p>
</li>
<li>
<p>éƒ¨ç½² dolphinscheduler (è¯¦è§<strong>å®‰è£… dolphinscheduler</strong>)</p>
</li>
<li>
<p>å¤åˆ¶ Spark 3.1.1 äºŒè¿›åˆ¶åŒ…åˆ° Docker å®¹å™¨ä¸­</p>
</li>
</ol>
<pre><code class="language-bash">kubectl cp spark-3.1.1-bin-hadoop2.7.tgz dolphinscheduler-worker-0:/opt/soft
kubectl cp -n <span class="hljs-built_in">test</span> spark-3.1.1-bin-hadoop2.7.tgz dolphinscheduler-worker-0:/opt/soft <span class="hljs-comment"># with test namespace</span>
</code></pre>
<ol start="5">
<li>ç™»å½•åˆ°å®¹å™¨å¹¶ç¡®ä¿ <code>SPARK_HOME2</code> å­˜åœ¨</li>
</ol>
<pre><code class="language-bash">kubectl <span class="hljs-built_in">exec</span> -it dolphinscheduler-worker-0 bash
kubectl <span class="hljs-built_in">exec</span> -n <span class="hljs-built_in">test</span> -it dolphinscheduler-worker-0 bash <span class="hljs-comment"># with test namespace</span>
<span class="hljs-built_in">cd</span> /opt/soft
tar zxf spark-3.1.1-bin-hadoop2.7.tgz
rm -f spark-3.1.1-bin-hadoop2.7.tgz
ln -s spark-3.1.1-bin-hadoop2.7 spark2 <span class="hljs-comment"># or just mv</span>
<span class="hljs-variable">$SPARK_HOME2</span>/bin/spark-submit --version
</code></pre>
<p>å¦‚æœä¸€åˆ‡æ‰§è¡Œæ­£å¸¸ï¼Œæœ€åä¸€æ¡å‘½ä»¤å°†ä¼šæ‰“å° Spark ç‰ˆæœ¬ä¿¡æ¯</p>
<ol start="6">
<li>åœ¨ä¸€ä¸ª Shell ä»»åŠ¡ä¸‹éªŒè¯ Spark</li>
</ol>
<pre><code>$SPARK_HOME2/bin/spark-submit --class org.apache.spark.examples.SparkPi $SPARK_HOME2/examples/jars/spark-examples_2.12-3.1.1.jar
</code></pre>
<p>æ£€æŸ¥ä»»åŠ¡æ—¥å¿—æ˜¯å¦åŒ…å«è¾“å‡º <code>Pi is roughly 3.146015</code></p>
<h3>å¦‚ä½•åœ¨ Masterã€Worker å’Œ Api æœåŠ¡ä¹‹é—´æ”¯æŒå…±äº«å­˜å‚¨ï¼Ÿ</h3>
<p>ä¾‹å¦‚, Masterã€Worker å’Œ Api æœåŠ¡å¯èƒ½åŒæ—¶ä½¿ç”¨ Hadoop</p>
<ol>
<li>ä¿®æ”¹ <code>values.yaml</code> æ–‡ä»¶ä¸­ä¸‹é¢çš„é…ç½®é¡¹</li>
</ol>
<pre><code class="language-yaml"><span class="hljs-attr">common:</span>
  <span class="hljs-attr">sharedStoragePersistence:</span>
    <span class="hljs-attr">enabled:</span> <span class="hljs-literal">false</span>
    <span class="hljs-attr">mountPath:</span> <span class="hljs-string">&quot;/opt/soft&quot;</span>
    <span class="hljs-attr">accessModes:</span>
    <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;ReadWriteMany&quot;</span>
    <span class="hljs-attr">storageClassName:</span> <span class="hljs-string">&quot;-&quot;</span>
    <span class="hljs-attr">storage:</span> <span class="hljs-string">&quot;20Gi&quot;</span>
</code></pre>
<p><code>storageClassName</code> å’Œ <code>storage</code> éœ€è¦è¢«ä¿®æ”¹ä¸ºå®é™…å€¼</p>
<blockquote>
<p><strong>æ³¨æ„</strong>: <code>storageClassName</code> å¿…é¡»æ”¯æŒè®¿é—®æ¨¡å¼: <code>ReadWriteMany</code></p>
</blockquote>
<ol start="2">
<li>
<p>å°† Hadoop å¤åˆ¶åˆ°ç›®å½• <code>/opt/soft</code></p>
</li>
<li>
<p>ç¡®ä¿ <code>$HADOOP_HOME</code> å’Œ <code>$HADOOP_CONF_DIR</code> æ­£ç¡®</p>
</li>
</ol>
<h3>å¦‚ä½•æ”¯æŒæœ¬åœ°æ–‡ä»¶å­˜å‚¨è€Œé HDFS å’Œ S3ï¼Ÿ</h3>
<p>ä¿®æ”¹ <code>values.yaml</code> æ–‡ä»¶ä¸­ä¸‹é¢çš„é…ç½®é¡¹</p>
<pre><code class="language-yaml"><span class="hljs-attr">common:</span>
  <span class="hljs-attr">configmap:</span>
    <span class="hljs-attr">RESOURCE_STORAGE_TYPE:</span> <span class="hljs-string">&quot;HDFS&quot;</span>
    <span class="hljs-attr">RESOURCE_UPLOAD_PATH:</span> <span class="hljs-string">&quot;/dolphinscheduler&quot;</span>
    <span class="hljs-attr">FS_DEFAULT_FS:</span> <span class="hljs-string">&quot;file:///&quot;</span>
  <span class="hljs-attr">fsFileResourcePersistence:</span>
    <span class="hljs-attr">enabled:</span> <span class="hljs-literal">true</span>
    <span class="hljs-attr">accessModes:</span>
    <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;ReadWriteMany&quot;</span>
    <span class="hljs-attr">storageClassName:</span> <span class="hljs-string">&quot;-&quot;</span>
    <span class="hljs-attr">storage:</span> <span class="hljs-string">&quot;20Gi&quot;</span>
</code></pre>
<p><code>storageClassName</code> å’Œ <code>storage</code> éœ€è¦è¢«ä¿®æ”¹ä¸ºå®é™…å€¼</p>
<blockquote>
<p><strong>æ³¨æ„</strong>: <code>storageClassName</code> å¿…é¡»æ”¯æŒè®¿é—®æ¨¡å¼: <code>ReadWriteMany</code></p>
</blockquote>
<h3>å¦‚ä½•æ”¯æŒ S3 èµ„æºå­˜å‚¨ï¼Œä¾‹å¦‚ MinIOï¼Ÿ</h3>
<p>ä»¥ MinIO ä¸ºä¾‹: ä¿®æ”¹ <code>values.yaml</code> æ–‡ä»¶ä¸­ä¸‹é¢çš„é…ç½®é¡¹</p>
<pre><code class="language-yaml"><span class="hljs-attr">common:</span>
  <span class="hljs-attr">configmap:</span>
    <span class="hljs-attr">RESOURCE_STORAGE_TYPE:</span> <span class="hljs-string">&quot;S3&quot;</span>
    <span class="hljs-attr">RESOURCE_UPLOAD_PATH:</span> <span class="hljs-string">&quot;/dolphinscheduler&quot;</span>
    <span class="hljs-attr">FS_DEFAULT_FS:</span> <span class="hljs-string">&quot;s3a://BUCKET_NAME&quot;</span>
    <span class="hljs-attr">FS_S3A_ENDPOINT:</span> <span class="hljs-string">&quot;http://MINIO_IP:9000&quot;</span>
    <span class="hljs-attr">FS_S3A_ACCESS_KEY:</span> <span class="hljs-string">&quot;MINIO_ACCESS_KEY&quot;</span>
    <span class="hljs-attr">FS_S3A_SECRET_KEY:</span> <span class="hljs-string">&quot;MINIO_SECRET_KEY&quot;</span>
</code></pre>
<p><code>BUCKET_NAME</code>, <code>MINIO_IP</code>, <code>MINIO_ACCESS_KEY</code> å’Œ <code>MINIO_SECRET_KEY</code> éœ€è¦è¢«ä¿®æ”¹ä¸ºå®é™…å€¼</p>
<blockquote>
<p><strong>æ³¨æ„</strong>: <code>MINIO_IP</code> åªèƒ½ä½¿ç”¨ IP è€ŒéåŸŸå, å› ä¸º DolphinScheduler å°šä¸æ”¯æŒ S3 è·¯å¾„é£æ ¼è®¿é—® (S3 path style access)</p>
</blockquote>
<h3>å¦‚ä½•é…ç½® SkyWalkingï¼Ÿ</h3>
<p>ä¿®æ”¹ <code>values.yaml</code> æ–‡ä»¶ä¸­çš„ SKYWALKING é…ç½®é¡¹</p>
<pre><code class="language-yaml"><span class="hljs-attr">common:</span>
  <span class="hljs-attr">configmap:</span>
    <span class="hljs-attr">SKYWALKING_ENABLE:</span> <span class="hljs-string">&quot;true&quot;</span>
    <span class="hljs-attr">SW_AGENT_COLLECTOR_BACKEND_SERVICES:</span> <span class="hljs-string">&quot;127.0.0.1:11800&quot;</span>
    <span class="hljs-attr">SW_GRPC_LOG_SERVER_HOST:</span> <span class="hljs-string">&quot;127.0.0.1&quot;</span>
    <span class="hljs-attr">SW_GRPC_LOG_SERVER_PORT:</span> <span class="hljs-string">&quot;11800&quot;</span>
</code></pre>
<h2>é™„å½•-é…ç½®</h2>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>timezone</code></td>
<td>World time and date for cities in all time zones</td>
<td><code>Asia/Shanghai</code></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>image.repository</code></td>
<td>Docker image repository for the DolphinScheduler</td>
<td><code>apache/dolphinscheduler</code></td>
</tr>
<tr>
<td><code>image.tag</code></td>
<td>Docker image version for the DolphinScheduler</td>
<td><code>latest</code></td>
</tr>
<tr>
<td><code>image.pullPolicy</code></td>
<td>Image pull policy. One of Always, Never, IfNotPresent</td>
<td><code>IfNotPresent</code></td>
</tr>
<tr>
<td><code>image.pullSecret</code></td>
<td>Image pull secret. An optional reference to secret in the same namespace to use for pulling any of the images</td>
<td><code>nil</code></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>postgresql.enabled</code></td>
<td>If not exists external PostgreSQL, by default, the DolphinScheduler will use a internal PostgreSQL</td>
<td><code>true</code></td>
</tr>
<tr>
<td><code>postgresql.postgresqlUsername</code></td>
<td>The username for internal PostgreSQL</td>
<td><code>root</code></td>
</tr>
<tr>
<td><code>postgresql.postgresqlPassword</code></td>
<td>The password for internal PostgreSQL</td>
<td><code>root</code></td>
</tr>
<tr>
<td><code>postgresql.postgresqlDatabase</code></td>
<td>The database for internal PostgreSQL</td>
<td><code>dolphinscheduler</code></td>
</tr>
<tr>
<td><code>postgresql.persistence.enabled</code></td>
<td>Set <code>postgresql.persistence.enabled</code> to <code>true</code> to mount a new volume for internal PostgreSQL</td>
<td><code>false</code></td>
</tr>
<tr>
<td><code>postgresql.persistence.size</code></td>
<td><code>PersistentVolumeClaim</code> size</td>
<td><code>20Gi</code></td>
</tr>
<tr>
<td><code>postgresql.persistence.storageClass</code></td>
<td>PostgreSQL data persistent volume storage class. If set to &quot;-&quot;, storageClassName: &quot;&quot;, which disables dynamic provisioning</td>
<td><code>-</code></td>
</tr>
<tr>
<td><code>externalDatabase.type</code></td>
<td>If exists external PostgreSQL, and set <code>postgresql.enabled</code> value to false. DolphinScheduler's database type will use it</td>
<td><code>postgresql</code></td>
</tr>
<tr>
<td><code>externalDatabase.driver</code></td>
<td>If exists external PostgreSQL, and set <code>postgresql.enabled</code> value to false. DolphinScheduler's database driver will use it</td>
<td><code>org.postgresql.Driver</code></td>
</tr>
<tr>
<td><code>externalDatabase.host</code></td>
<td>If exists external PostgreSQL, and set <code>postgresql.enabled</code> value to false. DolphinScheduler's database host will use it</td>
<td><code>localhost</code></td>
</tr>
<tr>
<td><code>externalDatabase.port</code></td>
<td>If exists external PostgreSQL, and set <code>postgresql.enabled</code> value to false. DolphinScheduler's database port will use it</td>
<td><code>5432</code></td>
</tr>
<tr>
<td><code>externalDatabase.username</code></td>
<td>If exists external PostgreSQL, and set <code>postgresql.enabled</code> value to false. DolphinScheduler's database username will use it</td>
<td><code>root</code></td>
</tr>
<tr>
<td><code>externalDatabase.password</code></td>
<td>If exists external PostgreSQL, and set <code>postgresql.enabled</code> value to false. DolphinScheduler's database password will use it</td>
<td><code>root</code></td>
</tr>
<tr>
<td><code>externalDatabase.database</code></td>
<td>If exists external PostgreSQL, and set <code>postgresql.enabled</code> value to false. DolphinScheduler's database database will use it</td>
<td><code>dolphinscheduler</code></td>
</tr>
<tr>
<td><code>externalDatabase.params</code></td>
<td>If exists external PostgreSQL, and set <code>postgresql.enabled</code> value to false. DolphinScheduler's database params will use it</td>
<td><code>characterEncoding=utf8</code></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>zookeeper.enabled</code></td>
<td>If not exists external Zookeeper, by default, the DolphinScheduler will use a internal Zookeeper</td>
<td><code>true</code></td>
</tr>
<tr>
<td><code>zookeeper.fourlwCommandsWhitelist</code></td>
<td>A list of comma separated Four Letter Words commands to use</td>
<td><code>srvr,ruok,wchs,cons</code></td>
</tr>
<tr>
<td><code>zookeeper.persistence.enabled</code></td>
<td>Set <code>zookeeper.persistence.enabled</code> to <code>true</code> to mount a new volume for internal Zookeeper</td>
<td><code>false</code></td>
</tr>
<tr>
<td><code>zookeeper.persistence.size</code></td>
<td><code>PersistentVolumeClaim</code> size</td>
<td><code>20Gi</code></td>
</tr>
<tr>
<td><code>zookeeper.persistence.storageClass</code></td>
<td>Zookeeper data persistent volume storage class. If set to &quot;-&quot;, storageClassName: &quot;&quot;, which disables dynamic provisioning</td>
<td><code>-</code></td>
</tr>
<tr>
<td><code>zookeeper.zookeeperRoot</code></td>
<td>Specify dolphinscheduler root directory in Zookeeper</td>
<td><code>/dolphinscheduler</code></td>
</tr>
<tr>
<td><code>externalZookeeper.zookeeperQuorum</code></td>
<td>If exists external Zookeeper, and set <code>zookeeper.enabled</code> value to false. Specify Zookeeper quorum</td>
<td><code>127.0.0.1:2181</code></td>
</tr>
<tr>
<td><code>externalZookeeper.zookeeperRoot</code></td>
<td>If exists external Zookeeper, and set <code>zookeeper.enabled</code> value to false. Specify dolphinscheduler root directory in Zookeeper</td>
<td><code>/dolphinscheduler</code></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>common.configmap.DOLPHINSCHEDULER_OPTS</code></td>
<td>The jvm options for dolphinscheduler, suitable for all servers</td>
<td><code>&quot;&quot;</code></td>
</tr>
<tr>
<td><code>common.configmap.DATA_BASEDIR_PATH</code></td>
<td>User data directory path, self configuration, please make sure the directory exists and have read write permissions</td>
<td><code>/tmp/dolphinscheduler</code></td>
</tr>
<tr>
<td><code>common.configmap.RESOURCE_STORAGE_TYPE</code></td>
<td>Resource storage type: HDFS, S3, NONE</td>
<td><code>HDFS</code></td>
</tr>
<tr>
<td><code>common.configmap.RESOURCE_UPLOAD_PATH</code></td>
<td>Resource store on HDFS/S3 path, please make sure the directory exists on hdfs and have read write permissions</td>
<td><code>/dolphinscheduler</code></td>
</tr>
<tr>
<td><code>common.configmap.FS_DEFAULT_FS</code></td>
<td>Resource storage file system like <code>file:///</code>, <code>hdfs://mycluster:8020</code> or <code>s3a://dolphinscheduler</code></td>
<td><code>file:///</code></td>
</tr>
<tr>
<td><code>common.configmap.FS_S3A_ENDPOINT</code></td>
<td>S3 endpoint when <code>common.configmap.RESOURCE_STORAGE_TYPE</code> is set to <code>S3</code></td>
<td><code>s3.xxx.amazonaws.com</code></td>
</tr>
<tr>
<td><code>common.configmap.FS_S3A_ACCESS_KEY</code></td>
<td>S3 access key when <code>common.configmap.RESOURCE_STORAGE_TYPE</code> is set to <code>S3</code></td>
<td><code>xxxxxxx</code></td>
</tr>
<tr>
<td><code>common.configmap.FS_S3A_SECRET_KEY</code></td>
<td>S3 secret key when <code>common.configmap.RESOURCE_STORAGE_TYPE</code> is set to <code>S3</code></td>
<td><code>xxxxxxx</code></td>
</tr>
<tr>
<td><code>common.configmap.HADOOP_SECURITY_AUTHENTICATION_STARTUP_STATE</code></td>
<td>Whether to startup kerberos</td>
<td><code>false</code></td>
</tr>
<tr>
<td><code>common.configmap.JAVA_SECURITY_KRB5_CONF_PATH</code></td>
<td>The java.security.krb5.conf path</td>
<td><code>/opt/krb5.conf</code></td>
</tr>
<tr>
<td><code>common.configmap.LOGIN_USER_KEYTAB_USERNAME</code></td>
<td>The login user from keytab username</td>
<td><code>hdfs@HADOOP.COM</code></td>
</tr>
<tr>
<td><code>common.configmap.LOGIN_USER_KEYTAB_PATH</code></td>
<td>The login user from keytab path</td>
<td><code>/opt/hdfs.keytab</code></td>
</tr>
<tr>
<td><code>common.configmap.KERBEROS_EXPIRE_TIME</code></td>
<td>The kerberos expire time, the unit is hour</td>
<td><code>2</code></td>
</tr>
<tr>
<td><code>common.configmap.HDFS_ROOT_USER</code></td>
<td>The HDFS root user who must have the permission to create directories under the HDFS root path</td>
<td><code>hdfs</code></td>
</tr>
<tr>
<td><code>common.configmap.RESOURCE_MANAGER_HTTPADDRESS_PORT</code></td>
<td>Set resource manager httpaddress port for yarn</td>
<td><code>8088</code></td>
</tr>
<tr>
<td><code>common.configmap.YARN_RESOURCEMANAGER_HA_RM_IDS</code></td>
<td>If resourcemanager HA is enabled, please set the HA IPs</td>
<td><code>nil</code></td>
</tr>
<tr>
<td><code>common.configmap.YARN_APPLICATION_STATUS_ADDRESS</code></td>
<td>If resourcemanager is single, you only need to replace ds1 to actual resourcemanager hostname, otherwise keep default</td>
<td><code>http://ds1:%s/ws/v1/cluster/apps/%s</code></td>
</tr>
<tr>
<td><code>common.configmap.SKYWALKING_ENABLE</code></td>
<td>Set whether to enable skywalking</td>
<td><code>false</code></td>
</tr>
<tr>
<td><code>common.configmap.SW_AGENT_COLLECTOR_BACKEND_SERVICES</code></td>
<td>Set agent collector backend services for skywalking</td>
<td><code>127.0.0.1:11800</code></td>
</tr>
<tr>
<td><code>common.configmap.SW_GRPC_LOG_SERVER_HOST</code></td>
<td>Set grpc log server host for skywalking</td>
<td><code>127.0.0.1</code></td>
</tr>
<tr>
<td><code>common.configmap.SW_GRPC_LOG_SERVER_PORT</code></td>
<td>Set grpc log server port for skywalking</td>
<td><code>11800</code></td>
</tr>
<tr>
<td><code>common.configmap.HADOOP_HOME</code></td>
<td>Set <code>HADOOP_HOME</code> for DolphinScheduler's task environment</td>
<td><code>/opt/soft/hadoop</code></td>
</tr>
<tr>
<td><code>common.configmap.HADOOP_CONF_DIR</code></td>
<td>Set <code>HADOOP_CONF_DIR</code> for DolphinScheduler's task environment</td>
<td><code>/opt/soft/hadoop/etc/hadoop</code></td>
</tr>
<tr>
<td><code>common.configmap.SPARK_HOME1</code></td>
<td>Set <code>SPARK_HOME1</code> for DolphinScheduler's task environment</td>
<td><code>/opt/soft/spark1</code></td>
</tr>
<tr>
<td><code>common.configmap.SPARK_HOME2</code></td>
<td>Set <code>SPARK_HOME2</code> for DolphinScheduler's task environment</td>
<td><code>/opt/soft/spark2</code></td>
</tr>
<tr>
<td><code>common.configmap.PYTHON_HOME</code></td>
<td>Set <code>PYTHON_HOME</code> for DolphinScheduler's task environment</td>
<td><code>/usr/bin/python</code></td>
</tr>
<tr>
<td><code>common.configmap.JAVA_HOME</code></td>
<td>Set <code>JAVA_HOME</code> for DolphinScheduler's task environment</td>
<td><code>/usr/local/openjdk-8</code></td>
</tr>
<tr>
<td><code>common.configmap.HIVE_HOME</code></td>
<td>Set <code>HIVE_HOME</code> for DolphinScheduler's task environment</td>
<td><code>/opt/soft/hive</code></td>
</tr>
<tr>
<td><code>common.configmap.FLINK_HOME</code></td>
<td>Set <code>FLINK_HOME</code> for DolphinScheduler's task environment</td>
<td><code>/opt/soft/flink</code></td>
</tr>
<tr>
<td><code>common.configmap.DATAX_HOME</code></td>
<td>Set <code>DATAX_HOME</code> for DolphinScheduler's task environment</td>
<td><code>/opt/soft/datax</code></td>
</tr>
<tr>
<td><code>common.sharedStoragePersistence.enabled</code></td>
<td>Set <code>common.sharedStoragePersistence.enabled</code> to <code>true</code> to mount a shared storage volume for Hadoop, Spark binary and etc</td>
<td><code>false</code></td>
</tr>
<tr>
<td><code>common.sharedStoragePersistence.mountPath</code></td>
<td>The mount path for the shared storage volume</td>
<td><code>/opt/soft</code></td>
</tr>
<tr>
<td><code>common.sharedStoragePersistence.accessModes</code></td>
<td><code>PersistentVolumeClaim</code> access modes, must be <code>ReadWriteMany</code></td>
<td><code>[ReadWriteMany]</code></td>
</tr>
<tr>
<td><code>common.sharedStoragePersistence.storageClassName</code></td>
<td>Shared Storage persistent volume storage class, must support the access mode: ReadWriteMany</td>
<td><code>-</code></td>
</tr>
<tr>
<td><code>common.sharedStoragePersistence.storage</code></td>
<td><code>PersistentVolumeClaim</code> size</td>
<td><code>20Gi</code></td>
</tr>
<tr>
<td><code>common.fsFileResourcePersistence.enabled</code></td>
<td>Set <code>common.fsFileResourcePersistence.enabled</code> to <code>true</code> to mount a new file resource volume for <code>api</code> and <code>worker</code></td>
<td><code>false</code></td>
</tr>
<tr>
<td><code>common.fsFileResourcePersistence.accessModes</code></td>
<td><code>PersistentVolumeClaim</code> access modes, must be <code>ReadWriteMany</code></td>
<td><code>[ReadWriteMany]</code></td>
</tr>
<tr>
<td><code>common.fsFileResourcePersistence.storageClassName</code></td>
<td>Resource persistent volume storage class, must support the access mode: ReadWriteMany</td>
<td><code>-</code></td>
</tr>
<tr>
<td><code>common.fsFileResourcePersistence.storage</code></td>
<td><code>PersistentVolumeClaim</code> size</td>
<td><code>20Gi</code></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>master.podManagementPolicy</code></td>
<td>PodManagementPolicy controls how pods are created during initial scale up, when replacing pods on nodes, or when scaling down</td>
<td><code>Parallel</code></td>
</tr>
<tr>
<td><code>master.replicas</code></td>
<td>Replicas is the desired number of replicas of the given Template</td>
<td><code>3</code></td>
</tr>
<tr>
<td><code>master.annotations</code></td>
<td>The <code>annotations</code> for master server</td>
<td><code>{}</code></td>
</tr>
<tr>
<td><code>master.affinity</code></td>
<td>If specified, the pod's scheduling constraints</td>
<td><code>{}</code></td>
</tr>
<tr>
<td><code>master.nodeSelector</code></td>
<td>NodeSelector is a selector which must be true for the pod to fit on a node</td>
<td><code>{}</code></td>
</tr>
<tr>
<td><code>master.tolerations</code></td>
<td>If specified, the pod's tolerations</td>
<td><code>{}</code></td>
</tr>
<tr>
<td><code>master.resources</code></td>
<td>The <code>resource</code> limit and request config for master server</td>
<td><code>{}</code></td>
</tr>
<tr>
<td><code>master.configmap.MASTER_SERVER_OPTS</code></td>
<td>The jvm options for master server</td>
<td><code>-Xms1g -Xmx1g -Xmn512m</code></td>
</tr>
<tr>
<td><code>master.configmap.MASTER_EXEC_THREADS</code></td>
<td>Master execute thread number to limit process instances</td>
<td><code>100</code></td>
</tr>
<tr>
<td><code>master.configmap.MASTER_EXEC_TASK_NUM</code></td>
<td>Master execute task number in parallel per process instance</td>
<td><code>20</code></td>
</tr>
<tr>
<td><code>master.configmap.MASTER_DISPATCH_TASK_NUM</code></td>
<td>Master dispatch task number per batch</td>
<td><code>3</code></td>
</tr>
<tr>
<td><code>master.configmap.MASTER_HOST_SELECTOR</code></td>
<td>Master host selector to select a suitable worker, optional values include Random, RoundRobin, LowerWeight</td>
<td><code>LowerWeight</code></td>
</tr>
<tr>
<td><code>master.configmap.MASTER_HEARTBEAT_INTERVAL</code></td>
<td>Master heartbeat interval, the unit is second</td>
<td><code>10</code></td>
</tr>
<tr>
<td><code>master.configmap.MASTER_TASK_COMMIT_RETRYTIMES</code></td>
<td>Master commit task retry times</td>
<td><code>5</code></td>
</tr>
<tr>
<td><code>master.configmap.MASTER_TASK_COMMIT_INTERVAL</code></td>
<td>master commit task interval, the unit is second</td>
<td><code>1</code></td>
</tr>
<tr>
<td><code>master.configmap.MASTER_MAX_CPULOAD_AVG</code></td>
<td>Master max cpuload avg, only higher than the system cpu load average, master server can schedule</td>
<td><code>-1</code> (<code>the number of cpu cores * 2</code>)</td>
</tr>
<tr>
<td><code>master.configmap.MASTER_RESERVED_MEMORY</code></td>
<td>Master reserved memory, only lower than system available memory, master server can schedule, the unit is G</td>
<td><code>0.3</code></td>
</tr>
<tr>
<td><code>master.livenessProbe.enabled</code></td>
<td>Turn on and off liveness probe</td>
<td><code>true</code></td>
</tr>
<tr>
<td><code>master.livenessProbe.initialDelaySeconds</code></td>
<td>Delay before liveness probe is initiated</td>
<td><code>30</code></td>
</tr>
<tr>
<td><code>master.livenessProbe.periodSeconds</code></td>
<td>How often to perform the probe</td>
<td><code>30</code></td>
</tr>
<tr>
<td><code>master.livenessProbe.timeoutSeconds</code></td>
<td>When the probe times out</td>
<td><code>5</code></td>
</tr>
<tr>
<td><code>master.livenessProbe.failureThreshold</code></td>
<td>Minimum consecutive successes for the probe</td>
<td><code>3</code></td>
</tr>
<tr>
<td><code>master.livenessProbe.successThreshold</code></td>
<td>Minimum consecutive failures for the probe</td>
<td><code>1</code></td>
</tr>
<tr>
<td><code>master.readinessProbe.enabled</code></td>
<td>Turn on and off readiness probe</td>
<td><code>true</code></td>
</tr>
<tr>
<td><code>master.readinessProbe.initialDelaySeconds</code></td>
<td>Delay before readiness probe is initiated</td>
<td><code>30</code></td>
</tr>
<tr>
<td><code>master.readinessProbe.periodSeconds</code></td>
<td>How often to perform the probe</td>
<td><code>30</code></td>
</tr>
<tr>
<td><code>master.readinessProbe.timeoutSeconds</code></td>
<td>When the probe times out</td>
<td><code>5</code></td>
</tr>
<tr>
<td><code>master.readinessProbe.failureThreshold</code></td>
<td>Minimum consecutive successes for the probe</td>
<td><code>3</code></td>
</tr>
<tr>
<td><code>master.readinessProbe.successThreshold</code></td>
<td>Minimum consecutive failures for the probe</td>
<td><code>1</code></td>
</tr>
<tr>
<td><code>master.persistentVolumeClaim.enabled</code></td>
<td>Set <code>master.persistentVolumeClaim.enabled</code> to <code>true</code> to mount a new volume for <code>master</code></td>
<td><code>false</code></td>
</tr>
<tr>
<td><code>master.persistentVolumeClaim.accessModes</code></td>
<td><code>PersistentVolumeClaim</code> access modes</td>
<td><code>[ReadWriteOnce]</code></td>
</tr>
<tr>
<td><code>master.persistentVolumeClaim.storageClassName</code></td>
<td><code>Master</code> logs data persistent volume storage class. If set to &quot;-&quot;, storageClassName: &quot;&quot;, which disables dynamic provisioning</td>
<td><code>-</code></td>
</tr>
<tr>
<td><code>master.persistentVolumeClaim.storage</code></td>
<td><code>PersistentVolumeClaim</code> size</td>
<td><code>20Gi</code></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>worker.podManagementPolicy</code></td>
<td>PodManagementPolicy controls how pods are created during initial scale up, when replacing pods on nodes, or when scaling down</td>
<td><code>Parallel</code></td>
</tr>
<tr>
<td><code>worker.replicas</code></td>
<td>Replicas is the desired number of replicas of the given Template</td>
<td><code>3</code></td>
</tr>
<tr>
<td><code>worker.annotations</code></td>
<td>The <code>annotations</code> for worker server</td>
<td><code>{}</code></td>
</tr>
<tr>
<td><code>worker.affinity</code></td>
<td>If specified, the pod's scheduling constraints</td>
<td><code>{}</code></td>
</tr>
<tr>
<td><code>worker.nodeSelector</code></td>
<td>NodeSelector is a selector which must be true for the pod to fit on a node</td>
<td><code>{}</code></td>
</tr>
<tr>
<td><code>worker.tolerations</code></td>
<td>If specified, the pod's tolerations</td>
<td><code>{}</code></td>
</tr>
<tr>
<td><code>worker.resources</code></td>
<td>The <code>resource</code> limit and request config for worker server</td>
<td><code>{}</code></td>
</tr>
<tr>
<td><code>worker.configmap.WORKER_SERVER_OPTS</code></td>
<td>The jvm options for worker server</td>
<td><code>-Xms1g -Xmx1g -Xmn512m</code></td>
</tr>
<tr>
<td><code>worker.configmap.WORKER_EXEC_THREADS</code></td>
<td>Worker execute thread number to limit task instances</td>
<td><code>100</code></td>
</tr>
<tr>
<td><code>worker.configmap.WORKER_HEARTBEAT_INTERVAL</code></td>
<td>Worker heartbeat interval, the unit is second</td>
<td><code>10</code></td>
</tr>
<tr>
<td><code>worker.configmap.WORKER_MAX_CPULOAD_AVG</code></td>
<td>Worker max cpuload avg, only higher than the system cpu load average, worker server can be dispatched tasks</td>
<td><code>-1</code> (<code>the number of cpu cores * 2</code>)</td>
</tr>
<tr>
<td><code>worker.configmap.WORKER_RESERVED_MEMORY</code></td>
<td>Worker reserved memory, only lower than system available memory, worker server can be dispatched tasks, the unit is G</td>
<td><code>0.3</code></td>
</tr>
<tr>
<td><code>worker.configmap.WORKER_GROUPS</code></td>
<td>Worker groups</td>
<td><code>default</code></td>
</tr>
<tr>
<td><code>worker.livenessProbe.enabled</code></td>
<td>Turn on and off liveness probe</td>
<td><code>true</code></td>
</tr>
<tr>
<td><code>worker.livenessProbe.initialDelaySeconds</code></td>
<td>Delay before liveness probe is initiated</td>
<td><code>30</code></td>
</tr>
<tr>
<td><code>worker.livenessProbe.periodSeconds</code></td>
<td>How often to perform the probe</td>
<td><code>30</code></td>
</tr>
<tr>
<td><code>worker.livenessProbe.timeoutSeconds</code></td>
<td>When the probe times out</td>
<td><code>5</code></td>
</tr>
<tr>
<td><code>worker.livenessProbe.failureThreshold</code></td>
<td>Minimum consecutive successes for the probe</td>
<td><code>3</code></td>
</tr>
<tr>
<td><code>worker.livenessProbe.successThreshold</code></td>
<td>Minimum consecutive failures for the probe</td>
<td><code>1</code></td>
</tr>
<tr>
<td><code>worker.readinessProbe.enabled</code></td>
<td>Turn on and off readiness probe</td>
<td><code>true</code></td>
</tr>
<tr>
<td><code>worker.readinessProbe.initialDelaySeconds</code></td>
<td>Delay before readiness probe is initiated</td>
<td><code>30</code></td>
</tr>
<tr>
<td><code>worker.readinessProbe.periodSeconds</code></td>
<td>How often to perform the probe</td>
<td><code>30</code></td>
</tr>
<tr>
<td><code>worker.readinessProbe.timeoutSeconds</code></td>
<td>When the probe times out</td>
<td><code>5</code></td>
</tr>
<tr>
<td><code>worker.readinessProbe.failureThreshold</code></td>
<td>Minimum consecutive successes for the probe</td>
<td><code>3</code></td>
</tr>
<tr>
<td><code>worker.readinessProbe.successThreshold</code></td>
<td>Minimum consecutive failures for the probe</td>
<td><code>1</code></td>
</tr>
<tr>
<td><code>worker.persistentVolumeClaim.enabled</code></td>
<td>Set <code>worker.persistentVolumeClaim.enabled</code> to <code>true</code> to enable <code>persistentVolumeClaim</code> for <code>worker</code></td>
<td><code>false</code></td>
</tr>
<tr>
<td><code>worker.persistentVolumeClaim.dataPersistentVolume.enabled</code></td>
<td>Set <code>worker.persistentVolumeClaim.dataPersistentVolume.enabled</code> to <code>true</code> to mount a data volume for <code>worker</code></td>
<td><code>false</code></td>
</tr>
<tr>
<td><code>worker.persistentVolumeClaim.dataPersistentVolume.accessModes</code></td>
<td><code>PersistentVolumeClaim</code> access modes</td>
<td><code>[ReadWriteOnce]</code></td>
</tr>
<tr>
<td><code>worker.persistentVolumeClaim.dataPersistentVolume.storageClassName</code></td>
<td><code>Worker</code> data persistent volume storage class. If set to &quot;-&quot;, storageClassName: &quot;&quot;, which disables dynamic provisioning</td>
<td><code>-</code></td>
</tr>
<tr>
<td><code>worker.persistentVolumeClaim.dataPersistentVolume.storage</code></td>
<td><code>PersistentVolumeClaim</code> size</td>
<td><code>20Gi</code></td>
</tr>
<tr>
<td><code>worker.persistentVolumeClaim.logsPersistentVolume.enabled</code></td>
<td>Set <code>worker.persistentVolumeClaim.logsPersistentVolume.enabled</code> to <code>true</code> to mount a logs volume for <code>worker</code></td>
<td><code>false</code></td>
</tr>
<tr>
<td><code>worker.persistentVolumeClaim.logsPersistentVolume.accessModes</code></td>
<td><code>PersistentVolumeClaim</code> access modes</td>
<td><code>[ReadWriteOnce]</code></td>
</tr>
<tr>
<td><code>worker.persistentVolumeClaim.logsPersistentVolume.storageClassName</code></td>
<td><code>Worker</code> logs data persistent volume storage class. If set to &quot;-&quot;, storageClassName: &quot;&quot;, which disables dynamic provisioning</td>
<td><code>-</code></td>
</tr>
<tr>
<td><code>worker.persistentVolumeClaim.logsPersistentVolume.storage</code></td>
<td><code>PersistentVolumeClaim</code> size</td>
<td><code>20Gi</code></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>alert.replicas</code></td>
<td>Replicas is the desired number of replicas of the given Template</td>
<td><code>1</code></td>
</tr>
<tr>
<td><code>alert.strategy.type</code></td>
<td>Type of deployment. Can be &quot;Recreate&quot; or &quot;RollingUpdate&quot;</td>
<td><code>RollingUpdate</code></td>
</tr>
<tr>
<td><code>alert.strategy.rollingUpdate.maxSurge</code></td>
<td>The maximum number of pods that can be scheduled above the desired number of pods</td>
<td><code>25%</code></td>
</tr>
<tr>
<td><code>alert.strategy.rollingUpdate.maxUnavailable</code></td>
<td>The maximum number of pods that can be unavailable during the update</td>
<td><code>25%</code></td>
</tr>
<tr>
<td><code>alert.annotations</code></td>
<td>The <code>annotations</code> for alert server</td>
<td><code>{}</code></td>
</tr>
<tr>
<td><code>alert.affinity</code></td>
<td>If specified, the pod's scheduling constraints</td>
<td><code>{}</code></td>
</tr>
<tr>
<td><code>alert.nodeSelector</code></td>
<td>NodeSelector is a selector which must be true for the pod to fit on a node</td>
<td><code>{}</code></td>
</tr>
<tr>
<td><code>alert.tolerations</code></td>
<td>If specified, the pod's tolerations</td>
<td><code>{}</code></td>
</tr>
<tr>
<td><code>alert.resources</code></td>
<td>The <code>resource</code> limit and request config for alert server</td>
<td><code>{}</code></td>
</tr>
<tr>
<td><code>alert.configmap.ALERT_SERVER_OPTS</code></td>
<td>The jvm options for alert server</td>
<td><code>-Xms512m -Xmx512m -Xmn256m</code></td>
</tr>
<tr>
<td><code>alert.configmap.XLS_FILE_PATH</code></td>
<td>XLS file path</td>
<td><code>/tmp/xls</code></td>
</tr>
<tr>
<td><code>alert.configmap.MAIL_SERVER_HOST</code></td>
<td>Mail <code>SERVER HOST</code></td>
<td><code>nil</code></td>
</tr>
<tr>
<td><code>alert.configmap.MAIL_SERVER_PORT</code></td>
<td>Mail <code>SERVER PORT</code></td>
<td><code>nil</code></td>
</tr>
<tr>
<td><code>alert.configmap.MAIL_SENDER</code></td>
<td>Mail <code>SENDER</code></td>
<td><code>nil</code></td>
</tr>
<tr>
<td><code>alert.configmap.MAIL_USER</code></td>
<td>Mail <code>USER</code></td>
<td><code>nil</code></td>
</tr>
<tr>
<td><code>alert.configmap.MAIL_PASSWD</code></td>
<td>Mail <code>PASSWORD</code></td>
<td><code>nil</code></td>
</tr>
<tr>
<td><code>alert.configmap.MAIL_SMTP_STARTTLS_ENABLE</code></td>
<td>Mail <code>SMTP STARTTLS</code> enable</td>
<td><code>false</code></td>
</tr>
<tr>
<td><code>alert.configmap.MAIL_SMTP_SSL_ENABLE</code></td>
<td>Mail <code>SMTP SSL</code> enable</td>
<td><code>false</code></td>
</tr>
<tr>
<td><code>alert.configmap.MAIL_SMTP_SSL_TRUST</code></td>
<td>Mail <code>SMTP SSL TRUST</code></td>
<td><code>nil</code></td>
</tr>
<tr>
<td><code>alert.configmap.ENTERPRISE_WECHAT_ENABLE</code></td>
<td><code>Enterprise Wechat</code> enable</td>
<td><code>false</code></td>
</tr>
<tr>
<td><code>alert.configmap.ENTERPRISE_WECHAT_CORP_ID</code></td>
<td><code>Enterprise Wechat</code> corp id</td>
<td><code>nil</code></td>
</tr>
<tr>
<td><code>alert.configmap.ENTERPRISE_WECHAT_SECRET</code></td>
<td><code>Enterprise Wechat</code> secret</td>
<td><code>nil</code></td>
</tr>
<tr>
<td><code>alert.configmap.ENTERPRISE_WECHAT_AGENT_ID</code></td>
<td><code>Enterprise Wechat</code> agent id</td>
<td><code>nil</code></td>
</tr>
<tr>
<td><code>alert.configmap.ENTERPRISE_WECHAT_USERS</code></td>
<td><code>Enterprise Wechat</code> users</td>
<td><code>nil</code></td>
</tr>
<tr>
<td><code>alert.livenessProbe.enabled</code></td>
<td>Turn on and off liveness probe</td>
<td><code>true</code></td>
</tr>
<tr>
<td><code>alert.livenessProbe.initialDelaySeconds</code></td>
<td>Delay before liveness probe is initiated</td>
<td><code>30</code></td>
</tr>
<tr>
<td><code>alert.livenessProbe.periodSeconds</code></td>
<td>How often to perform the probe</td>
<td><code>30</code></td>
</tr>
<tr>
<td><code>alert.livenessProbe.timeoutSeconds</code></td>
<td>When the probe times out</td>
<td><code>5</code></td>
</tr>
<tr>
<td><code>alert.livenessProbe.failureThreshold</code></td>
<td>Minimum consecutive successes for the probe</td>
<td><code>3</code></td>
</tr>
<tr>
<td><code>alert.livenessProbe.successThreshold</code></td>
<td>Minimum consecutive failures for the probe</td>
<td><code>1</code></td>
</tr>
<tr>
<td><code>alert.readinessProbe.enabled</code></td>
<td>Turn on and off readiness probe</td>
<td><code>true</code></td>
</tr>
<tr>
<td><code>alert.readinessProbe.initialDelaySeconds</code></td>
<td>Delay before readiness probe is initiated</td>
<td><code>30</code></td>
</tr>
<tr>
<td><code>alert.readinessProbe.periodSeconds</code></td>
<td>How often to perform the probe</td>
<td><code>30</code></td>
</tr>
<tr>
<td><code>alert.readinessProbe.timeoutSeconds</code></td>
<td>When the probe times out</td>
<td><code>5</code></td>
</tr>
<tr>
<td><code>alert.readinessProbe.failureThreshold</code></td>
<td>Minimum consecutive successes for the probe</td>
<td><code>3</code></td>
</tr>
<tr>
<td><code>alert.readinessProbe.successThreshold</code></td>
<td>Minimum consecutive failures for the probe</td>
<td><code>1</code></td>
</tr>
<tr>
<td><code>alert.persistentVolumeClaim.enabled</code></td>
<td>Set <code>alert.persistentVolumeClaim.enabled</code> to <code>true</code> to mount a new volume for <code>alert</code></td>
<td><code>false</code></td>
</tr>
<tr>
<td><code>alert.persistentVolumeClaim.accessModes</code></td>
<td><code>PersistentVolumeClaim</code> access modes</td>
<td><code>[ReadWriteOnce]</code></td>
</tr>
<tr>
<td><code>alert.persistentVolumeClaim.storageClassName</code></td>
<td><code>Alert</code> logs data persistent volume storage class. If set to &quot;-&quot;, storageClassName: &quot;&quot;, which disables dynamic provisioning</td>
<td><code>-</code></td>
</tr>
<tr>
<td><code>alert.persistentVolumeClaim.storage</code></td>
<td><code>PersistentVolumeClaim</code> size</td>
<td><code>20Gi</code></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>api.replicas</code></td>
<td>Replicas is the desired number of replicas of the given Template</td>
<td><code>1</code></td>
</tr>
<tr>
<td><code>api.strategy.type</code></td>
<td>Type of deployment. Can be &quot;Recreate&quot; or &quot;RollingUpdate&quot;</td>
<td><code>RollingUpdate</code></td>
</tr>
<tr>
<td><code>api.strategy.rollingUpdate.maxSurge</code></td>
<td>The maximum number of pods that can be scheduled above the desired number of pods</td>
<td><code>25%</code></td>
</tr>
<tr>
<td><code>api.strategy.rollingUpdate.maxUnavailable</code></td>
<td>The maximum number of pods that can be unavailable during the update</td>
<td><code>25%</code></td>
</tr>
<tr>
<td><code>api.annotations</code></td>
<td>The <code>annotations</code> for api server</td>
<td><code>{}</code></td>
</tr>
<tr>
<td><code>api.affinity</code></td>
<td>If specified, the pod's scheduling constraints</td>
<td><code>{}</code></td>
</tr>
<tr>
<td><code>api.nodeSelector</code></td>
<td>NodeSelector is a selector which must be true for the pod to fit on a node</td>
<td><code>{}</code></td>
</tr>
<tr>
<td><code>api.tolerations</code></td>
<td>If specified, the pod's tolerations</td>
<td><code>{}</code></td>
</tr>
<tr>
<td><code>api.resources</code></td>
<td>The <code>resource</code> limit and request config for api server</td>
<td><code>{}</code></td>
</tr>
<tr>
<td><code>api.configmap.API_SERVER_OPTS</code></td>
<td>The jvm options for api server</td>
<td><code>-Xms512m -Xmx512m -Xmn256m</code></td>
</tr>
<tr>
<td><code>api.livenessProbe.enabled</code></td>
<td>Turn on and off liveness probe</td>
<td><code>true</code></td>
</tr>
<tr>
<td><code>api.livenessProbe.initialDelaySeconds</code></td>
<td>Delay before liveness probe is initiated</td>
<td><code>30</code></td>
</tr>
<tr>
<td><code>api.livenessProbe.periodSeconds</code></td>
<td>How often to perform the probe</td>
<td><code>30</code></td>
</tr>
<tr>
<td><code>api.livenessProbe.timeoutSeconds</code></td>
<td>When the probe times out</td>
<td><code>5</code></td>
</tr>
<tr>
<td><code>api.livenessProbe.failureThreshold</code></td>
<td>Minimum consecutive successes for the probe</td>
<td><code>3</code></td>
</tr>
<tr>
<td><code>api.livenessProbe.successThreshold</code></td>
<td>Minimum consecutive failures for the probe</td>
<td><code>1</code></td>
</tr>
<tr>
<td><code>api.readinessProbe.enabled</code></td>
<td>Turn on and off readiness probe</td>
<td><code>true</code></td>
</tr>
<tr>
<td><code>api.readinessProbe.initialDelaySeconds</code></td>
<td>Delay before readiness probe is initiated</td>
<td><code>30</code></td>
</tr>
<tr>
<td><code>api.readinessProbe.periodSeconds</code></td>
<td>How often to perform the probe</td>
<td><code>30</code></td>
</tr>
<tr>
<td><code>api.readinessProbe.timeoutSeconds</code></td>
<td>When the probe times out</td>
<td><code>5</code></td>
</tr>
<tr>
<td><code>api.readinessProbe.failureThreshold</code></td>
<td>Minimum consecutive successes for the probe</td>
<td><code>3</code></td>
</tr>
<tr>
<td><code>api.readinessProbe.successThreshold</code></td>
<td>Minimum consecutive failures for the probe</td>
<td><code>1</code></td>
</tr>
<tr>
<td><code>api.persistentVolumeClaim.enabled</code></td>
<td>Set <code>api.persistentVolumeClaim.enabled</code> to <code>true</code> to mount a new volume for <code>api</code></td>
<td><code>false</code></td>
</tr>
<tr>
<td><code>api.persistentVolumeClaim.accessModes</code></td>
<td><code>PersistentVolumeClaim</code> access modes</td>
<td><code>[ReadWriteOnce]</code></td>
</tr>
<tr>
<td><code>api.persistentVolumeClaim.storageClassName</code></td>
<td><code>api</code> logs data persistent volume storage class. If set to &quot;-&quot;, storageClassName: &quot;&quot;, which disables dynamic provisioning</td>
<td><code>-</code></td>
</tr>
<tr>
<td><code>api.persistentVolumeClaim.storage</code></td>
<td><code>PersistentVolumeClaim</code> size</td>
<td><code>20Gi</code></td>
</tr>
<tr>
<td><code>api.service.type</code></td>
<td><code>type</code> determines how the Service is exposed. Valid options are ExternalName, ClusterIP, NodePort, and LoadBalancer</td>
<td><code>ClusterIP</code></td>
</tr>
<tr>
<td><code>api.service.clusterIP</code></td>
<td><code>clusterIP</code> is the IP address of the service and is usually assigned randomly by the master</td>
<td><code>nil</code></td>
</tr>
<tr>
<td><code>api.service.nodePort</code></td>
<td><code>nodePort</code> is the port on each node on which this service is exposed when type=NodePort</td>
<td><code>nil</code></td>
</tr>
<tr>
<td><code>api.service.externalIPs</code></td>
<td><code>externalIPs</code> is a list of IP addresses for which nodes in the cluster will also accept traffic for this service</td>
<td><code>[]</code></td>
</tr>
<tr>
<td><code>api.service.externalName</code></td>
<td><code>externalName</code> is the external reference that kubedns or equivalent will return as a CNAME record for this service</td>
<td><code>nil</code></td>
</tr>
<tr>
<td><code>api.service.loadBalancerIP</code></td>
<td><code>loadBalancerIP</code> when service.type is LoadBalancer. LoadBalancer will get created with the IP specified in this field</td>
<td><code>nil</code></td>
</tr>
<tr>
<td><code>api.service.annotations</code></td>
<td><code>annotations</code> may need to be set when service.type is LoadBalancer</td>
<td><code>{}</code></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>ingress.enabled</code></td>
<td>Enable ingress</td>
<td><code>false</code></td>
</tr>
<tr>
<td><code>ingress.host</code></td>
<td>Ingress host</td>
<td><code>dolphinscheduler.org</code></td>
</tr>
<tr>
<td><code>ingress.path</code></td>
<td>Ingress path</td>
<td><code>/dolphinscheduler</code></td>
</tr>
<tr>
<td><code>ingress.tls.enabled</code></td>
<td>Enable ingress tls</td>
<td><code>false</code></td>
</tr>
<tr>
<td><code>ingress.tls.secretName</code></td>
<td>Ingress tls secret name</td>
<td><code>dolphinscheduler-tls</code></td>
</tr>
</tbody>
</table>
</div></section><footer class="footer-container"><div class="footer-body"><div><h3>è”ç³»æˆ‘ä»¬</h3><h4>æœ‰é—®é¢˜éœ€è¦åé¦ˆï¼Ÿè¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼è”ç³»æˆ‘ä»¬ã€‚</h4></div><div class="contact-container"><ul><li><a href="/zh-cn/community/development/subscribe.html"><img class="img-base" src="/img/emailgray.png"/><img class="img-change" src="/img/emailblue.png"/><p>é‚®ä»¶åˆ—è¡¨</p></a></li><li><a href="https://twitter.com/dolphinschedule"><img class="img-base" src="/img/twittergray.png"/><img class="img-change" src="/img/twitterblue.png"/><p>Twitter</p></a></li><li><a href="https://stackoverflow.com/questions/tagged/apache-dolphinscheduler"><img class="img-base" src="/img/stackoverflow.png"/><img class="img-change" src="/img/stackoverflow-selected.png"/><p>Stack Overflow</p></a></li><li><a href="https://s.apache.org/dolphinscheduler-slack"><img class="img-base" src="/img/slack.png"/><img class="img-change" src="/img/slack-selected.png"/><p>Slack</p></a></li></ul></div><div class="cols-container"><div class="docu-container"><h4>æ–‡æ¡£</h4><ul><li><a href="/zh-cn/development/architecture-design.html"><p>æ¦‚è§ˆ</p></a></li><li><a href="/zh-cn/docs/latest/user_doc/guide/quick-start.html"><p>å¿«é€Ÿå¼€å§‹</p></a></li><li><a href="/zh-cn/development/development-environment-setup.html"><p>å¼€å‘è€…æŒ‡å—</p></a></li></ul></div><div></div><div class="asf-container"><h4>ASF</h4><ul><li><a href="http://www.apache.org"><p>åŸºé‡‘ä¼š</p></a></li><li><a href="http://www.apache.org/licenses/"><p>è¯ä¹¦</p></a></li><li><a href="http://www.apache.org/events/current-event"><p>äº‹ä»¶</p></a></li><li><a href="http://www.apache.org/foundation/sponsorship.html"><p>èµåŠ©</p></a></li><li><a href="http://www.apache.org/foundation/thanks.html"><p>è‡´è°¢</p></a></li></ul></div></div><div class="copyright"><span>Copyright Â© 2019-2021 The Apache Software Foundation. Apache DolphinScheduler, DolphinScheduler, and its feather logo are trademarks of The Apache Software Foundation.</span></div></div></footer></div></div>
  <script src="/asset/js/react/react-with-addons.min.js"></script>
  <script src="/asset/js/react/react-dom.min.js"></script>
  <script>window.rootPath = '';</script>
  <script src="/build/vendor.3e36ada.js"></script>
  <script src="/build/docs.md.000d526.js"></script>
  <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?d6bc736fd9885d9a5dc938425ac062ad";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-899J8PYKJZ"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-899J8PYKJZ');
  </script>
</body>
</html>