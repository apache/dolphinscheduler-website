{
  "filename": "faq.md",
  "__html": "<h2>Q：DolphinScheduler服务介绍及建议运行内存</h2>\n<p>A： DolphinScheduler由5个服务组成，MasterServer、WorkerServer、ApiServer、AlertServer、LoggerServer和UI。</p>\n<table>\n<thead>\n<tr>\n<th>服务</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>MasterServer</td>\n<td>主要负责 <strong>DAG</strong> 的切分和任务状态的监控</td>\n</tr>\n<tr>\n<td>WorkerServer/LoggerServer</td>\n<td>主要负责任务的提交、执行和任务状态的更新。LoggerServer用于Rest Api通过 <strong>RPC</strong> 查看日志</td>\n</tr>\n<tr>\n<td>ApiServer</td>\n<td>提供Rest Api服务，供UI进行调用</td>\n</tr>\n<tr>\n<td>AlertServer</td>\n<td>提供告警服务</td>\n</tr>\n<tr>\n<td>UI</td>\n<td>前端页面展示</td>\n</tr>\n</tbody>\n</table>\n<p>注意：<strong>由于服务比较多，建议单机部署最好是4核16G以上</strong></p>\n<hr>\n<h2>Q： 管理员为什么不能创建项目</h2>\n<p>A：管理员目前属于&quot;<strong>纯管理</strong>&quot;, 没有租户，即没有linux上对应的用户，所以没有执行权限,  <strong>故没有所属的项目、资源及数据源</strong>，所以没有创建权限。<strong>但是有所有的查看权限</strong>。如果需要创建项目等业务操作，<strong>请使用管理员创建租户和普通用户，然后使用普通用户登录进行操作</strong>。我们将会在1.1.0版本中将管理员的创建和执行权限放开，管理员将会有所有的权限</p>\n<hr>\n<h2>Q：系统支持哪些邮箱？</h2>\n<p>A：支持绝大多数邮箱，qq、163、126、139、outlook、aliyun等皆支持。支持<strong>TLS和SSL</strong>协议，可以在alert.properties中选择性配置</p>\n<hr>\n<h2>Q：常用的系统变量时间参数有哪些，如何使用？</h2>\n<p>A：请参考 使用手册</p>\n<hr>\n<h2>Q：pip install kazoo 这个安装报错。是必须安装的吗？</h2>\n<p>A： 这个是python连接zookeeper需要使用到的，必须要安装</p>\n<hr>\n<h2>Q: 怎么指定机器运行任务</h2>\n<p>A：使用 <strong>管理员</strong> 创建Worker分组，在 <strong>流程定义启动</strong> 的时候可<strong>指定Worker分组</strong>或者在<strong>任务节点上指定Worker分组</strong>。如果不指定，则使用Default，<strong>Default默认是使用的集群里所有的Worker中随机选取一台来进行任务提交、执行</strong></p>\n<hr>\n<h2>Q：任务的优先级</h2>\n<p>A：我们同时 <strong>支持流程和任务的优先级</strong>。优先级我们有 <strong>HIGHEST、HIGH、MEDIUM、LOW和LOWEST</strong> 五种级别。<strong>可以设置不同流程实例之间的优先级，也可以设置同一个流程实例中不同任务实例的优先级</strong>。详细内容请参考任务优先级设计 <a href=\"https://analysys.github.io/easyscheduler_docs_cn/%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1.html#%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1\">https://analysys.github.io/easyscheduler_docs_cn/系统架构设计.html#系统架构设计</a></p>\n<hr>\n<h2>Q：dolphinscheduler-grpc报错</h2>\n<p>A：在根目录下执行：mvn -U clean package assembly:assembly -Dmaven.test.skip=true ， 然后刷新下整个项目</p>\n<hr>\n<h2>Q：DolphinScheduler支持windows上运行么</h2>\n<p>A： 理论上只有<strong>Worker是需要在Linux上运行的</strong>，其它的服务都是可以在windows上正常运行的。但是还是建议最好能在linux上部署使用</p>\n<hr>\n<h2>Q：UI 在 linux 编译node-sass提示：Error：EACCESS:permission denied，mkdir xxxx</h2>\n<p>A：单独安装 <strong>npm install node-sass --unsafe-perm</strong>，之后再 <strong>npm install</strong></p>\n<hr>\n<h2>Q：UI 不能正常登陆访问</h2>\n<p>A： 1，如果是node启动的查看dolphinscheduler-ui下的.env API_BASE配置是否是Api Server服务地址</p>\n<pre><code>2，如果是nginx启动的并且是通过 **install-dolphinscheduler-ui.sh** 安装的，查看             \t\t\t\t\t\t\t\t\t\t\t**/etc/nginx/conf.d/dolphinscheduler.conf** 中的proxy_pass配置是否是Api Server服务地址\n\n3，如果以上配置都是正确的，那么请查看Api Server服务是否是正常的，curl http://192.168.xx.xx:12345/dolphinscheduler/users/get-user-info，查看Api Server日志，如果提示 cn.dolphinscheduler.api.interceptor.LoginHandlerInterceptor:[76] - session info is null，则证明Api Server服务是正常的\n\n4，如果以上都没有问题，需要查看一下 **application.properties** 中的 **server.context-path 和 server.port 配置**是否正确\n</code></pre>\n<hr>\n<h2>Q： 流程定义手动启动或调度启动之后，没有流程实例生成</h2>\n<p>A： 1，首先通过<strong>jps 查看MasterServer服务是否存在</strong>，或者从服务监控直接查看zk中是否存在master服务</p>\n<p>​\t2，如果存在master服务，查看 <strong>命令状态统计</strong> 或者 <strong>t_ds_error_command</strong> 中是否增加的新记录，如果增加了，<strong>请查看 message 字段定位启动异常原因</strong></p>\n<hr>\n<h2>Q ： 任务状态一直处于提交成功状态</h2>\n<p>A： 1，首先通过<strong>jps 查看WorkerServer服务是否存在</strong>，或者从服务监控直接查看zk中是否存在worker服务</p>\n<p>​       2，如果 <strong>WorkerServer</strong> 服务正常，需要 <strong>查看MasterServer是否把task任务放到zk队列中</strong> ，<strong>需要查看MasterServer日志及zk队列中是否有任务阻塞</strong></p>\n<p>​\t3，如果以上都没有问题，需要定位是否指定了Worker分组，但是 <strong>Worker分组的机器不是在线状态</strong></p>\n<hr>\n<h2>Q ： <a href=\"http://install.sh\">install.sh</a> 中需要注意问题</h2>\n<p>A：  1，如果替换变量中包含特殊字符，<strong>请用 \\ 转移符进行转移</strong></p>\n<p>​\t2，installPath=&quot;/data1_1T/dolphinscheduler&quot;，<strong>这个目录不能和当前要一键安装的install.sh目录是一样的</strong></p>\n<p>​\t3，deployUser=&quot;dolphinscheduler&quot;，<strong>部署用户必须具有sudo权限</strong>，因为worker是通过sudo -u 租户 sh xxx.command进行执行的</p>\n<p>​\t4，monitorServerState=&quot;false&quot;，服务监控脚本是否启动，默认是不启动服务监控脚本的。<strong>如果启动服务监控脚本，则每5分钟定时来监控master和worker的服务是否down机，如果down机则会自动重启</strong></p>\n<p>​\t5，hdfsStartupSate=&quot;false&quot;，是否开启HDFS资源上传功能。默认是不开启的，<strong>如果不开启则资源中心是不能使用的</strong>。如果开启，需要conf/common/hadoop/hadoop.properties中配置fs.defaultFS和yarn的相关配置，如果使用namenode HA，需要将core-site.xml和hdfs-site.xml复制到conf根目录下</p>\n<p>​\t注意：<strong>1.0.x版本是不会自动创建hdfs根目录的，需要自行创建，并且需要部署用户有hdfs的操作权限</strong></p>\n<hr>\n<h2>Q ： 流程定义和流程实例下线异常</h2>\n<p>A ： 对于 <strong>1.0.4 以前的版本中</strong>，修改dolphinscheduler-api cn.dolphinscheduler.api.quartz包下的代码即可</p>\n<pre><code>public boolean deleteJob(String jobName, String jobGroupName) {\n    lock.writeLock().lock();\n    try {\n      JobKey jobKey = new JobKey(jobName,jobGroupName);\n      if(scheduler.checkExists(jobKey)){\n        logger.info(&quot;try to delete job, job name: {}, job group name: {},&quot;, jobName, jobGroupName);\n        return scheduler.deleteJob(jobKey);\n      }else {\n        return true;\n      }\n\n    } catch (SchedulerException e) {\n      logger.error(String.format(&quot;delete job : %s failed&quot;,jobName), e);\n    } finally {\n      lock.writeLock().unlock();\n    }\n    return false;\n  }\n</code></pre>\n<hr>\n<h2>Q ： HDFS启动之前创建的租户，能正常使用资源中心吗</h2>\n<p>A： 不能。因为在未启动HDFS创建的租户，不会在HDFS中注册租户目录。所以上次资源会报错</p>\n<h2>Q :  多Master和多Worker状态下，服务掉了，怎么容错</h2>\n<p>A：  <strong>注意：Master监控Master及Worker服务。</strong></p>\n<p>​\t1，如果Master服务掉了，其它的Master会接管挂掉的Master的流程，继续监控Worker task状态</p>\n<p>​\t2，如果Worker服务掉，Master会监控到Worker服务掉了，如果存在Yarn任务，Kill Yarn任务之后走重试</p>\n<p>具体请看容错设计：<a href=\"https://analysys.github.io/easyscheduler_docs_cn/%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1.html#%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1\">https://analysys.github.io/easyscheduler_docs_cn/系统架构设计.html#系统架构设计</a></p>\n<hr>\n<h2>Q ： 对于Master和Worker一台机器伪分布式下的容错</h2>\n<p>A ： 1.0.3 版本只实现了Master启动流程容错，不走Worker容错。也就是说如果Worker挂掉的时候，没有Master存在。这流程将会出现问题。我们会在 <strong>1.1.0</strong> 版本中增加Master和Worker启动自容错，修复这个问题。如果想手动修改这个问题，需要针对 <strong>跨重启正在运行流程</strong> <strong>并且已经掉的正在运行的Worker任务，需要修改为失败</strong>，<strong>同时跨重启正在运行流程设置为失败状态</strong>。然后从失败节点进行流程恢复即可</p>\n<hr>\n<h2>Q ： 定时容易设置成每秒执行</h2>\n<p>A ： 设置定时的时候需要注意，如果第一位（* * * * * ? *）设置成 * ，则表示每秒执行。<strong>我们将会在1.1.0版本中加入显示最近调度的时间列表</strong> ，使用http://cron.qqe2.com/ 可以在线看近5次运行时间</p>\n<h2>Q： 定时有有效时间范围吗</h2>\n<p>A：有的，<strong>如果定时的起止时间是同一个时间，那么此定时将是无效的定时</strong>。<strong>如果起止时间的结束时间比当前的时间小，很有可能定时会被自动删除</strong></p>\n<h2>Q ： 任务依赖有几种实现</h2>\n<p>A：\t1，<strong>DAG</strong> 之间的任务依赖关系，是从 <strong>入度为零</strong> 进行DAG切分的</p>\n<p>​\t2，有 <strong>任务依赖节点</strong> ，可以实现跨流程的任务或者流程依赖，具体请参考 依赖(DEPENDENT)节点：<a href=\"https://analysys.github.io/easyscheduler_docs_cn/%E7%B3%BB%E7%BB%9F%E4%BD%BF%E7%94%A8%E6%89%8B%E5%86%8C.html#%E4%BB%BB%E5%8A%A1%E8%8A%82%E7%82%B9%E7%B1%BB%E5%9E%8B%E5%92%8C%E5%8F%82%E6%95%B0%E8%AE%BE%E7%BD%AE\">https://analysys.github.io/easyscheduler_docs_cn/系统使用手册.html#任务节点类型和参数设置</a></p>\n<p>​\t注意：<strong>不支持跨项目的流程或任务依赖</strong></p>\n<h2>Q： 流程定义有几种启动方式</h2>\n<p>A： 1，在 <strong>流程定义列表</strong>，点击 <strong>启动</strong> 按钮</p>\n<p>​\t2，<strong>流程定义列表添加定时器</strong>，调度启动流程定义</p>\n<p>​\t3，流程定义 <strong>查看或编辑</strong> DAG 页面，任意 <strong>任务节点右击</strong> 启动流程定义</p>\n<p>​\t4，可以对流程定义 DAG 编辑，设置某些任务的运行标志位 <strong>禁止运行</strong>，则在启动流程定义的时候，将该节点的连线将从DAG中去掉</p>\n<h2>Q ： Python任务设置Python版本</h2>\n<p>A：  1，对于1**.0.3之后的版本**只需要修改 conf/env/.dolphinscheduler_env.sh中的PYTHON_HOME</p>\n<pre><code>export PYTHON_HOME=/bin/python\n</code></pre>\n<p>注意：这了 <strong>PYTHON_HOME</strong> ，是python命令的绝对路径，而不是单纯的 PYTHON_HOME，还需要注意的是 export PATH 的时候，需要直接</p>\n<pre><code>export PATH=$HADOOP_HOME/bin:$SPARK_HOME1/bin:$SPARK_HOME2/bin:$PYTHON_HOME:$JAVA_HOME/bin:$HIVE_HOME/bin:$PATH\n</code></pre>\n<p>​\t2，对 1.0.3 之前的版本，Python任务只能支持系统的Python版本，不支持指定Python版本</p>\n<h2>Q： Worker Task 通过sudo -u 租户 sh xxx.command会产生子进程，在kill的时候，是否会杀掉</h2>\n<p>A： 我们会在1.0.4中增加kill任务同时，kill掉任务产生的各种所有子进程</p>\n<h2>Q ： DolphinScheduler中的队列怎么用，用户队列和租户队列是什么意思</h2>\n<p>A ： DolphinScheduler 中的队列可以在用户或者租户上指定队列，<strong>用户指定的队列优先级是高于租户队列的优先级的。</strong>，例如：对MR任务指定队列，是通过 mapreduce.job.queuename 来指定队列的。</p>\n<p>注意：MR在用以上方法指定队列的时候，传递参数请使用如下方式：</p>\n<pre><code>\tConfiguration conf = new Configuration();\n        GenericOptionsParser optionParser = new GenericOptionsParser(conf, args);\n        String[] remainingArgs = optionParser.getRemainingArgs();\n</code></pre>\n<p>如果是Spark任务 --queue 方式指定队列</p>\n<h2>Q : Master 或者 Worker报如下告警</h2>\n<p align=\"center\">\n   <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/master_worker_lack_res.png\" width=\"60%\" />\n </p>\n<p>A ： 修改conf下的 master.properties <strong>master.reserved.memory</strong> 的值为更小的值，比如说0.1 或者</p>\n<p>worker.properties <strong>worker.reserved.memory</strong> 的值为更小的值，比如说0.1</p>\n<h2>Q : hive版本是1.1.0+cdh5.15.0，SQL hive任务连接报错</h2>\n<p align=\"center\">\n   <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/cdh_hive_error.png\" width=\"60%\" />\n </p>\n<p>A ： 将 hive pom</p>\n<pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;org.apache.hive&lt;/groupId&gt;\n    &lt;artifactId&gt;hive-jdbc&lt;/artifactId&gt;\n    &lt;version&gt;2.1.0&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre>\n<p>修改为</p>\n<pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;org.apache.hive&lt;/groupId&gt;\n    &lt;artifactId&gt;hive-jdbc&lt;/artifactId&gt;\n    &lt;version&gt;1.1.0&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre>\n",
  "link": "/zh-cn/docs/faq.html",
  "meta": {}
}