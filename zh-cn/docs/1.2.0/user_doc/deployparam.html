<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
  <meta name="keywords" content="deployparam">
  <meta name="description" content="deployparam">
  <title>deployparam</title>
  <link rel="shortcut icon" href="/img/favicon.ico">
  <link rel="stylesheet" href="/build/vendor.23870e5.css">
</head>
<body>
  <div id="root"><div class="md2html docs-page" data-reactroot=""><header class="header-container header-container-dark"><div class="header-body"><span class="mobile-menu-btn mobile-menu-btn-dark"></span><a href="/zh-cn/index.html"><img class="logo" src="/img/hlogo_white.svg"/></a><div class="search search-dark"><span class="icon-search"></span></div><span class="language-switch language-switch-dark">En</span><div class="header-menu"><div><ul class="ant-menu whiteClass ant-menu-light ant-menu-root ant-menu-horizontal" role="menu"><li class="ant-menu-submenu ant-menu-submenu-horizontal ant-menu-overflowed-submenu" style="display:none" role="menuitem"><div class="ant-menu-submenu-title" aria-expanded="false" aria-haspopup="true"><span>···</span><i class="ant-menu-submenu-arrow"></i></div></li><li class="ant-menu-item" role="menuitem"><a href="/zh-cn/index.html" target="_self">首页</a></li><li class="ant-menu-submenu ant-menu-submenu-horizontal ant-menu-overflowed-submenu" style="display:none" role="menuitem"><div class="ant-menu-submenu-title" aria-expanded="false" aria-haspopup="true"><span>···</span><i class="ant-menu-submenu-arrow"></i></div></li><li class="ant-menu-submenu ant-menu-submenu-horizontal ant-menu-item-selected" role="menuitem"><div class="ant-menu-submenu-title" aria-expanded="false" aria-haspopup="true"><span class="submenu-title-wrapper"><a href="/zh-cn/docs/latest/user_doc/guide/quick-start.html" target="_self">文档</a></span><i class="ant-menu-submenu-arrow"></i></div></li><li class="ant-menu-submenu ant-menu-submenu-horizontal ant-menu-overflowed-submenu" style="display:none" role="menuitem"><div class="ant-menu-submenu-title" aria-expanded="false" aria-haspopup="true"><span>···</span><i class="ant-menu-submenu-arrow"></i></div></li><li class="ant-menu-item" role="menuitem"><a href="/zh-cn/download/download.html" target="_self">下载</a></li><li class="ant-menu-submenu ant-menu-submenu-horizontal ant-menu-overflowed-submenu" style="display:none" role="menuitem"><div class="ant-menu-submenu-title" aria-expanded="false" aria-haspopup="true"><span>···</span><i class="ant-menu-submenu-arrow"></i></div></li><li class="ant-menu-item" role="menuitem"><a href="/zh-cn/blog/index.html" target="_self">博客</a></li><li class="ant-menu-submenu ant-menu-submenu-horizontal ant-menu-overflowed-submenu" style="display:none" role="menuitem"><div class="ant-menu-submenu-title" aria-expanded="false" aria-haspopup="true"><span>···</span><i class="ant-menu-submenu-arrow"></i></div></li><li class="ant-menu-item" role="menuitem"><a href="/zh-cn/development/development-environment-setup.html" target="_self">开发者</a></li><li class="ant-menu-submenu ant-menu-submenu-horizontal ant-menu-overflowed-submenu" style="display:none" role="menuitem"><div class="ant-menu-submenu-title" aria-expanded="false" aria-haspopup="true"><span>···</span><i class="ant-menu-submenu-arrow"></i></div></li><li class="ant-menu-item" role="menuitem"><a href="/zh-cn/community/team.html" target="_self">社区</a></li><li class="ant-menu-submenu ant-menu-submenu-horizontal ant-menu-overflowed-submenu" style="display:none" role="menuitem"><div class="ant-menu-submenu-title" aria-expanded="false" aria-haspopup="true"><span>···</span><i class="ant-menu-submenu-arrow"></i></div></li><li class="ant-menu-submenu ant-menu-submenu-horizontal" role="menuitem"><div class="ant-menu-submenu-title" aria-expanded="false" aria-haspopup="true"><span class="submenu-title-wrapper"><a href="https://www.apache.org/" target="_blank">ASF</a></span><i class="ant-menu-submenu-arrow"></i></div></li><li class="ant-menu-submenu ant-menu-submenu-horizontal ant-menu-overflowed-submenu" style="display:none" role="menuitem"><div class="ant-menu-submenu-title" aria-expanded="false" aria-haspopup="true"><span>···</span><i class="ant-menu-submenu-arrow"></i></div></li><li class="ant-menu-item" role="menuitem"><a href="/zh-cn/user/index.html" target="_self">用户</a></li><li class="ant-menu-submenu ant-menu-submenu-horizontal ant-menu-overflowed-submenu" style="visibility:hidden;position:absolute" role="menuitem"><div class="ant-menu-submenu-title" aria-expanded="false" aria-haspopup="true"><span>···</span><i class="ant-menu-submenu-arrow"></i></div></li></ul></div></div><div class="mobile-menu"><div class="mobile-menu-content"><div class="mobile-menu-list"><div class="mobile-menu-item"><a class="mobile-menu-title" href="/zh-cn/index.html" target="_self">首页</a></div><div class="mobile-menu-item"><a class="mobile-menu-title" href="/zh-cn/docs/latest/user_doc/guide/quick-start.html" target="_self">文档</a><em class="mobile-menu-icon"></em><div class="mobile-sub-menus"><div class="mobile-sub-menu-item"><a href="/zh-cn/docs/latest/user_doc/guide/quick-start.html" target="_self">最新版本latest(2.0.5)</a></div><div class="mobile-sub-menu-item"><a href="/zh-cn/docs/1.3.9/user_doc/quick-start.html" target="_self">1.3.9</a></div><div class="mobile-sub-menu-item"><a href="/zh-cn/docs/release/history-versions.html" target="_self">历史版本</a></div><div class="mobile-sub-menu-item"><a href="/python/index.html" target="_self">PyDolphinScheduler</a></div><div class="mobile-sub-menu-item"><a href="/zh-cn/docs/dev/user_doc/about/introduction.html" target="_self">dev</a></div></div></div><div class="mobile-menu-item"><a class="mobile-menu-title" href="/zh-cn/download/download.html" target="_self">下载</a></div><div class="mobile-menu-item"><a class="mobile-menu-title" href="/zh-cn/blog/index.html" target="_self">博客</a></div><div class="mobile-menu-item"><a class="mobile-menu-title" href="/zh-cn/development/development-environment-setup.html" target="_self">开发者</a></div><div class="mobile-menu-item"><a class="mobile-menu-title" href="/zh-cn/community/team.html" target="_self">社区</a></div><div class="mobile-menu-item"><a class="mobile-menu-title" href="https://www.apache.org/" target="_blank">ASF</a><em class="mobile-menu-icon"></em><div class="mobile-sub-menus"><div class="mobile-sub-menu-item"><a href="https://www.apache.org/" target="_blank">Foundation</a></div><div class="mobile-sub-menu-item"><a href="https://www.apache.org/licenses/" target="_blank">License</a></div><div class="mobile-sub-menu-item"><a href="https://www.apache.org/events/current-event" target="_blank">Events</a></div><div class="mobile-sub-menu-item"><a href="https://www.apache.org/security/" target="_blank">Security</a></div><div class="mobile-sub-menu-item"><a href="https://www.apache.org/foundation/sponsorship.html" target="_blank">Sponsorship</a></div><div class="mobile-sub-menu-item"><a href="https://www.apache.org/foundation/thanks.html" target="_blank">Thanks</a></div></div></div><div class="mobile-menu-item"><a class="mobile-menu-title" href="/zh-cn/user/index.html" target="_self">用户</a></div></div></div><div class="mobile-menu-dummy"></div></div></div></header><section class="content-section"><div class="sidemenu"><div class="sidemenu-toggle"><img src="https://img.alicdn.com/tfs/TB1E6apXHGYBuNjy0FoXXciBFXa-200-200.png"/></div><ul><li class="menu-item menu-item-level-1"><span>部署文档</span><ul><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/zh-cn/docs/1.2.0/user_doc/hardware-environment.html" target="_self">软硬件环境建议配置</a></li><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/zh-cn/docs/1.2.0/user_doc/standalone-deployment.html" target="_self">单机部署(Standalone)</a></li><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/zh-cn/docs/1.2.0/user_doc/cluster-deployment.html" target="_self">集群部署(Cluster)</a></li></ul></li><li class="menu-item menu-item-level-1"><span>用户手册</span><ul><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/zh-cn/docs/1.2.0/user_doc/quick-start.html" target="_self">快速上手</a></li><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/zh-cn/docs/1.2.0/user_doc/system-manual.html" target="_self">用户手册</a></li><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/zh-cn/docs/1.2.0/user_doc/metadata-1.2.html" target="_self">元数据文档</a></li><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/zh-cn/docs/1.2.0/user_doc/deployparam.html" target="_self">部署参数分析</a></li></ul></li><li class="menu-item menu-item-level-1"><span>版本升级</span><ul><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/zh-cn/docs/1.2.0/user_doc/upgrade.html" target="_self">升级</a></li></ul></li><li class="menu-item menu-item-level-1"><span>FAQ</span><ul><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/zh-cn/docs/release/faq.html" target="_self">FAQ</a></li></ul></li></ul></div><div class="doc-content markdown-body"><h1>Dolphin Scheduler 1.2.0 部署参数分析</h1>
<h3>Dolphin Scheduler目录配置文件解读</h3>
<p>（讲解配置文件的作用，具体配置在install.sh部署文件中完成）<br /><img src="/img/doc-img/1.2.0/deployparam-img/deploydir.png" alt="image.png"></p>
<ul>
<li>bin 启动脚本</li>
<li>conf 配置文件</li>
<li>lib ds依赖的jar包</li>
<li>script 数据库创建升级脚本，部署分发脚本</li>
<li>sql ds的元数据创建升级sql文件</li>
<li>install脚本 部署ds主要的配置文件修改处
<a name="poKCK"></a></li>
</ul>
<h4>bin</h4>
<p>bin目录下比较重要的是dolphinscheduler-daemon文件，之前版本中极容易出现的找不到jdk问题来源，当前版本的jdk已经export了本机的$JAVA_HOME，再也不用担心找不到jdk了。<br /><img src="/img/doc-img/1.2.0/deployparam-img/daemon-120.png" alt="image.png">
<a name="lmmR2"></a></p>
<h4>conf</h4>
<p>非常重要的配置文件目录！！！<br />非常重要的配置文件目录！！！<br />非常重要的配置文件目录！！！<br /><img src="/img/doc-img/1.2.0/deployparam-img/conf-120.png" alt="image.png"></p>
<ul>
<li>env目录下的.dolphinscheduller_env.sh文件中记录了所有跟ds-task相关的环境变量,1.2.0版本的Spark不具备指定Spark版本的功能，可以注释掉SPARK_HOME1或者将SPARK_HOME1和SPARK_HOME2均配置为集群中的Spark2。下面给出CDH中的配置，测试环境中没有部署Flink，请忽略Flink的配置。（特别注意这是个隐藏文件，需要ls -al）</li>
</ul>
<pre><code class="language-shell">export HADOOP_HOME=/opt/cloudera/parcels/CDH/lib/hadoop
export HADOOP_CONF_DIR=/opt/cloudera/parcels/CDH/lib/hadoop/etc/hadoop
<span class="hljs-meta">#</span><span class="bash">可以注释掉，也可以配置为SPARK_HOME2</span>
<span class="hljs-meta">#</span><span class="bash"><span class="hljs-built_in">export</span> SPARK_HOME1=/opt/cloudera/parcels/SPARK2/lib/spark2</span>
export SPARK_HOME2=/opt/cloudera/parcels/SPARK2/lib/spark2
export PYTHON_HOME=/usr/local/anaconda3/bin/python
export JAVA_HOME=/usr/java/jdk1.8.0_131
export HIVE_HOME=/opt/cloudera/parcels/CDH/lib/hive
export FLINK_HOME=/opt/soft/flink
export PATH=$HADOOP_HOME/bin:$SPARK_HOME1/bin:$SPARK_HOME2/bin:$PYTHON_HOME:$JAVA_HOME/bin:$HIVE_HOME/bin:$PATH:$FLINK_HOME/bin:$PATH
</code></pre>
<p><a name="chqEB"></a></p>
<h4>common目录</h4>
<p>common目录包含：common.properties和hadoop/hadoop.properties</p>
<ul>
<li>common.properies
<ul>
<li>ds的task队列实现方式，默认是Zookeeper</li>
<li>ds的task和资源的worker执行路径</li>
<li>资源中心
<ul>
<li>资源中心可选择HDFS和S3</li>
</ul>
</li>
<li>资源文件类型</li>
<li>kerberos</li>
<li>开发状态
<ul>
<li>开发测试可以开启，生产环境建议设置为false</li>
</ul>
</li>
<li>ds的环境变量配置，本地调试的时候，需要保证dolphinscheduler.env.path存在</li>
</ul>
</li>
<li>hadoop.properties
<ul>
<li>hdfs namenode配置
<ul>
<li>单点可以直接写namenode的ip</li>
<li>hdfsHA需要将集群的core-site.xml和hdfs-site.xml文件拷贝到ds的conf目录下</li>
</ul>
</li>
<li>s3配置</li>
<li>yarn resourcemanager配置
<ul>
<li>单点配置yarn.application.status.address</li>
<li>HA配置yarn.resourcemanager.ha.rm.ids
<a name="ggGBc"></a></li>
</ul>
</li>
</ul>
</li>
</ul>
<h4>config目录</h4>
<p>config目录包含install_config.conf和run_config.conf</p>
<ul>
<li>install_config.conf
<ul>
<li>ds的安装路径</li>
<li>部署用户</li>
<li>部署ds的机器组ip</li>
</ul>
</li>
<li>run_config.conf
<ul>
<li>指定ds的masters，workers，alertServer，apiServer部署在哪些机器上
<a name="AC8Jm"></a></li>
</ul>
</li>
</ul>
<h4>alert.properties</h4>
<ul>
<li>邮件告警配置</li>
<li>excel下载目录</li>
<li>企业微信配置
<a name="1qiHb"></a></li>
</ul>
<h4>application-api.properties</h4>
<ul>
<li>apiserver端口，上下文，日志等
<a name="IiX6U"></a></li>
</ul>
<h4>application-dao.properties</h4>
<p>敲黑板，重点！！！ds的元数据库配置，在ds-1.2.0中默认的数据库是pg，如果要使用MySQL，需要将MySQL的jdbc包放到lib目录下。</p>
<ul>
<li>ds元数据库配置
<a name="oomWN"></a></li>
</ul>
<h4>master.properties</h4>
<ul>
<li>master执行线程数</li>
<li>master并行任务上限</li>
<li>master资源CPU和内存阈值，超出阈值不会进行dag切分
<a name="ZeAdP"></a></li>
</ul>
<h4>worker.properties</h4>
<ul>
<li>worker执行线程数</li>
<li>worker一次提交任务数</li>
<li>worker资源CPU和内存阈值，超出不会去task队列拉取task
<a name="saeo8"></a></li>
</ul>
<h4>Zookeeper.properties</h4>
<ul>
<li>zk集群</li>
<li>ds所需zk的znode，包含dag和task的分布式锁和master和worker的容错
<a name="2eTCI"></a></li>
</ul>
<h4>quartz.properties</h4>
<p>ds的定时由quartz框架完成，特别注意里边有quartz的数据库配置！！！</p>
<ul>
<li>quartz的基本属性，线程池和job配置</li>
<li>quartz元数据库配置
<a name="vWF4U"></a></li>
</ul>
<h3>install脚本</h3>
<p>install.sh部署脚本是ds部署中的重头戏，下面将参数分组进行分析。
<a name="rYEds"></a></p>
<h4>数据库配置</h4>
<pre><code class="language-shell"><span class="hljs-meta">#</span><span class="bash"> <span class="hljs-keyword">for</span> example postgresql or mysql ...</span>
dbtype=&quot;postgresql&quot;
<span class="hljs-meta">
#</span><span class="bash"> db config</span>
<span class="hljs-meta">#</span><span class="bash"> db address and port</span>
dbhost=&quot;192.168.xx.xx:5432&quot;
<span class="hljs-meta">
#</span><span class="bash"> db name</span>
dbname=&quot;dolphinscheduler&quot;
<span class="hljs-meta">
#</span><span class="bash"> db username</span>
username=&quot;xx&quot;
<span class="hljs-meta">
#</span><span class="bash"> db passwprd</span>
<span class="hljs-meta">#</span><span class="bash"> Note: <span class="hljs-keyword">if</span> there are special characters, please use the \ transfer character to transfer</span>
passowrd=&quot;xx&quot;
</code></pre>
<ul>
<li>dbtype参数可以设置postgresql和mysql，这里指定了ds连接元数据库的jdbc相关信息
<a name="K4u2S"></a></li>
</ul>
<h4>部署用户&amp;目录</h4>
<pre><code class="language-shell"><span class="hljs-meta">#</span><span class="bash"> conf/config/install_config.conf config</span>
<span class="hljs-meta">#</span><span class="bash"> Note: the installation path is not the same as the current path (<span class="hljs-built_in">pwd</span>)</span>
installPath=&quot;/data1_1T/dolphinscheduler&quot;
<span class="hljs-meta">
#</span><span class="bash"> deployment user</span>
<span class="hljs-meta">#</span><span class="bash"> Note: the deployment user needs to have sudo privileges and permissions to operate hdfs. If hdfs is enabled, the root directory needs to be created by itself</span>
deployUser=&quot;dolphinscheduler&quot;
</code></pre>
<ul>
<li>installPath是安装路径，在执行install.sh之后，会把ds安装到指定目录，如/opt/ds-agent。installPath不要和当前要一键安装的install.sh是同一目录。</li>
<li>deployUser是指ds的部署用户，该用户需要在部署ds的机器上打通sudo免密，并且需要具有操作hdfs的权限，建议挂到hadoop的supergroup组下。
<a name="6rEDt"></a></li>
</ul>
<h4>zk集群&amp;角色指定</h4>
<ul>
<li>配置zk集群的时候，特别注意：要用ip:2181的方式配置上去，一定要把端口带上。</li>
<li>ds一共包括master worker alert api四种角色，其中alert api只需指定一台机器即可，master和worker可以部署多态机器。下面的例子就是在4台机器中，部署2台master，2台worker，1台alert，1台api</li>
<li>ips参数，填写所有需要部署机器的hostname</li>
<li>masters，填写部署master机器的hostname</li>
<li>workers，填写部署worker机器的hostname</li>
<li>alertServer，填写部署alert机器的hostname</li>
<li>apiServers，填写部署api机器的hostname</li>
<li>zkroot参数可以通过调整，在一套zk集群中，托管多个ds集群，如配置zkRoot=&quot;/dspro&quot;,zkRoot=&quot;/dstest&quot;</li>
</ul>
<pre><code class="language-shell"><span class="hljs-meta">#</span><span class="bash"> zk cluster</span>
zkQuorum=&quot;192.168.xx.xx:2181,192.168.xx.xx:2181,192.168.xx.xx:2181&quot;
<span class="hljs-meta">
#</span><span class="bash"> install hosts</span>
<span class="hljs-meta">#</span><span class="bash"> Note: install the scheduled hostname list. If it is pseudo-distributed, just write a pseudo-distributed hostname</span>
ips=&quot;ark0,ark1,ark2,ark3&quot;
<span class="hljs-meta">
#</span><span class="bash"> conf/config/run_config.conf config</span>
<span class="hljs-meta">#</span><span class="bash"> run master machine</span>
<span class="hljs-meta">#</span><span class="bash"> Note: list of hosts hostname <span class="hljs-keyword">for</span> deploying master</span>
masters=&quot;ark0,ark1&quot;
<span class="hljs-meta">
#</span><span class="bash"> run worker machine</span>
<span class="hljs-meta">#</span><span class="bash"> note: list of machine hostnames <span class="hljs-keyword">for</span> deploying workers</span>
workers=&quot;ark2,ark3&quot;
<span class="hljs-meta">
#</span><span class="bash"> run alert machine</span>
<span class="hljs-meta">#</span><span class="bash"> note: list of machine hostnames <span class="hljs-keyword">for</span> deploying alert server</span>
alertServer=&quot;ark3&quot;
<span class="hljs-meta">
#</span><span class="bash"> run api machine</span>
<span class="hljs-meta">#</span><span class="bash"> note: list of machine hostnames <span class="hljs-keyword">for</span> deploying api server</span>
apiServers=&quot;ark1&quot;
<span class="hljs-meta">
#</span><span class="bash"> zk config</span>
<span class="hljs-meta">#</span><span class="bash"> zk root directory</span>
zkRoot=&quot;/dolphinscheduler&quot;
<span class="hljs-meta">
#</span><span class="bash"> used to record the zk directory of the hanging machine</span>
zkDeadServers=&quot;$zkRoot/dead-servers&quot;
<span class="hljs-meta">
#</span><span class="bash"> masters directory</span>
zkMasters=&quot;$zkRoot/masters&quot;
<span class="hljs-meta">
#</span><span class="bash"> workers directory</span>
zkWorkers=&quot;$zkRoot/workers&quot;
<span class="hljs-meta">
#</span><span class="bash"> zk master distributed lock</span>
mastersLock=&quot;$zkRoot/lock/masters&quot;
<span class="hljs-meta">
#</span><span class="bash"> zk worker distributed lock</span>
workersLock=&quot;$zkRoot/lock/workers&quot;
<span class="hljs-meta">
#</span><span class="bash"> zk master fault-tolerant distributed lock</span>
mastersFailover=&quot;$zkRoot/lock/failover/masters&quot;
<span class="hljs-meta">
#</span><span class="bash"> zk worker fault-tolerant distributed lock</span>
workersFailover=&quot;$zkRoot/lock/failover/workers&quot;
<span class="hljs-meta">
#</span><span class="bash"> zk master start fault tolerant distributed lock</span>
mastersStartupFailover=&quot;$zkRoot/lock/failover/startup-masters&quot;
<span class="hljs-meta">
#</span><span class="bash"> zk session timeout</span>
zkSessionTimeout=&quot;300&quot;
<span class="hljs-meta">
#</span><span class="bash"> zk connection timeout</span>
zkConnectionTimeout=&quot;300&quot;
<span class="hljs-meta">
#</span><span class="bash"> zk retry interval</span>
zkRetrySleep=&quot;100&quot;
<span class="hljs-meta">
#</span><span class="bash"> zk retry maximum number of <span class="hljs-built_in">times</span></span>
zkRetryMaxtime=&quot;5&quot;
</code></pre>
<p><a name="7aGb8"></a></p>
<h4>邮件配置&amp;excel文件路径</h4>
<ul>
<li>邮件配置这块也是大家非常容易出问题的，建议可以拉一下ds的代码，跑一下alert.MailUtilisTest这个测试类，下面给出QQ邮箱配置方式。如果是内网邮箱，需要注意的是ssl是否需要关闭，以及mail.user登陆用户是否需要去掉邮箱后缀。</li>
<li>excel路径则需要保证该路径的写入权限</li>
</ul>
<pre><code class="language-shell"><span class="hljs-meta">#</span><span class="bash">QQ邮箱配置</span>
<span class="hljs-meta">#</span><span class="bash"> alert config</span>
<span class="hljs-meta">#</span><span class="bash"> mail protocol</span>
mailProtocol=&quot;SMTP&quot;
<span class="hljs-meta">
#</span><span class="bash"> mail server host</span>
mailServerHost=&quot;smtp.qq.com&quot;
<span class="hljs-meta">
#</span><span class="bash"> mail server port</span>
mailServerPort=&quot;465&quot;
<span class="hljs-meta">
#</span><span class="bash"> sender</span>
mailSender=&quot;783xx8369@qq.com&quot;
<span class="hljs-meta">
#</span><span class="bash"> user</span>
mailUser=&quot;783xx8369@qq.com&quot;
<span class="hljs-meta">
#</span><span class="bash"> sender password</span>
mailPassword=&quot;邮箱授权码&quot;
<span class="hljs-meta">
#</span><span class="bash"> TLS mail protocol support</span>
starttlsEnable=&quot;false&quot;

sslTrust=&quot;smtp.qq.com&quot;
<span class="hljs-meta">
#</span><span class="bash"> SSL mail protocol support</span>
<span class="hljs-meta">#</span><span class="bash"> note: The SSL protocol is enabled by default.</span> 
<span class="hljs-meta">#</span><span class="bash"> only one of TLS and SSL can be <span class="hljs-keyword">in</span> the <span class="hljs-literal">true</span> state.</span>
sslEnable=&quot;true&quot;
<span class="hljs-meta">
#</span><span class="bash"> download excel path</span>
xlsFilePath=&quot;/tmp/xls&quot;
<span class="hljs-meta">
#</span><span class="bash"> alert port</span>
alertPort=7789
</code></pre>
<p><a name="h0lJz"></a></p>
<h4>apiServer配置</h4>
<ul>
<li>apiServer这里可以关注一下，apiserver的端口和上下文即apiServerPort和apiServerContextPath参数</li>
</ul>
<pre><code class="language-shell"><span class="hljs-meta">#</span><span class="bash"> api config</span>
<span class="hljs-meta">#</span><span class="bash"> api server port</span>
apiServerPort=&quot;12345&quot;
<span class="hljs-meta">
#</span><span class="bash"> api session timeout</span>
apiServerSessionTimeout=&quot;7200&quot;
<span class="hljs-meta">
#</span><span class="bash"> api server context path</span>
apiServerContextPath=&quot;/dolphinscheduler/&quot;
<span class="hljs-meta">
#</span><span class="bash"> spring max file size</span>
springMaxFileSize=&quot;1024MB&quot;
<span class="hljs-meta">
#</span><span class="bash"> spring max request size</span>
springMaxRequestSize=&quot;1024MB&quot;
<span class="hljs-meta">
#</span><span class="bash"> api max http post size</span>
apiMaxHttpPostSize=&quot;5000000&quot;
</code></pre>
<p><a name="T4u9c"></a></p>
<h4>资源中心&amp;YARN</h4>
<ul>
<li>ds的资源中心支持HDFS和S3.</li>
<li>resUploadStartupType=&quot;HDFS&quot;则开启hdfs作为资源中心。</li>
<li>defaultFS，如果hdfs没有配置HA则需要在这里写上单点namenode的ip，如果HDFS是HA则需要将集群的core-site.xml文件和hdfs-site.xml文件拷贝到conf目录下</li>
<li>yarnHaIps，如果yarn启用了HA，配置两个resourcemanager的ip，如果是单点，配置空字符串</li>
<li>singleYarnIp，如果yarn是单点，配置resourcemanager的ip</li>
<li>hdfsPath，HDFS上ds存储资源的根路径，可采用默认值，如果是从1.1.0版本进行升级，需要注意这个地方，改为/escheduler</li>
</ul>
<pre><code class="language-shell"><span class="hljs-meta">#</span><span class="bash"> resource Center upload and select storage method：HDFS,S3,NONE</span>
resUploadStartupType=&quot;NONE&quot;
<span class="hljs-meta">
#</span><span class="bash"> <span class="hljs-keyword">if</span> resUploadStartupType is HDFS，defaultFS write namenode address，HA you need to put core-site.xml and hdfs-site.xml <span class="hljs-keyword">in</span> the conf directory.</span>
<span class="hljs-meta">#</span><span class="bash"> <span class="hljs-keyword">if</span> S3，write S3 address，HA，<span class="hljs-keyword">for</span> example ：s3a://dolphinscheduler，</span>
<span class="hljs-meta">#</span><span class="bash"> Note，s3 be sure to create the root directory /dolphinscheduler</span>
defaultFS=&quot;hdfs://mycluster:8020&quot;
<span class="hljs-meta">
#</span><span class="bash"> <span class="hljs-keyword">if</span> S3 is configured, the following configuration is required.</span>
s3Endpoint=&quot;http://192.168.xx.xx:9010&quot;
s3AccessKey=&quot;xxxxxxxxxx&quot;
s3SecretKey=&quot;xxxxxxxxxx&quot;
<span class="hljs-meta">
#</span><span class="bash"> resourcemanager HA configuration, <span class="hljs-keyword">if</span> it is a single resourcemanager, here is yarnHaIps=<span class="hljs-string">&quot;&quot;</span></span>
yarnHaIps=&quot;192.168.xx.xx,192.168.xx.xx&quot;
<span class="hljs-meta">
#</span><span class="bash"> <span class="hljs-keyword">if</span> it is a single resourcemanager, you only need to configure one host name. If it is resourcemanager HA, the default configuration is fine.</span>
singleYarnIp=&quot;ark1&quot;
<span class="hljs-meta">
#</span><span class="bash"> hdfs root path, the owner of the root path must be the deployment user.</span> 
<span class="hljs-meta">#</span><span class="bash"> versions prior to 1.1.0 <span class="hljs-keyword">do</span> not automatically create the hdfs root directory, you need to create it yourself.</span>
hdfsPath=&quot;/dolphinscheduler&quot;
<span class="hljs-meta">
#</span><span class="bash"> have users who create directory permissions under hdfs root path /</span>
<span class="hljs-meta">#</span><span class="bash"> Note: <span class="hljs-keyword">if</span> kerberos is enabled, hdfsRootUser=<span class="hljs-string">&quot;&quot;</span> can be used directly.</span>
hdfsRootUser=&quot;hdfs&quot;
</code></pre>
<p><a name="0bSHO"></a></p>
<h4>开发状态</h4>
<ul>
<li>devState在测试环境部署的时候可以调为true，生产环境部署建议调为false</li>
</ul>
<pre><code class="language-shell"><span class="hljs-meta">#</span><span class="bash"> development status, <span class="hljs-keyword">if</span> <span class="hljs-literal">true</span>, <span class="hljs-keyword">for</span> the SHELL script, you can view the encapsulated SHELL script <span class="hljs-keyword">in</span> the execPath directory.</span> 
<span class="hljs-meta">#</span><span class="bash"> If it is <span class="hljs-literal">false</span>, execute the direct delete</span>
devState=&quot;true&quot;
</code></pre>
<p><a name="x9hTX"></a></p>
<h4>角色参数</h4>
<ul>
<li>下面的参数主要是调整的application.properties里边的配置，涉及master,worker和apiserver</li>
<li>apiServerPort可以自定义修改apiserver的端口，注意需要跟前端保持一致。</li>
<li>master和worker的参数，初次部署建议保持默认值，如果在运行当中出现性能问题在作调整，有条件可以压一下自身环境中的master和worker的最佳线程数。</li>
<li>worker.reserved.memory是worker的内存阈值，masterReservedMemory是master的内存阈值，建议调整为0.1</li>
<li>masterMaxCpuLoadAvg建议注释掉，ds-1.2.0master和worker的CPU负载给出了默认cpu线程数 * 2的默认值</li>
</ul>
<pre><code class="language-shell"><span class="hljs-meta">#</span><span class="bash"> master config</span> 
<span class="hljs-meta">#</span><span class="bash"> master execution thread maximum number, maximum parallelism of process instance</span>
masterExecThreads=&quot;100&quot;
<span class="hljs-meta">
#</span><span class="bash"> the maximum number of master task execution threads, the maximum degree of parallelism <span class="hljs-keyword">for</span> each process instance</span>
masterExecTaskNum=&quot;20&quot;
<span class="hljs-meta">
#</span><span class="bash"> master heartbeat interval</span>
masterHeartbeatInterval=&quot;10&quot;
<span class="hljs-meta">
#</span><span class="bash"> master task submission retries</span>
masterTaskCommitRetryTimes=&quot;5&quot;
<span class="hljs-meta">
#</span><span class="bash"> master task submission retry interval</span>
masterTaskCommitInterval=&quot;100&quot;
<span class="hljs-meta">
#</span><span class="bash"> master maximum cpu average load, used to determine whether the master has execution capability</span>
<span class="hljs-meta">#</span><span class="bash">masterMaxCpuLoadAvg=<span class="hljs-string">&quot;10&quot;</span></span>
<span class="hljs-meta">
#</span><span class="bash"> master reserve memory to determine <span class="hljs-keyword">if</span> the master has execution capability</span>
masterReservedMemory=&quot;1&quot;
<span class="hljs-meta">
#</span><span class="bash"> master port</span>
masterPort=5566
<span class="hljs-meta">
#</span><span class="bash"> worker config</span> 
<span class="hljs-meta">#</span><span class="bash"> worker execution thread</span>
workerExecThreads=&quot;100&quot;
<span class="hljs-meta">
#</span><span class="bash"> worker heartbeat interval</span>
workerHeartbeatInterval=&quot;10&quot;
<span class="hljs-meta">
#</span><span class="bash"> worker number of fetch tasks</span>
workerFetchTaskNum=&quot;3&quot;
<span class="hljs-meta">
#</span><span class="bash"> worker reserve memory to determine <span class="hljs-keyword">if</span> the master has execution capability</span>
workerReservedMemory=&quot;1&quot;
<span class="hljs-meta">
#</span><span class="bash"> master port</span>
workerPort=7788
</code></pre>
<p><a name="3QaMD"></a></p>
<h3>特别注意</h3>
<ul>
<li>ds需要启用资源中心之后，才可以创建租户，因此资源中心的配置一定要正确</li>
<li>ds老版本部署需要配置JDK的问题已经解决</li>
<li>installPath不要和当前要一键安装的install.sh是同一目录</li>
<li>ds的task运行都依赖env目录下的环境变量文件，需要正确配置</li>
<li>HDFS高可用，需要把core-site.xml和hdfs-site.xml文件拷贝到conf目录下</li>
<li>邮件配置中mailUser和mailSender的区别</li>
</ul>
</div></section><footer class="footer-container"><div class="footer-body"><div><h3>联系我们</h3><h4>有问题需要反馈？请通过以下方式联系我们。</h4></div><div class="contact-container"><ul><li><a href="/zh-cn/community/development/subscribe.html"><img class="img-base" src="/img/emailgray.png"/><img class="img-change" src="/img/emailblue.png"/><p>邮件列表</p></a></li><li><a href="https://twitter.com/dolphinschedule"><img class="img-base" src="/img/twittergray.png"/><img class="img-change" src="/img/twitterblue.png"/><p>Twitter</p></a></li><li><a href="https://stackoverflow.com/questions/tagged/apache-dolphinscheduler"><img class="img-base" src="/img/stackoverflow.png"/><img class="img-change" src="/img/stackoverflow-selected.png"/><p>Stack Overflow</p></a></li><li><a href="https://join.slack.com/t/asf-dolphinscheduler/shared_invite/zt-omtdhuio-_JISsxYhiVsltmC5h38yfw"><img class="img-base" src="/img/slack.png"/><img class="img-change" src="/img/slack-selected.png"/><p>Slack</p></a></li></ul></div><div class="cols-container"><div class="docu-container"><h4>文档</h4><ul><li><a href="/zh-cn/development/architecture-design.html"><p>概览</p></a></li><li><a href="/zh-cn/docs/latest/user_doc/guide/quick-start.html"><p>快速开始</p></a></li><li><a href="/zh-cn/development/development-environment-setup.html"><p>开发者指南</p></a></li></ul></div><div></div><div class="asf-container"><h4>ASF</h4><ul><li><a href="http://www.apache.org"><p>基金会</p></a></li><li><a href="http://www.apache.org/licenses/"><p>证书</p></a></li><li><a href="http://www.apache.org/events/current-event"><p>事件</p></a></li><li><a href="http://www.apache.org/foundation/sponsorship.html"><p>赞助</p></a></li><li><a href="http://www.apache.org/foundation/thanks.html"><p>致谢</p></a></li></ul></div></div><div class="copyright"><span>Copyright © 2019-2021 The Apache Software Foundation. Apache DolphinScheduler, DolphinScheduler, and its feather logo are trademarks of The Apache Software Foundation.</span></div></div></footer></div></div>
  <script src="//cdn.jsdelivr.net/npm/react@15.6.2/dist/react-with-addons.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/react-dom@15.6.2/dist/react-dom.min.js"></script>
  <script>window.rootPath = '';</script>
  <script src="/build/vendor.90dcf97.js"></script>
  <script src="/build/docs.md.8182f21.js"></script>
  <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?4e7b4b400dd31fa015018a435c64d06f";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-899J8PYKJZ"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-899J8PYKJZ');
  </script>
</body>
</html>