{
  "filename": "DolphinScheduler_Kubernetes_Technology_in_action.md",
  "__html": "<h1>Apache DolphinScheduler在Kubernetes体系中的技术实战</h1>\n<p>作者 | 杨滇，深圳交通中心 数据和算法平台架构师</p>\n<h2>Kubernetes技术体系给Apache DolphinScheduler带来的技术新特性</h2>\n<p>Apache DolphinScheduler是当前非常优秀的分布式易扩展的可视化工作流任务调度平台。</p>\n<p>基于笔者所在公司业务的特性，阐述我们使用 Kubernetes 作为Apache DolphinScheduler的技术底座的原因：</p>\n<ul>\n<li>各类独立部署项目，需要快速建立开发环境和生产环境；</li>\n<li>项目环境互联网访问受限，服务器只能使用离线的安装方式；</li>\n<li>尽可能统一的安装配置的信息，减少多个项目配置的异常；</li>\n<li>与对象存储技术的结合，统一非结构化数据的技术；</li>\n<li>便捷的监控体系，与现有监控集成；</li>\n<li>多种调度器的混合使用；</li>\n<li>全自动的资源调整能力；</li>\n<li>快速的自愈能力；</li>\n</ul>\n<p>本文的案例都是基于Apache DolphinScheduler1.3.9版本为基础。Hadoop</p>\n<h2>基于helm工具的自动化高效部署方式</h2>\n<p>首先，我们介绍基于官网提供的helm的安装方式。Helm 是查找、分享和使用软件构建 Kubernetes 的最优方式。也是云原生CNCF的毕业项目之一。</p>\n<div align=center>\n<img src=\"/img/2022-02-22/2.png\"/>\n</div>\n<p>海豚的官网和GitHub上有非常详细的配置文件和案例。这里我们重点介绍一些社区中经常出现的咨询和问题。</p>\n<p>官网文档地址 <a href=\"https://dolphinscheduler.apache.org/zh-cn/docs/1.3.9/user_doc/kubernetes-deployment.html\">https://dolphinscheduler.apache.org/zh-cn/docs/1.3.9/user_doc/kubernetes-deployment.html</a></p>\n<p>GitHub文件夹地址  <a href=\"https://github.com/apache/dolphinscheduler/tree/1.3.9-release/docker/kubernetes/dolphinscheduler/\">https://github.com/apache/dolphinscheduler/tree/1.3.9-release/docker/kubernetes/dolphinscheduler/</a></p>\n<ul>\n<li>\n<p>在value.yaml文件中修改镜像，以实现离线安装（air-gap install）；\n<a href=\"https://about.gitlab.com/topics/gitops/\">https://about.gitlab.com/topics/gitops/</a></p>\n<pre><code class=\"language-yaml\"><span class=\"hljs-attr\">image:</span>\n  <span class=\"hljs-attr\">repository:</span> <span class=\"hljs-string\">&quot;apache/dolphinscheduler&quot;</span>\n  <span class=\"hljs-attr\">tag:</span> <span class=\"hljs-string\">&quot;1.3.9&quot;</span>\n  <span class=\"hljs-attr\">pullPolicy:</span> <span class=\"hljs-string\">&quot;IfNotPresent&quot;</span>\n</code></pre>\n<p>针对公司内部安装好的harbor，或者其他公有云的私仓，进行pull，tag，以及push。<a href=\"http://xn--harbor-hu8itg33jqzybfap84cwou1fnbr5eq4zdn6g.abc.com\">这里我们假定私仓地址是harbor.abc.com</a>，你所在构建镜像的主机已经进行了docker login <a href=\"http://harbor.abc.com\">harbor.abc.com</a>， 且已经建立和授权私仓下面新建apache项目。</p>\n<p>执行shell命令</p>\n<pre><code class=\"language-shell\">docker pull apache/dolphinscheduler:1.3.9\ndock tag apache/dolphinscheduler:1.3.9 harbor.abc.com/apache/dolphinscheduler:1.3.9\ndocker push apache/dolphinscheduler:1.3.9\n</code></pre>\n<p>再替换value文件中的镜像信息，这里我们推荐使用Always的方式拉取镜像，生产环境中尽量每次去检查是否是最新的镜像内容，保证软件制品的正确性。此外，很多同学会把tag写成latest（制作镜像不写tag信息，这样在生产环境非常危险，任何人push了镜像，就相当于改变了latest的tag的镜像，而且也无法判断latest是什么版本，所以建议要明确每次发版的tag，并且使用Always。</p>\n<pre><code class=\"language-yaml\"><span class=\"hljs-attr\">image:</span>\n  <span class=\"hljs-attr\">repository:</span> <span class=\"hljs-string\">&quot;harbor.abc.com/apache/dolphinscheduler&quot;</span>\n  <span class=\"hljs-attr\">tag:</span> <span class=\"hljs-string\">&quot;1.3.9&quot;</span>\n  <span class=\"hljs-attr\">pullPolicy:</span> <span class=\"hljs-string\">&quot;Always&quot;</span><span class=\"hljs-string\">GitHub</span>\n</code></pre>\n<p>把 <a href=\"https://github.com/apache/dolphinscheduler/tree/1.3.9-release/docker/kubernetes/dolphinscheduler/\">https://github.com/apache/dolphinscheduler/tree/1.3.9-release/docker/kubernetes/dolphinscheduler/</a> 整个目录copy到可以执行helm命令的主机，然后按照官网执行</p>\n<pre><code class=\"language-shell\">kubectl create ns ds139Git\n</code></pre>\n</li>\n</ul>\n<p>MySQL install dolphinscheduler . -n ds139</p>\n<pre><code>\n即可实现离线安装。\n\n+ 集成DataX MySQL Oracle客户端组件，首先下载以下组件\n\nhttps://repo1.maven.org/maven2/MySQL/MySQL-connector-java/5.1.49/MySQL-connector-java-5.1.49.jar\n\nhttps://repo1.maven.org/maven2/com/Oracle/database/jdbc/ojdbc8/\n\nhttps://GitHub.com/alibaba/DataX/blob/master/userGuid.md 根据提示进行编译构建，文件包位于 {DataX_source_code_home}/target/DataX/DataX/ \n\n基于以上plugin组件新建dockerfile，基础镜像可以使用已经push到私仓的镜像。\n\n~~~dock\nFROM harbor.abc.com/apache/dolphinscheduler:1.3.9\nCOPY *.jar /opt/dolphinscheduler/lib/\nRUN mkdir -p /opt/soft/DataX\nCOPY DataX /opt/soft/DataX\n</code></pre>\n<p>保存dockerfile，执行shell命令</p>\n<pre><code class=\"language-shell\">docker build -t harbor.abc.com/apache/dolphinscheduler:1.3.9-MySQL-Oracle-DataX .  #不要忘记最后一个点\ndocker push harbor.abc.com/apache/dolphinscheduler:1.3.9-MySQL-Oracle-DataX\n</code></pre>\n<p>修改value文件</p>\n<pre><code class=\"language-yaml\"><span class=\"hljs-attr\">image:</span>\n  <span class=\"hljs-attr\">repository:</span> <span class=\"hljs-string\">&quot;harbor.abc.com/apache/dolphinscheduler&quot;</span>\n  <span class=\"hljs-attr\">tag:</span> <span class=\"hljs-string\">&quot;1.3.9-MySQL-Oracle-DataX&quot;</span>\n  <span class=\"hljs-attr\">pullPolicy:</span> <span class=\"hljs-string\">&quot;Always&quot;</span>\n</code></pre>\n<p>执行helm install dolphinscheduler . -n ds139，或者执行helm upgrade dolphinscheduler -n ds139，也可以先helm uninstall dolphinscheduler -n ds139，再执行helm install dolphinscheduler . -n ds139。</p>\n<ul>\n<li>\n<p>通常生产环境建议使用独立外置postgresql作为管理数据库，并且使用独立安装的zookeeper环境（本案例使用了zookeeper operator <a href=\"https://GitHub.com/pravega/zookeeper-operator\">https://GitHub.com/pravega/zookeeper-operator</a> ，与Apache DolphinScheduler在同一个Kubernetes集群中）。</p>\n<pre><code class=\"language-yaml\"><span class=\"hljs-comment\">## If not exists external database, by default, Dolphinscheduler&#x27;s database will use it.</span>\n<span class=\"hljs-attr\">postgresql:</span>\n  <span class=\"hljs-attr\">enabled:</span> <span class=\"hljs-literal\">false</span>\n  <span class=\"hljs-attr\">postgresqlUsername:</span> <span class=\"hljs-string\">&quot;root&quot;</span>\n  <span class=\"hljs-attr\">postgresqlPassword:</span> <span class=\"hljs-string\">&quot;root&quot;</span>\n  <span class=\"hljs-attr\">postgresqlDatabase:</span> <span class=\"hljs-string\">&quot;dolphinscheduler&quot;</span>\n  <span class=\"hljs-attr\">persistence:</span>\n    <span class=\"hljs-attr\">enabled:</span> <span class=\"hljs-literal\">false</span>\n    <span class=\"hljs-attr\">size:</span> <span class=\"hljs-string\">&quot;20Gi&quot;</span>\n    <span class=\"hljs-attr\">storageClass:</span> <span class=\"hljs-string\">&quot;-&quot;</span>\n\n<span class=\"hljs-comment\">## If exists external database, and set postgresql.enable value to false.</span>\n<span class=\"hljs-comment\">## external database will be used, otherwise Dolphinscheduler&#x27;s database will be used.</span>\n<span class=\"hljs-attr\">externalDatabase:</span>\n  <span class=\"hljs-attr\">type:</span> <span class=\"hljs-string\">&quot;postgresql&quot;</span>\n  <span class=\"hljs-attr\">driver:</span> <span class=\"hljs-string\">&quot;org.postgresql.Driver&quot;</span>\n  <span class=\"hljs-attr\">host:</span> <span class=\"hljs-string\">&quot;192.168.1.100&quot;</span>\n  <span class=\"hljs-attr\">port:</span> <span class=\"hljs-string\">&quot;5432&quot;</span>\n  <span class=\"hljs-attr\">username:</span> <span class=\"hljs-string\">&quot;admin&quot;</span>\n  <span class=\"hljs-attr\">password:</span> <span class=\"hljs-string\">&quot;password&quot;</span>\n  <span class=\"hljs-attr\">database:</span> <span class=\"hljs-string\">&quot;dolphinscheduler&quot;</span>\n  <span class=\"hljs-attr\">params:</span> <span class=\"hljs-string\">&quot;characterEncoding=utf8&quot;</span>\n  \n<span class=\"hljs-comment\">## If not exists external zookeeper, by default, Dolphinscheduler&#x27;s zookeeper will use it.</span>\n<span class=\"hljs-attr\">zookeeper:</span>\n  <span class=\"hljs-attr\">enabled:</span> <span class=\"hljs-literal\">false</span>\n  <span class=\"hljs-attr\">fourlwCommandsWhitelist:</span> <span class=\"hljs-string\">&quot;srvr,ruok,wchs,cons&quot;</span>\n  <span class=\"hljs-attr\">persistence:</span>\n    <span class=\"hljs-attr\">enabled:</span> <span class=\"hljs-literal\">false</span>\n    <span class=\"hljs-attr\">size:</span> <span class=\"hljs-string\">&quot;20Gi&quot;</span>\n    <span class=\"hljs-attr\">storageClass:</span> <span class=\"hljs-string\">&quot;storage-nfs&quot;</span>\n  <span class=\"hljs-attr\">zookeeperRoot:</span> <span class=\"hljs-string\">&quot;/dolphinscheduler&quot;</span>\n\n<span class=\"hljs-comment\">## If exists external zookeeper, and set zookeeper.enable value to false.</span>\n<span class=\"hljs-comment\">## If zookeeper.enable is false, Dolphinscheduler&#x27;s zookeeper will use it.</span>\n<span class=\"hljs-attr\">externalZookeeper:</span>\n  <span class=\"hljs-attr\">zookeeperQuorum:</span> <span class=\"hljs-string\">&quot;zookeeper-0.zookeeper-headless.zookeeper.svc.cluster.local:2181,zookeeper-1.zookeeper-headless.zookeeper.svc.cluster.local:2181,zookeeper-2.zookeeper-headless.zookeeper.svc.cluster.local:2181&quot;</span>\n  <span class=\"hljs-attr\">zookeeperRoot:</span> <span class=\"hljs-string\">&quot;/dolphinscheduler&quot;</span>\n</code></pre>\n</li>\n</ul>\n<h2>基于argo-cd的Gitops部署方式</h2>\n<p>argo-cd是基于Kubernetes 的声明式Gitops持续交付工具。argo-cd是CNCF的孵化项目，Gitops的最佳实践工具。关于Gitops的解释可以参考https://about.gitlab.com/topics/gitops/</p>\n<div align=center>\n<img src=\"/img/2022-02-22/3.png\"/>\n</div>\n<p>Gitops可以为Apache DolphinScheduler的实施带来以下优点。</p>\n<ul>\n<li>图形化安装集群化的软件，一键安装；</li>\n<li>Git记录全发版流程，一键回滚；</li>\n<li>便捷的海豚工具日志查看；</li>\n</ul>\n<p>使用argo-cd的实施安装步骤：</p>\n<ul>\n<li>\n<p>从GitHub上下载Apache DolphinScheduler源码，修改value文件，参考上个章节helm安装需要修改的内容；</p>\n</li>\n<li>\n<p>把修改后的源码目录新建Git项目，并且push到公司内部的Gitlab中，GitHub源码的目录名为docker/Kubernetes/dolphinscheduler；</p>\n</li>\n<li>\n<p>在argo-cd中配置Gitlab信息，我们使用https的模式；</p>\n</li>\n</ul>\n<div align=center>\n<img src=\"/img/2022-02-22/4.png\"/>\n</div>\n<ul>\n<li>argo-cd新建部署工程，填写相关信息</li>\n</ul>\n<div align=center>\n<img src=\"/img/2022-02-22/5.png\"/>\n</div>\n<div align=center>\n<img src=\"/img/2022-02-22/6.png\"/>\n</div>\n<ul>\n<li>对Git中的部署信息进行刷新和拉取，实现最后的部署工作；可以看到pod，configmap，secret，service等等资源全自动拉起。</li>\n</ul>\n<div align=center>\n<img src=\"/img/2022-02-22/7.png\"/>\n</div>\n<div align=center>\n<img src=\"/img/2022-02-22/8.png\"/>\n</div>\n<ul>\n<li>\n<p>通过kubectl命令可以看到相关资源信息；</p>\n<pre><code class=\"language-shell\">[root@tpk8s-master01 ~]# kubectl get po -n ds139\nNAME                                     READY   STATUS    RESTARTS   AGE\ndolphinscheduler-alert-96c74dc84-72cc9   1/1     Running   0          22m\ndolphinscheduler-api-78db664b7b-gsltq    1/1     Running   0          22m\ndolphinscheduler-master-0                1/1     Running   0          22m\ndolphinscheduler-master-1                1/1     Running   0          22m\ndolphinscheduler-master-2                1/1     Running   0          22m\ndolphinscheduler-worker-0                1/1     Running   0          22m\ndolphinscheduler-worker-1                1/1     Running   0          22m\ndolphinscheduler-worker-2                1/1     Running   0          22m\n\n[root@tpk8s-master01 ~]# kubectl get statefulset -n ds139\nNAME                      READY   AGE\ndolphinscheduler-master   3/3     22m\ndolphinscheduler-worker   3/3     22m\n\n[root@tpk8s-master01 ~]# kubectl get cm -n ds139\nNAME                      DATA   AGE\ndolphinscheduler-alert    15     23m\ndolphinscheduler-api      1      23m\ndolphinscheduler-common   29     23m\ndolphinscheduler-master   10     23m\ndolphinscheduler-worker   7      23m\n\n[root@tpk8s-master01 ~]# kubectl get service -n ds139\nNAME                               TYPE        CLUSTER-IP    EXTERNAL-IP   PORT(S)              AGE\ndolphinscheduler-api               ClusterIP   10.43.238.5   &lt;none&gt;        12345/TCP            23m\ndolphinscheduler-master-headless   ClusterIP   None          &lt;none&gt;        5678/TCP             23m\ndolphinscheduler-worker-headless   ClusterIP   None          &lt;none&gt;        1234/TCP,50051/TCP   23m\n\n[root@tpk8s-master01 ~]# kubectl get ingress -n ds139\nNAME               CLASS    HOSTS           ADDRESS\ndolphinscheduler   &lt;none&gt;   ds139.abc.com   \n\n</code></pre>\n</li>\n<li>\n<p>可以看到所有的pod都分撒在Kubernetes集群中不同的host上，例如worker1和2都在不同的节点上。</p>\n</li>\n</ul>\n<div align=center>\n<img src=\"/img/2022-02-22/9.png\"/>\n</div>\n<div align=center>\n<img src=\"/img/2022-02-22/10.png\"/>\n</div>\n<ul>\n<li>我们配置了ingress，公司内部配置了泛域名就可以方便的使用域名进行访问；</li>\n</ul>\n<div align=center>\n<img src=\"/img/2022-02-22/11.png\"/>\n</div>\n<p>可以登录域名进行访问。</p>\n<div align=center>\n<img src=\"/img/2022-02-22/12.png\"/>\n</div>\n<p>具体配置可以修改value文件中的内容：</p>\n<pre><code class=\"language-yaml\"><span class=\"hljs-attr\">ingress:</span>\n  <span class=\"hljs-attr\">enabled:</span> <span class=\"hljs-literal\">true</span>\n  <span class=\"hljs-attr\">host:</span> <span class=\"hljs-string\">&quot;ds139.abc.com&quot;</span>\n  <span class=\"hljs-attr\">path:</span> <span class=\"hljs-string\">&quot;/dolphinscheduler&quot;</span>\n  <span class=\"hljs-attr\">tls:</span>\n    <span class=\"hljs-attr\">enabled:</span> <span class=\"hljs-literal\">false</span>\n    <span class=\"hljs-attr\">secretName:</span> <span class=\"hljs-string\">&quot;dolphinscheduler-tls&quot;</span>\n</code></pre>\n<ul>\n<li>方便查看Apache DolphinScheduler各个组件的内部日志：</li>\n</ul>\n<div align=center>\n<img src=\"/img/2022-02-22/13.png\"/>\n</div>\n<ul>\n<li>对部署好的系统进行检查，3个master，3个worker，zookeeper都配置正常；</li>\n</ul>\n<div align=center>\n<img src=\"/img/2022-02-22/14.png\"/>\n</div>\n<div align=center>\n<img src=\"/img/2022-02-22/15.png\"/>\n</div>\n<div align=center>\n<img src=\"/img/2022-02-22/16.png\"/>\n</div>\n<ul>\n<li>\n<p>使用argo-cd可以非常方便的进行修改master，worker，api，alert等组件的副本数量，海豚的helm配置也预留了cpu和内存的设置信息。这里我们修改value中的副本值。修改后，提交公司内部Gitlab。</p>\n<pre><code class=\"language-yaml\"><span class=\"hljs-attr\">master:</span>\n  <span class=\"hljs-comment\">## PodManagementPolicy controls how pods are created during initial scale up, when replacing pods on nodes, or when scaling down.</span>\n  <span class=\"hljs-attr\">podManagementPolicy:</span> <span class=\"hljs-string\">&quot;Parallel&quot;</span>\n  <span class=\"hljs-comment\">## Replicas is the desired number of replicas of the given Template.</span>\n  <span class=\"hljs-attr\">replicas:</span> <span class=\"hljs-string\">&quot;5&quot;</span>\n  \n<span class=\"hljs-attr\">worker:</span>\n  <span class=\"hljs-comment\">## PodManagementPolicy controls how pods are created during initial scale up, when replacing pods on nodes, or when scaling down.</span>\n  <span class=\"hljs-attr\">podManagementPolicy:</span> <span class=\"hljs-string\">&quot;Parallel&quot;</span>\n  <span class=\"hljs-comment\">## Replicas is the desired number of replicas of the given Template.</span>\n  <span class=\"hljs-attr\">replicas:</span> <span class=\"hljs-string\">&quot;5&quot;</span>\n  \n  \n<span class=\"hljs-attr\">alert:</span>\n  <span class=\"hljs-comment\">## Number of desired pods. This is a pointer to distinguish between explicit zero and not specified. Defaults to 1.</span>\n  <span class=\"hljs-attr\">replicas:</span> <span class=\"hljs-string\">&quot;3&quot;</span>\n  \n<span class=\"hljs-attr\">api:</span>\n  <span class=\"hljs-comment\">## Number of desired pods. This is a pointer to distinguish between explicit zero and not specified. Defaults to 1.</span>\n  <span class=\"hljs-attr\">replicas:</span> <span class=\"hljs-string\">&quot;3&quot;</span>\n</code></pre>\n</li>\n</ul>\n<ul>\n<li>只需要在argo-cd点击sync同步，对应的pods都按照需求进行了增加</li>\n</ul>\n<div align=center>\n<img src=\"/img/2022-02-22/17.png\"/>\n</div>\n<div align=center>\n<img src=\"/img/2022-02-22/18.png\"/>\n</div>\n<pre><code>[root@tpk8s-master01 ~]# kubectl get po -n ds139\nNAME                                     READY   STATUS    RESTARTS   AGE\ndolphinscheduler-alert-96c74dc84-72cc9   1/1     Running   0          43m\ndolphinscheduler-alert-96c74dc84-j6zdh   1/1     Running   0          2m27s\ndolphinscheduler-alert-96c74dc84-rn9wb   1/1     Running   0          2m27s\ndolphinscheduler-api-78db664b7b-6j8rj    1/1     Running   0          2m27s\ndolphinscheduler-api-78db664b7b-bsdgv    1/1     Running   0          2m27s\ndolphinscheduler-api-78db664b7b-gsltq    1/1     Running   0          43m\ndolphinscheduler-master-0                1/1     Running   0          43m\ndolphinscheduler-master-1                1/1     Running   0          43m\ndolphinscheduler-master-2                1/1     Running   0          43m\ndolphinscheduler-master-3                1/1     Running   0          2m27s\ndolphinscheduler-master-4                1/1     Running   0          2m27s\ndolphinscheduler-worker-0                1/1     Running   0          43m\ndolphinscheduler-worker-1                1/1     Running   0          43m\ndolphinscheduler-worker-2                1/1     Running   0          43m\ndolphinscheduler-worker-3                1/1     Running   0          2m27s\ndolphinscheduler-worker-4                1/1     Running   0          2m27s\n</code></pre>\n<h2>Apache DolphinScheduler与s3对象存储技术集成</h2>\n<p>许多同学在海豚的社区中提问，如何配置s3 minio的集成。这里给出基于Kubernetes的helm配置。</p>\n<ul>\n<li>\n<p>修改value中s3的部分，建议使用ip+端口指向minio服务器。</p>\n<pre><code class=\"language-yaml\"><span class=\"hljs-attr\">common:</span>\n  <span class=\"hljs-comment\">## Configmap</span>\n  <span class=\"hljs-attr\">configmap:</span>\n    <span class=\"hljs-attr\">DOLPHINSCHEDULER_OPTS:</span> <span class=\"hljs-string\">&quot;&quot;</span>\n    <span class=\"hljs-attr\">DATA_BASEDIR_PATH:</span> <span class=\"hljs-string\">&quot;/tmp/dolphinscheduler&quot;</span>\n    <span class=\"hljs-attr\">RESOURCE_STORAGE_TYPE:</span> <span class=\"hljs-string\">&quot;S3&quot;</span>\n    <span class=\"hljs-attr\">RESOURCE_UPLOAD_PATH:</span> <span class=\"hljs-string\">&quot;/dolphinscheduler&quot;</span>\n    <span class=\"hljs-attr\">FS_DEFAULT_FS:</span> <span class=\"hljs-string\">&quot;s3a://dfs&quot;</span>\n    <span class=\"hljs-attr\">FS_S3A_ENDPOINT:</span> <span class=\"hljs-string\">&quot;http://192.168.1.100:9000&quot;</span>\n    <span class=\"hljs-attr\">FS_S3A_ACCESS_KEY:</span> <span class=\"hljs-string\">&quot;admin&quot;</span>\n    <span class=\"hljs-attr\">FS_S3A_SECRET_KEY:</span> <span class=\"hljs-string\">&quot;password&quot;</span>\n</code></pre>\n</li>\n<li>\n<p>minio中存放海豚文件的bucket名字是dolphinscheduler，这里新建文件夹和文件进行测试。</p>\n</li>\n</ul>\n<div align=center>\n<img src=\"/img/2022-02-22/19.png\"/>\n</div>\n<div align=center>\n<img src=\"/img/2022-02-22/19-1.png\"/>\n</div>\n<h2>Apache DolphinScheduler与 Kube-prometheus 的技术集成</h2>\n<ul>\n<li>\n<p>我们在Kubernetes使用kube-prometheus operator技术，实现了在部署海豚后，自动实现了对海豚各个组件的资源监控。</p>\n</li>\n<li>\n<p>请注意kube-prometheus的版本，需要对应Kubernetes主版本。<a href=\"https://GitHub.com/prometheus-operator/kube-prometheus\">https://GitHub.com/prometheus-operator/kube-prometheus</a></p>\n</li>\n</ul>\n<div align=center>\n<img src=\"/img/2022-02-22/20.png\"/>\n</div>\n<div align=center>\n<img src=\"/img/2022-02-22/21.png\"/>\n</div>\n<div align=center>\n<img src=\"/img/2022-02-22/18.png\"/>\n</div>\n<div align=center>\n<img src=\"/img/2022-02-22/22.png\"/>\n</div>\n<h2>Apache DolphinScheduler与 Service Mesh 的技术集成</h2>\n<ul>\n<li>\n<p>通过 Service Mesh 技术可以实现对海豚内部的服务调用，以及海豚api外部调用的可观测性分析，以实现Apache DolphinScheduler产品的自身服务优化。</p>\n</li>\n<li>\n<p>我们使用linkerd作为Service Mesh的产品进行集成，linkerd也是CNCF优秀的毕业项目。</p>\n</li>\n</ul>\n <div align=center>\n<img src=\"/img/2022-02-22/23.png\"/>\n</div>\n<ul>\n<li>\n<p>只需要在海豚helm的value文件中修改annotations，重新部署，就可以快速实现mesh proxy sidecar的注入。可以对master，worker，api，alert等组件都注入。</p>\n<pre><code class=\"language-yaml\">  <span class=\"hljs-attr\">annotations:</span> <span class=\"hljs-comment\">#{}</span>\n    <span class=\"hljs-attr\">linkerd.io/inject:</span> <span class=\"hljs-string\">enabled</span>\n</code></pre>\n</li>\n</ul>\n<p>可以观察组件之间的服务通信质量，每秒请求的次数等等。</p>\n<div align=center>\n<img src=\"/img/2022-02-22/24.png\"/>\n</div>\n<div align=center>\n<img src=\"/img/2022-02-22/25.png\"/>\n</div>\n<h2>未来Apache DolphinScheduler基于云原生技术的展望</h2>\n<p>Apache DolphinScheduler作为面向新一代云原生大数据工具，未来可以在Kubernetes生态集成更多的优秀工具和特性，满足更多的用户群体和场景。</p>\n<ul>\n<li>\n<p>和argo-workflow的集成，可以通过api，cli等方式在Apache DolphinScheduler中调用argo-workflow单个作业，dag作业，以及周期性作业；</p>\n</li>\n<li>\n<p>使用hpa的方式，自动扩缩容worker，实现无人干预的水平扩展方式；</p>\n</li>\n<li>\n<p>集成Kubernetes的spark operator和Hadoopoperator工具，全面的云原生化；</p>\n</li>\n<li>\n<p>实现多云和多集群的分布式作业调度；</p>\n</li>\n<li>\n<p>采用sidecar实现定期删除worker作业日志；</p>\n</li>\n</ul>\n<div align=center>\n<img src=\"/img/2022-02-22/26.png\"/>\n</div>\n",
  "link": "/dist/zh-cn/blog/DolphinScheduler_Kubernetes_Technology_in_action.html",
  "meta": {}
}