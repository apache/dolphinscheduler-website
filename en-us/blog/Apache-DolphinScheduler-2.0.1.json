{
  "filename": "Apache-DolphinScheduler-2.0.1.md",
  "__html": "<h2>Apache DolphinScheduler 2.0.1 is here, and the highly anticipated one-click upgrade and plug-in finally come!</h2>\n<p>Good news! Apache DolphinScheduler 2.0.1 version is officially released today!</p>\n<p>In this version, DolphinScheduler has undergone a microkernel + plug-in architecture improvement, 70% of the code has\nbeen refactored, and the long-awaited plug-in function has also been emphatically optimized. In addition, there are many\nhighlights in this upgrade, such as a one-click upgrade to the latest version, &quot;de-ZK&quot; in the registration center, and\nnew task parameter transfer functions, etc..</p>\n<p>Download Apache DolphinScheduler 2.0.1：<a href=\"https://dolphinscheduler.apache.org/zh-cn/download/download.html\">https://dolphinscheduler.apache.org/zh-cn/download/download.html</a></p>\n<p>The workflow execution process activities of Apache DolphinScheduler 2.0.1 are shown in the following figure:</p>\n<div align=center>\n<img src=\"https://s1.imgpp.com/2021/12/20/master-process-2.0-en.png\"/>\n</div>\n<p>Start process activity diagram</p>\n<p>Version 2.0.1 enhanced the system's processing capabilities by optimizing the kernel, thereby greatly improving\nperformance. The new UI interface also greatly improved the user experience. More importantly, there are two major\nchanges in version 2.0.1: plug-in and refactoring.\n<a href=\"https://dolphinscheduler.apache.org/en-us/docs/latest/user_doc/guide/upgrade.html\">https://dolphinscheduler.apache.org/en-us/docs/latest/user_doc/guide/upgrade.html</a></p>\n<h2>01 Plug-in</h2>\n<p>Previously, some users had feedback that they hoped that Apache DolphinScheduler could be optimized for plug-inization.\nIn respond, Apache DolphinScheduler 2.0.1 has optimized plug-in function, adding alarm plug-ins, registry plug-ins, and\ntask plug-in management functions. With plug-in, users can meet their own functional needs more flexibly, customize\ndevelopment task components based on interfaces more simply, and seamlessly migrate user task components to a higher\nversion of DolphinScheduler. DolphinScheduler is in the process of microkernel + plug-in architecture improvement. All\ncore capabilities such as tasks, alarm components, data sources, resource storage, registry, etc. will be designed as\nextension points. We hope to improve the flexibility and friendliness of Apache DolphinScheduler itself through SPI. The\nrelated code can refer to the dolphinscheduler-spi module, and the extended interfaces of related plug-ins are also\nunder this module. When users need to deploy the plug-in of related functions, it is recommended to read the code of\nthis module first. Of course, it is also recommended that you read the document to save time. We have adopted an\nexcellent front-end module form-create, which supports the generation of front-end UI components based on json. If\nplug-in development involves the front-end, we will use json to generate related front-end UI modules. The plug-in\nparameters are encapsulated in org.apache.dolphinscheduler.spi.params, which converts all relevant parameters into\ncorresponding json. This means that you can completely draw front-end modules (mainly refers to forms) by Java.</p>\n<h3>1 Alarm plug-in</h3>\n<p>Taking the alert plug-in as an example, Apache DolphinScheduler 2.0.1 enables the loading of related plug-ins when the\nalert-server starts. Alert provides a variety of plug-in configuration methods and currently has built-in alert plug-ins\nsuch as Email, DingTalk, EnterpriseWeChat, and Script. When the plug-in module development work is completed, it can be\nenabled through a simple configuration.</p>\n<h3>2 Multi-registry modules</h3>\n<p>In Apache DolphinScheduler 1.X, the Zookeeper module plays a very important role , including monitoring and discovery of\nmaster/worker services, disconnection alarms, fault tolerance notification and so on. In version 2.0.1, we gradually &quot;\nde-ZK&quot; in the registry, weakening the role of Zookeeper, and adding plug-in management functions. In plug-in management,\nusers can increase the support of registry centers such as ETCD, making Apache Dolphinscheduler more flexible and\nadaptable to more complex user needs.</p>\n<h3>3 Task module plugin</h3>\n<p>The new version also adds the task plug-in function, which enhances the isolation function of different task components.\nWhen a user develops a custom plug-in, he only needs to implement the plug-in interface. It mainly includes creating\ntasks (task initialization, task running, etc.) and task cancellation.</p>\n<p>If it is a Yarn task, you need to implement AbstractYarnTask. At present, developers need to use Vue to develop and\ndeploy the front end of the task plug-in. In subsequent versions, we will implement the automatic drawing of front-end\nmodules by Java.</p>\n<h2>02 Refactor</h2>\n<p>So far, Apache DolphinScheduler has refactored about 70% of the code and achieved a comprehensive upgrade.</p>\n<h3>1 Master core optimization</h3>\n<p>In the upgrade, we refactor the execution process of the Master, changing the previous state polling monitoring to an\nevent notification mechanism, which greatly reduces the polling pressure of the database; removing the global lock,\nadding the fragmentation processing mechanism of the Master, and changing the sequence Read and write commands to\nparallel processing, which enhances the horizontal scalability of the Master; optimizes the workflow processing flow\nreduces the use of the thread pool and greatly increases the number of workflows processed by a single Master; adds the\ncache mechanism, optimizes the database connection method, and simplifies the processing process, reducing unnecessary\ntime-consuming operations, etc.</p>\n<h3>2 Workflow and task decoupling</h3>\n<p>In Apache DolphinScheduler 1.x version, tasks and task relationships are saved in the workflow definition table in the\nform of large json. If a workflow is very large, (for example reaches 100 to 1000 tasks), the json will be too big to be\nparsed when in use. This process is more performance-consuming, and tasks cannot be reused; on the other hand, there is\nno good implementation solution in workflow version and task version for big json.</p>\n<p>Therefore, in the new version, we have decoupled the workflow and tasks, added a correlation chart between tasks and\nworkflow, and added a log table to save the historical version of workflow definitions and task definition, which\nImproves the efficiency of workflow operation.</p>\n<p>The operation flow chart of the workflow and tasks under the API module are shown as below:</p>\n<div align=center>\n<img src=\"https://s1.imgpp.com/2021/12/20/3.png\"/>\n</div>\n<h2>03 Automatic Version Upgrade Function</h2>\n<p>Automatic version upgrade finally comes true in version 2.0.1. The users can automatically upgrade Apache\nDolphinScheduler from version 1. x to version 2.0.1 by one line usage script, and you can use the new version to run the\nprevious workflow without perception:</p>\n<pre><code>sh ./script/create-dolphinscheduler.sh\n</code></pre>\n<p>For specific upgrade documentation, please refer to:</p>\n<p><a href=\"https://dolphinscheduler.apache.org/en-us/docs/latest/user_doc/guide/upgrade.html\">https://dolphinscheduler.apache.org/en-us/docs/latest/user_doc/guide/upgrade.html</a></p>\n<p>In addition, future versions of Apache DolphinScheduler can be automatically upgraded, saving the trouble of manual\nupgrades.</p>\n<h2>04 List of New Features</h2>\n<p>Details of the new features of Apache DolphinScheduler 2.0.1 are as follows:</p>\n<h3>1 New Standalone service</h3>\n<p>StandAlone Server is a service created to allow users to quickly experience the product. The registry and database\nH2-DataBase and Zk-TestServer are built-in. After modification, you can start StandAloneServer with one key to\ndebugging.</p>\n<p>If you want a quick experience, after decompressing the installation package, you only need to configure the JDK\nenvironment to start the Apache DolphinScheduler system with one click, thereby reducing configuration costs and\nimproving R&amp;D efficiency.</p>\n<p>For detailed usage documentation, please refer to:</p>\n<p><a href=\"https://dolphinscheduler.apache.org/en-us/docs/latest/user_doc/guide/installation/standalone.html\">https://dolphinscheduler.apache.org/en-us/docs/latest/user_doc/guide/installation/standalone.html</a></p>\n<p>Or use Docker to deploy all services with one\nclick: <a href=\"https://dolphinscheduler.apache.org/en-us/docs/latest/user_doc/guide/installation/docker.html\">https://dolphinscheduler.apache.org/en-us/docs/latest/user_doc/guide/installation/docker.html</a></p>\n<h3>2 Task parameter transfer function</h3>\n<p>Currently, the transfer between shell tasks and sql tasks is supported. Passing parameters between shell tasks:\nSet an out variable &quot;trans&quot; in the previous &quot;create_parameter&quot; task: echo'${setValue(trans=hello trans)}'</p>\n<div align=center>\n<img src=\"https://s1.imgpp.com/2021/12/17/323f6a18d8a1d2f2d8fdcb5687c264b5.png\"/>\n</div>\nOnce Keyword: \"${setValue(key=value)}\" is detected in the task log of the current task, the system will automatically parse the variable transfer value, in the post-task, you can directly use the \"trans\" variable:\n<div align=center>\n<img src=\"https://s1.imgpp.com/2021/12/17/8be29339b73b594dc05a6b832d9330ec.png\"/>\n</div>\n<p>The parameter passing of the SQL task:\nThe name of the custom variable prop of the SQL task needs to be consistent with the field name, and the variable will\nselect the value corresponding to the column with the same variable name in the column name in the SQL query result. The\noutput of user number:</p>\n<div align=center>\n<img src=\"https://s1.imgpp.com/2021/12/17/85bc5216c01ca958cdf11d4bd555c8a6.png\"/>\n</div>\n<p>Use the variable &quot;cnt&quot; in downstream tasks:</p>\n<div align=center>\n<img src=\"https://s1.imgpp.com/2021/12/17/4278d0b7f833b64f24fc3d6122287454.png\"/>\n</div>\n<p>2.0.1 adds switch task and pigeon task components:</p>\n<ul>\n<li>switch task</li>\n</ul>\n<p>Setting the judgment condition in the switch task can realize the effect of running different conditional branches\naccording to different conditional judgment results. For example, there are three tasks, the dependency is A -&gt; B\n-&gt; [C, D], where task_a is the shell task and task_b is the switch task.</p>\n<p>In task A, a global variable named id is defined through a global variable, and the declaration method\nis <code>echo'${setValue(id=1)}'</code>.</p>\n<p>Task B adds conditions and uses the global variables declared upstream to achieve conditional judgment (global variables\nthat exist when the Switch is running are just fine, which means that they can be global variables that are not directly\ngenerated upstream). Next, we set id as 1, run task C, and others run task D.</p>\n<p>Configure task C to run when the global variable id=1. Then edit ${id} == 1 in the condition of task B, and select C for\nbranch circulation. For other tasks, select D in the branch circulation.</p>\n<div align=center>\n<img src=\"https://s1.imgpp.com/2021/12/17/636f53ddc809f028ffdfc18fd08b5828.md.jpg\"/>\n</div>\n<p>-pigeon task</p>\n<p>The pigeon task is a task component that can be docked with third-party systems. It can trigger task execution, cancel\ntask execution, obtain task status, and obtain task logs. The pigeon task needs to configure the API address of the\nabove task operation and the corresponding interface parameters in the configuration file. Enter a target task name in\nthe task component to connect to the third-party system and can operate the task of the third-party system in Apache\nDolphinScheduler.</p>\n<h3>3 Adds environmental management function</h3>\n<p>The default environment configuration is dolphinscheduler_env.sh.</p>\n<p>Configure the worker running environment online. A worker can specify multiple environments, and each environment is\nequivalent to the dolphinscheduler_env.sh file.</p>\n<div align=center>\n<img src=\"https://s1.imgpp.com/2021/12/17/ef8b444c6dbebe397daaaa3bbadf743f.png\"/>\n</div>\n<p>When creating a task, select the worker group and the corresponding environment variables. When the task is executed,\nthe worker will execute the task in the corresponding execution environment.</p>\n<h2>05 Optimization item</h2>\n<h3>1 Optimize the RestApi</h3>\n<p>We have updated the new RestApi specification and re-optimized the API part by the specification, making it easier for\nusers to use the API.</p>\n<h3>2 Optimize the workflow version management</h3>\n<p>We optimized the workflow version management function and increased the historical version of the workflow and tasks.</p>\n<h3>3 Optimize worker group management function</h3>\n<p>In version 2.0, the worker group management function is completed. Users can modify the group information of the worker\nthrough the page configuration, saving the troubåle to modify the configuration file on the server and restart the\nworker.</p>\n<p>After the optimization, each worker node will belong to its worker group, and be grouped to default by default. When the\ntask is executed, the task can be assigned to the designated worker group, and finally run by the worker node in the\ngroup.</p>\n<p>There are two ways to modify the worker group:</p>\n<p>Open the &quot;conf/worker.properties&quot; configuration file on the worker node to be grouped, and modify the worker. groups\nparameter. The worker group to which the worker belongs can be modified during operation. If the modification is\nsuccessful, the worker will use this newly created group, ignoring the configuration in worker. properties. Modify step\nby step: Security Center -&gt; Worker Group Management -&gt; Click'New Worker Group' -&gt; Enter'Group Name' -&gt; Select Existing\nWorker -&gt; Click'Submit'.</p>\n<p>Other optimization issues:</p>\n<p>When starting the workflow, you can modify the startup parameters; Added workflow state automatically-launching when\nsaving the workflow; Optimized the results returned by the API, and speeded up the page loading speed when creating a\nworkflow; Speeded ​​up the loading of workflow instance pages; Optimized the display information of the workflow\nrelationship page; Optimized the import and export function, supporting cross-system import and export workflow;\nOptimized some API operations, such as adding several interface methods, task deletion check, etc.</p>\n<h2>06 Changelogs</h2>\n<p>In addition, Apache DolphinScheduler 2.0.1 also fixes some bugs, including:</p>\n<p>Fixed the problem that netty client would create multiple pipes; Fixed the problem of importing workflow definition\nerrors; Fixed the problem that the task code would be obtained repeatedly; Fix the problem that the Hive data source\nconnection fails when Kerberos is used; Fix the problem that the Standalone service fails to start; Fix the problem that\nthe alarm group display failure; Fix the problem of abnormal file upload; Fix the problem that the Switch task fails to\nrun; Fix the problem of invalid workflow timeout strategy; Fix the problem that the SQL task cannot send mail.</p>\n<h2>07 Acknowledgements</h2>\n<p>Thanks to the 289 community contributors who participated in the optimization and improvement of version 2.0.1 (in no\nparticular order)!</p>\n<div align=center>\n<img src=\"https://s1.imgpp.com/2021/12/17/2020b4f57e33734414a11149704ded92.png\"/>\n</div>\n<div align=center>\n<img src=\"https://s1.imgpp.com/2021/12/17/1825b6945d5845233b7389479ba6c074.png\"/>\n</div>\n",
  "link": "/dist/en-us/blog/Apache-DolphinScheduler-2.0.1.html",
  "meta": {
    "title": "Apache DolphinScheduler 2.0.1 is here, and the highly anticipated one-click upgrade and plug-in finally come!",
    "keywords": "Apache,DolphinScheduler,scheduler,big data,ETL,airflow,hadoop，orchestration, dataops,2.0.1",
    "description": "Good news! Apache DolphinScheduler 2.0.1 version is officially released today!"
  }
}