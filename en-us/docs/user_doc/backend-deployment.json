{
  "filename": "backend-deployment.md",
  "__html": "<h1>Backend Deployment Document</h1>\n<p>There are two deployment modes for the backend:</p>\n<ul>\n<li>automatic deployment</li>\n<li>source code compile and then deployment</li>\n</ul>\n<h2>Preparations</h2>\n<p>Download the latest version of the installation package, download address： <a href=\"https://gitee.com/easyscheduler/EasyScheduler/attach_files/\">gitee download</a> or <a href=\"https://github.com/analysys/EasyScheduler/releases\">github download</a>, download escheduler-backend-x.x.x.tar.gz(back-end referred to as escheduler-backend),escheduler-ui-x.x.x.tar.gz(front-end referred to as escheduler-ui)</p>\n<h4>Preparations 1: Installation of basic software (self-installation of required items)</h4>\n<ul>\n<li><a href=\"http://geek.analysys.cn/topic/124\">Mysql</a> (5.5+) :  Mandatory</li>\n<li><a href=\"https://www.oracle.com/technetwork/java/javase/downloads/index.html\">JDK</a> (1.8+) :  Mandatory</li>\n<li><a href=\"https://www.jianshu.com/p/de90172ea680\">ZooKeeper</a>(3.4.6+) ：Mandatory</li>\n<li><a href=\"https://blog.csdn.net/Evankaka/article/details/51612437\">Hadoop</a>(2.6+) ：Optionally, if you need to use the resource upload function, MapReduce task submission needs to configure Hadoop (uploaded resource files are currently stored on Hdfs)</li>\n<li><a href=\"https://staroon.pro/2017/12/09/HiveInstall/\">Hive</a>(1.2.1) :   Optional, hive task submission needs to be installed</li>\n<li>Spark(1.x,2.x) :  Optional, Spark task submission needs to be installed</li>\n<li>PostgreSQL(8.2.15+) : Optional, PostgreSQL PostgreSQL stored procedures need to be installed</li>\n</ul>\n<pre><code> Note: Easy Scheduler itself does not rely on Hadoop, Hive, Spark, PostgreSQL, but only calls their Client to run the corresponding tasks.\n</code></pre>\n<h4>Preparations 2: Create deployment users</h4>\n<ul>\n<li>Deployment users are created on all machines that require deployment scheduling, because the worker service executes jobs in <code>sudo-u {linux-user}</code>, so deployment users need sudo privileges and are confidential.</li>\n</ul>\n<pre><code>vi /etc/sudoers\n\n# For example, the deployment user is an escheduler account\nescheduler  ALL=(ALL)       NOPASSWD: NOPASSWD: ALL\n\n# And you need to comment out the Default requiretty line\n#Default requiretty\n</code></pre>\n<h4>Preparations 3: SSH Secret-Free Configuration</h4>\n<p>Configure SSH secret-free login on deployment machines and other installation machines. If you want to install easyscheduler on deployment machines, you need to configure native password-free login itself.</p>\n<ul>\n<li><a href=\"http://geek.analysys.cn/topic/113\">Connect the host and other machines SSH</a></li>\n</ul>\n<h4>Preparations 4: database initialization</h4>\n<ul>\n<li>\n<p>Create databases and accounts</p>\n<p>Execute the following command to create database and account</p>\n<pre><code>CREATE DATABASE escheduler DEFAULT CHARACTER SET utf8 DEFAULT COLLATE utf8_general_ci;\nGRANT ALL PRIVILEGES ON escheduler.* TO '{user}'@'%' IDENTIFIED BY '{password}';\nGRANT ALL PRIVILEGES ON escheduler.* TO '{user}'@'localhost' IDENTIFIED BY '{password}';\nflush privileges;\n</code></pre>\n</li>\n<li>\n<p>creates tables and imports basic data\nModify the following attributes in ./conf/dao/data_source.properties</p>\n<pre><code>    spring.datasource.url\n    spring.datasource.username\n    spring.datasource.password\n</code></pre>\n<p>Execute scripts for creating tables and importing basic data</p>\n<pre><code>sh ./script/create-escheduler.sh\n</code></pre>\n</li>\n</ul>\n<h4>Preparations 5: Modify the deployment directory permissions and operation parameters</h4>\n<pre><code> instruction of escheduler-backend directory \n</code></pre>\n<pre><code class=\"language-directory\">bin : Basic service startup script\nconf : Project Profile\nlib : The project relies on jar packages, including individual module jars and third-party jars\nscript :  Cluster Start, Stop and Service Monitor Start and Stop scripts\nsql : The project relies on SQL files\ninstall.sh :  One-click deployment script\n</code></pre>\n<ul>\n<li>\n<p>Modify permissions (please modify the 'deployUser' to the corresponding deployment user) so that the deployment user has operational privileges on the escheduler-backend directory</p>\n<p><code>sudo chown -R deployUser:deployUser escheduler-backend</code></p>\n</li>\n<li>\n<p>Modify the <code>.escheduler_env.sh</code> environment variable in the conf/env/directory</p>\n</li>\n<li>\n<p>Modify deployment parameters (depending on your server and business situation):</p>\n</li>\n<li>\n<p>Modify the parameters in <strong><a href=\"http://install.sh\">install.sh</a></strong> to replace the values required by your business</p>\n<ul>\n<li>MonitorServerState switch variable, added in version 1.0.3, controls whether to start the self-start script (monitor master, worker status, if off-line will start automatically). The default value of &quot;false&quot; means that the self-start script is not started, and if it needs to start, it is changed to &quot;true&quot;.</li>\n<li>'hdfsStartupSate' switch variable controls whether to start hdfs\nThe default value of &quot;false&quot; means not to start hdfs\nChange the variable to 'true' if you want to use hdfs, you also need to create the hdfs root path by yourself, that 'hdfsPath' in <a href=\"http://install.sh\">install.sh</a>.</li>\n</ul>\n</li>\n<li>\n<p>If you use hdfs-related functions, you need to copy<strong>hdfs-site.xml</strong> and <strong>core-site.xml</strong> to the conf directory</p>\n</li>\n</ul>\n<h2>Deployment</h2>\n<p>Automated deployment is recommended, and experienced partners can use source deployment as well.</p>\n<h3>Automated Deployment</h3>\n<ul>\n<li>\n<p>Install zookeeper tools</p>\n<p><code>pip install kazoo</code></p>\n</li>\n<li>\n<p>Switch to deployment user, one-click deployment</p>\n<p><code>sh install.sh</code></p>\n</li>\n<li>\n<p>Use the <code>jps</code> command to check if the services are started (<code>jps</code> comes from <code>Java JDK</code>)</p>\n</li>\n</ul>\n<pre><code class=\"language-aidl\">    MasterServer         ----- Master Service\n    WorkerServer         ----- Worker Service\n    LoggerServer         ----- Logger Service\n    ApiApplicationServer ----- API Service\n    AlertServer          ----- Alert Service\n</code></pre>\n<p>If all services are normal, the automatic deployment is successful</p>\n<p>After successful deployment, the log can be viewed and stored in a specified folder.</p>\n<pre><code class=\"language-logPath\"> logs/\n    ├── escheduler-alert-server.log\n    ├── escheduler-master-server.log\n    |—— escheduler-worker-server.log\n    |—— escheduler-api-server.log\n    |—— escheduler-logger-server.log\n</code></pre>\n<h3>Compile source code to deploy</h3>\n<p>After downloading the release version of the source package, unzip it into the root directory</p>\n<ul>\n<li>Execute the compilation command：</li>\n</ul>\n<pre><code> mvn -U clean package assembly:assembly -Dmaven.test.skip=true\n</code></pre>\n<ul>\n<li>View directory</li>\n</ul>\n<p>After normal compilation, ./target/escheduler-{version}/ is generated in the current directory</p>\n<h3>Start-and-stop services commonly used in systems (for service purposes, please refer to System Architecture Design for details)</h3>\n<ul>\n<li>\n<p>stop all services in the cluster</p>\n<p><code>sh ./bin/stop-all.sh</code></p>\n</li>\n<li>\n<p>start all services in the cluster</p>\n<p><code>sh ./bin/start-all.sh</code></p>\n</li>\n<li>\n<p>start and stop one master server</p>\n</li>\n</ul>\n<pre><code class=\"language-master\">sh ./bin/escheduler-daemon.sh start master-server\nsh ./bin/escheduler-daemon.sh stop master-server\n</code></pre>\n<ul>\n<li>start and stop one worker server</li>\n</ul>\n<pre><code class=\"language-worker\">sh ./bin/escheduler-daemon.sh start worker-server\nsh ./bin/escheduler-daemon.sh stop worker-server\n</code></pre>\n<ul>\n<li>start and stop api server</li>\n</ul>\n<pre><code class=\"language-Api\">sh ./bin/escheduler-daemon.sh start api-server\nsh ./bin/escheduler-daemon.sh stop api-server\n</code></pre>\n<ul>\n<li>start and stop logger server</li>\n</ul>\n<pre><code class=\"language-Logger\">sh ./bin/escheduler-daemon.sh start logger-server\nsh ./bin/escheduler-daemon.sh stop logger-server\n</code></pre>\n<ul>\n<li>start and stop alert server</li>\n</ul>\n<pre><code class=\"language-Alert\">sh ./bin/escheduler-daemon.sh start alert-server\nsh ./bin/escheduler-daemon.sh stop alert-server\n</code></pre>\n<h2>Database Upgrade</h2>\n<p>Database upgrade is a function added in version 1.0.2. The database can be upgraded automatically by executing the following command:</p>\n<pre><code class=\"language-upgrade\">sh ./script/upgrade-escheduler.sh\n</code></pre>\n",
  "link": "/en-us/docs/user_doc/backend-deployment.html",
  "meta": {}
}