{
  "filename": "load-balance.md",
  "__html": "<h1>Load Balance</h1>\n<p>Load balancing refers to the reasonable allocation of server pressure through routing algorithms (usually in cluster environments) to achieve the maximum optimization of server performance.</p>\n<h2>DolphinScheduler-Worker Load Balancing Algorithms</h2>\n<p>DolphinScheduler-Master allocates tasks to workers, and by default provides three algorithms:</p>\n<ul>\n<li>\n<p>Weighted random (random)</p>\n</li>\n<li>\n<p>Smoothing polling (round-robin)</p>\n</li>\n<li>\n<p>Linear load (lower weight)</p>\n</li>\n</ul>\n<p>The default configuration is the linear load.</p>\n<p>As the routing sets on the client side, the master service, you can change master.host.selector in master.properties to configure the algorithm.</p>\n<p>e.g. master.host.selector=random (case-insensitive)</p>\n<h2>Worker Load Balancing Configuration</h2>\n<p>The configuration file is worker.properties</p>\n<h3>Weight</h3>\n<p>All the load algorithms above are weighted based on weights, which affect the routing outcome. You can set different weights for different machines by modifying the <code>worker.weight</code> value.</p>\n<h3>Preheating</h3>\n<p>Consider JIT optimization, worker runs at low power for a period of time after startup, so that it can gradually reach its optimal state, a process we call preheating. If you are interested, you can read some articles about JIT.</p>\n<p>So the worker gradually reaches its maximum weight with time after starts up ( by default ten minutes, there is no configuration about the pre-heating duration, it's recommend to submit a PR if have needs to change the duration).</p>\n<h2>Load Balancing Algorithm in Details</h2>\n<h3>Random (Weighted)</h3>\n<p>This algorithm is relatively simple, select a worker by random (the weight affects its weighting).</p>\n<h3>Smoothed Polling (Weighted)</h3>\n<p>An obvious drawback of the weighted polling algorithm, which is under special weights circumstance, weighted polling scheduling generates an imbalanced sequence of instances, and this unsmooth load may cause some instances to experience transient high loads, leading to a risk of system crash. To address this scheduling flaw, we provide a smooth weighted polling algorithm.</p>\n<p>Each worker has two weights parameters, weight (which remains constant after warm-up is complete) and current_weight (which changes dynamically). For every route, calculate the current_weight + weight and is iterated over all the workers, the weight of all the workers sum up and count as total_weight, then the worker with the largest current_weight is selected as the worker for this task. By meantime, set worker's current_weight-total_weight.</p>\n<h3>Linear Weighting (Default Algorithm)</h3>\n<p>This algorithm reports its own load information to the registry at regular intervals. Make decision on two main pieces of information:</p>\n<ul>\n<li>load average (default is the number of CPU cores * 2)</li>\n<li>available physical memory (default is 0.3, in G)</li>\n</ul>\n<p>If either of these is lower than the configured item, then this worker will not participate in the load. (no traffic will be allocated)</p>\n<p>You can customise the configuration by changing the following properties in worker.properties</p>\n<ul>\n<li>worker.max.cpuload.avg=-1 (worker max cpuload avg, only higher than the system cpu load average, worker server can be dispatched tasks. default value -1: the number of cpu cores * 2)</li>\n<li>worker.reserved.memory=0.3 (worker reserved memory, only lower than system available memory, worker server can be dispatched tasks. default value 0.3, the unit is G)</li>\n</ul>\n",
  "link": "/dist/en-us/docs/dev/user_doc/architecture/load-balance.html",
  "meta": {}
}