{
  "filename": "docker.md",
  "__html": "<h1>QuickStart in Docker</h1>\n<h2>Prerequisites</h2>\n<ul>\n<li><a href=\"https://docs.docker.com/engine/install/\">Docker</a> version: 1.13.1+</li>\n<li><a href=\"https://docs.docker.com/compose/\">Docker Compose</a> version: 1.11.0+</li>\n</ul>\n<h2>How to Use this Docker Image</h2>\n<p>Here are 3 ways to quickly install DolphinScheduler:</p>\n<h3>Start DolphinScheduler by Docker Compose (Recommended)</h3>\n<p>In this way, you need to install <a href=\"https://docs.docker.com/compose/\">docker-compose</a> as a prerequisite, please install it yourself according to the rich docker-compose installation guidance on the Internet.</p>\n<p>For Windows 7-10, you can install <a href=\"https://github.com/docker/toolbox/releases\">Docker Toolbox</a>. For Windows 10 64-bit, you can install <a href=\"https://docs.docker.com/docker-for-windows/install/\">Docker Desktop</a>, and meet the <a href=\"https://docs.docker.com/docker-for-windows/install/#system-requirements\">system requirements</a>.</p>\n<h4>Configure Memory not Less Than 4GB</h4>\n<p>For Mac user, click <code>Docker Desktop -&gt; Preferences -&gt; Resources -&gt; Memory</code>.</p>\n<p>For Windows Docker Toolbox users, configure the following two settings:</p>\n<ul>\n<li><strong>Memory</strong>: Open Oracle VirtualBox Manager, if you double-click <code>Docker Quickstart Terminal</code> and successfully run <code>Docker Toolbox</code>, you will see a Virtual Machine named <code>default</code>. And click <code>Settings -&gt; System -&gt; Motherboard -&gt; Base Memory</code></li>\n<li><strong>Port Forwarding</strong>: Click <code>Settings -&gt; Network -&gt; Advanced -&gt; Port Forwarding -&gt; Add</code>. fill <code>Name</code>, <code>Host Port</code> and <code>Guest Port</code> forms with <code>12345</code>, regardless of <code>Host IP</code> and <code>Guest IP</code></li>\n</ul>\n<p>For Windows Docker Desktop user</p>\n<ul>\n<li><strong>Hyper-V Mode</strong>: Click <code>Docker Desktop -&gt; Settings -&gt; Resources -&gt; Memory</code></li>\n<li><strong>WSL 2 Mode</strong>: Refer to <a href=\"https://docs.microsoft.com/en-us/windows/wsl/wsl-config#configure-global-options-with-wslconfig\">WSL 2 utility VM</a></li>\n</ul>\n<h4>Download the Source Code Package</h4>\n<p>Please download the source code package <code>apache-dolphinscheduler-1.3.8-src.tar.gz</code>, download address: <a href=\"/en-us/download/download.html\">download address</a>.</p>\n<h4>Pull Image and Start the Service</h4>\n<blockquote>\n<p>For Mac and Linux users, open <strong>Terminal</strong>\nFor Windows Docker Toolbox user, open <strong>Docker Quickstart Terminal</strong>\nFor Windows Docker Desktop user, open <strong>Windows PowerShell</strong></p>\n</blockquote>\n<pre><code>$ tar -zxvf apache-dolphinscheduler-1.3.8-src.tar.gz\n$ cd apache-dolphinscheduler-1.3.8-src/docker/docker-swarm\n$ docker pull dolphinscheduler.docker.scarf.sh/apache/dolphinscheduler:1.3.8\n$ docker tag apache/dolphinscheduler:1.3.8 apache/dolphinscheduler:latest\n$ docker-compose up -d\n</code></pre>\n<blockquote>\n<p>PowerShell should run <code>cd apache-dolphinscheduler-1.3.8-src\\docker\\docker-swarm</code></p>\n</blockquote>\n<p>The <strong>PostgreSQL</strong> (with username <code>root</code>, password <code>root</code> and database <code>dolphinscheduler</code>) and <strong>ZooKeeper</strong> services will start by default.</p>\n<h4>Login</h4>\n<p>Visit the Web UI: <a href=\"http://localhost:12345/dolphinscheduler\">http://localhost:12345/dolphinscheduler</a> (Modify the IP address if needed).</p>\n<p>The default username is <code>admin</code> and the default password is <code>dolphinscheduler123</code>.</p>\n<p align=\"center\">\n  <img src=\"/img/login_en.png\" width=\"60%\" />\n</p>\n<p>Please refer to the <a href=\"../start/quick-start.md\">Quick Start</a> to explore how to use DolphinScheduler.</p>\n<h3>Start via Existing PostgreSQL and ZooKeeper Service</h3>\n<p>In this way, you need to install <a href=\"https://docs.docker.com/engine/install/\">docker</a> as a prerequisite, please install it yourself according to the rich docker installation guidance on the Internet.</p>\n<h4>Basic Required Software</h4>\n<ul>\n<li><a href=\"https://www.postgresql.org/download/\">PostgreSQL</a> (version 8.2.15+)</li>\n<li><a href=\"https://zookeeper.apache.org/releases.html\">ZooKeeper</a> (version 3.4.6+)</li>\n<li><a href=\"https://docs.docker.com/engine/install/\">Docker</a> (version 1.13.1+)</li>\n</ul>\n<h4>Login to the PostgreSQL Database and Create a Database Named <code>dolphinscheduler</code></h4>\n<h4>Initialize the Database, Import <code>sql/dolphinscheduler_postgre.sql</code> to Create Tables and Initial Data</h4>\n<h4>Download the DolphinScheduler Image</h4>\n<p>We have already uploaded the user-oriented DolphinScheduler image to the Docker repository so that you can pull the image from the docker repository:</p>\n<pre><code>docker pull dolphinscheduler.docker.scarf.sh/apache/dolphinscheduler:1.3.8\n</code></pre>\n<h4>5. Run a DolphinScheduler Instance</h4>\n<pre><code>$ docker run -d --name dolphinscheduler \\\n-e DATABASE_HOST=&quot;192.168.x.x&quot; -e DATABASE_PORT=&quot;5432&quot; -e DATABASE_DATABASE=&quot;dolphinscheduler&quot; \\\n-e DATABASE_USERNAME=&quot;test&quot; -e DATABASE_PASSWORD=&quot;test&quot; \\\n-e ZOOKEEPER_QUORUM=&quot;192.168.x.x:2181&quot; \\\n-p 12345:12345 \\\napache/dolphinscheduler:1.3.8 all\n</code></pre>\n<p>Note: database test username and password need to be replaced with your actual PostgreSQL username and password, 192.168.x.x need to be replaced with your related PostgreSQL and ZooKeeper host IP.</p>\n<h4>Login</h4>\n<p>Same as above</p>\n<h3>Start a Standalone DolphinScheduler Server</h3>\n<p>The following services automatically start when the container starts:</p>\n<pre><code>     MasterServer         ----- master service\n     WorkerServer         ----- worker service\n     ApiApplicationServer ----- api service\n     AlertServer          ----- alert service\n</code></pre>\n<p>If you just want to run part of the services in the DolphinScheduler, you can start a single service in DolphinScheduler by running the following commands.</p>\n<ul>\n<li>Start a <strong>master server</strong>, For example:</li>\n</ul>\n<pre><code>$ docker run -d --name dolphinscheduler-master \\\n-e DATABASE_HOST=&quot;192.168.x.x&quot; -e DATABASE_PORT=&quot;5432&quot; -e DATABASE_DATABASE=&quot;dolphinscheduler&quot; \\\n-e DATABASE_USERNAME=&quot;test&quot; -e DATABASE_PASSWORD=&quot;test&quot; \\\n-e ZOOKEEPER_QUORUM=&quot;192.168.x.x:2181&quot; \\\napache/dolphinscheduler:1.3.8 master-server\n</code></pre>\n<ul>\n<li>Start a <strong>worker server</strong>, For example:</li>\n</ul>\n<pre><code>$ docker run -d --name dolphinscheduler-worker \\\n-e DATABASE_HOST=&quot;192.168.x.x&quot; -e DATABASE_PORT=&quot;5432&quot; -e DATABASE_DATABASE=&quot;dolphinscheduler&quot; \\\n-e DATABASE_USERNAME=&quot;test&quot; -e DATABASE_PASSWORD=&quot;test&quot; \\\n-e ZOOKEEPER_QUORUM=&quot;192.168.x.x:2181&quot; \\\napache/dolphinscheduler:1.3.8 worker-server\n</code></pre>\n<ul>\n<li>Start an <strong>api server</strong>, For example:</li>\n</ul>\n<pre><code>$ docker run -d --name dolphinscheduler-api \\\n-e DATABASE_HOST=&quot;192.168.x.x&quot; -e DATABASE_PORT=&quot;5432&quot; -e DATABASE_DATABASE=&quot;dolphinscheduler&quot; \\\n-e DATABASE_USERNAME=&quot;test&quot; -e DATABASE_PASSWORD=&quot;test&quot; \\\n-e ZOOKEEPER_QUORUM=&quot;192.168.x.x:2181&quot; \\\n-p 12345:12345 \\\napache/dolphinscheduler:1.3.8 api-server\n</code></pre>\n<ul>\n<li>Start an <strong>alert server</strong>, For example:</li>\n</ul>\n<pre><code>$ docker run -d --name dolphinscheduler-alert \\\n-e DATABASE_HOST=&quot;192.168.x.x&quot; -e DATABASE_PORT=&quot;5432&quot; -e DATABASE_DATABASE=&quot;dolphinscheduler&quot; \\\n-e DATABASE_USERNAME=&quot;test&quot; -e DATABASE_PASSWORD=&quot;test&quot; \\\napache/dolphinscheduler:1.3.8 alert-server\n</code></pre>\n<p><strong>Note</strong>: You must specify environment variables <code>DATABASE_HOST</code>, <code>DATABASE_PORT</code>, <code>DATABASE_DATABASE</code>, <code>DATABASE_USERNAME</code>, <code>DATABASE_PASSWORD</code>, <code>ZOOKEEPER_QUORUM</code> when start a single DolphinScheduler server.</p>\n<h2>Environment Variables</h2>\n<p>The Docker container is configured through environment variables, and the <a href=\"#appendix-environment-variables\">Appendix-Environment Variables</a> lists the configurable environment variables of the DolphinScheduler and their default values.</p>\n<p>Especially, it can be configured through the environment variable configuration file <code>config.env.sh</code> in Docker Compose and Docker Swarm.</p>\n<h2>Support Matrix</h2>\n<table>\n<thead>\n<tr>\n<th>Type</th>\n<th>Support</th>\n<th>Notes</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Shell</td>\n<td>Yes</td>\n<td></td>\n</tr>\n<tr>\n<td>Python2</td>\n<td>Yes</td>\n<td></td>\n</tr>\n<tr>\n<td>Python3</td>\n<td>Indirect Yes</td>\n<td>Refer to FAQ</td>\n</tr>\n<tr>\n<td>Hadoop2</td>\n<td>Indirect Yes</td>\n<td>Refer to FAQ</td>\n</tr>\n<tr>\n<td>Hadoop3</td>\n<td>Not Sure</td>\n<td>Not tested</td>\n</tr>\n<tr>\n<td>Spark-Local(client)</td>\n<td>Indirect Yes</td>\n<td>Refer to FAQ</td>\n</tr>\n<tr>\n<td>Spark-YARN(cluster)</td>\n<td>Indirect Yes</td>\n<td>Refer to FAQ</td>\n</tr>\n<tr>\n<td>Spark-Standalone(cluster)</td>\n<td>Not Yet</td>\n<td></td>\n</tr>\n<tr>\n<td>Spark-Kubernetes(cluster)</td>\n<td>Not Yet</td>\n<td></td>\n</tr>\n<tr>\n<td>Flink-Local(local&gt;=1.11)</td>\n<td>Not Yet</td>\n<td>Generic CLI mode is not yet supported</td>\n</tr>\n<tr>\n<td>Flink-YARN(yarn-cluster)</td>\n<td>Indirect Yes</td>\n<td>Refer to FAQ</td>\n</tr>\n<tr>\n<td>Flink-YARN(yarn-session/yarn-per-job/yarn-application&gt;=1.11)</td>\n<td>Not Yet</td>\n<td>Generic CLI mode is not yet supported</td>\n</tr>\n<tr>\n<td>Flink-Standalone(default)</td>\n<td>Not Yet</td>\n<td></td>\n</tr>\n<tr>\n<td>Flink-Standalone(remote&gt;=1.11)</td>\n<td>Not Yet</td>\n<td>Generic CLI mode is not yet supported</td>\n</tr>\n<tr>\n<td>Flink-Kubernetes(default)</td>\n<td>Not Yet</td>\n<td></td>\n</tr>\n<tr>\n<td>Flink-Kubernetes(remote&gt;=1.11)</td>\n<td>Not Yet</td>\n<td>Generic CLI mode is not yet supported</td>\n</tr>\n<tr>\n<td>Flink-NativeKubernetes(kubernetes-session/application&gt;=1.11)</td>\n<td>Not Yet</td>\n<td>Generic CLI mode is not yet supported</td>\n</tr>\n<tr>\n<td>MapReduce</td>\n<td>Indirect Yes</td>\n<td>Refer to FAQ</td>\n</tr>\n<tr>\n<td>Kerberos</td>\n<td>Indirect Yes</td>\n<td>Refer to FAQ</td>\n</tr>\n<tr>\n<td>HTTP</td>\n<td>Yes</td>\n<td></td>\n</tr>\n<tr>\n<td>DataX</td>\n<td>Indirect Yes</td>\n<td>Refer to FAQ</td>\n</tr>\n<tr>\n<td>Sqoop</td>\n<td>Indirect Yes</td>\n<td>Refer to FAQ</td>\n</tr>\n<tr>\n<td>SQL-MySQL</td>\n<td>Indirect Yes</td>\n<td>Refer to FAQ</td>\n</tr>\n<tr>\n<td>SQL-PostgreSQL</td>\n<td>Yes</td>\n<td></td>\n</tr>\n<tr>\n<td>SQL-Hive</td>\n<td>Indirect Yes</td>\n<td>Refer to FAQ</td>\n</tr>\n<tr>\n<td>SQL-Spark</td>\n<td>Indirect Yes</td>\n<td>Refer to FAQ</td>\n</tr>\n<tr>\n<td>SQL-ClickHouse</td>\n<td>Indirect Yes</td>\n<td>Refer to FAQ</td>\n</tr>\n<tr>\n<td>SQL-Oracle</td>\n<td>Indirect Yes</td>\n<td>Refer to FAQ</td>\n</tr>\n<tr>\n<td>SQL-SQLServer</td>\n<td>Indirect Yes</td>\n<td>Refer to FAQ</td>\n</tr>\n<tr>\n<td>SQL-DB2</td>\n<td>Indirect Yes</td>\n<td>Refer to FAQ</td>\n</tr>\n</tbody>\n</table>\n<h2>FAQ</h2>\n<h3>How to Manage DolphinScheduler by Docker Compose?</h3>\n<p>Start, restart, stop or list containers:</p>\n<pre><code>docker-compose start\ndocker-compose restart\ndocker-compose stop\ndocker-compose ps\n</code></pre>\n<p>Stop containers and remove containers, networks:</p>\n<pre><code>docker-compose down\n</code></pre>\n<p>Stop containers and remove containers, networks and volumes:</p>\n<pre><code>docker-compose down -v\n</code></pre>\n<h3>How to View the Logs of a Container?</h3>\n<p>List all running containers logs:</p>\n<pre><code>docker ps\ndocker ps --format &quot;{{.Names}}&quot; # only print names\n</code></pre>\n<p>View the logs of a container named docker-swarm_dolphinscheduler-api_1:</p>\n<pre><code>docker logs docker-swarm_dolphinscheduler-api_1\ndocker logs -f docker-swarm_dolphinscheduler-api_1 # follow log output\ndocker logs --tail 10 docker-swarm_dolphinscheduler-api_1 # show last 10 lines from the end of the logs\n</code></pre>\n<h3>How to Scale Master and Worker by Docker Compose?</h3>\n<p>Scale master to 2 instances:</p>\n<pre><code>docker-compose up -d --scale dolphinscheduler-master=2 dolphinscheduler-master\n</code></pre>\n<p>Scale worker to 3 instances:</p>\n<pre><code>docker-compose up -d --scale dolphinscheduler-worker=3 dolphinscheduler-worker\n</code></pre>\n<h3>How to Deploy DolphinScheduler on Docker Swarm?</h3>\n<p>Assuming that the Docker Swarm cluster has been created (If there is no Docker Swarm cluster, please refer to <a href=\"https://docs.docker.com/engine/swarm/swarm-tutorial/create-swarm/\">create-swarm</a>).</p>\n<p>Start a stack named <code>dolphinscheduler</code>:</p>\n<pre><code>docker stack deploy -c docker-stack.yml dolphinscheduler\n</code></pre>\n<p>List the services in the stack named <code>dolphinscheduler</code>:</p>\n<pre><code>docker stack services dolphinscheduler\n</code></pre>\n<p>Stop and remove the stack named <code>dolphinscheduler</code>:</p>\n<pre><code>docker stack rm dolphinscheduler\n</code></pre>\n<p>Remove the volumes of the stack named <code>dolphinscheduler</code>:</p>\n<pre><code>docker volume rm -f $(docker volume ls --format &quot;{{.Name}}&quot; | grep -e &quot;^dolphinscheduler&quot;)\n</code></pre>\n<h3>How to Scale Master and Worker on Docker Swarm?</h3>\n<p>Scale master of the stack named <code>dolphinscheduler</code> to 2 instances:</p>\n<pre><code>docker service scale dolphinscheduler_dolphinscheduler-master=2\n</code></pre>\n<p>Scale worker of the stack named <code>dolphinscheduler</code> to 3 instances:</p>\n<pre><code>docker service scale dolphinscheduler_dolphinscheduler-worker=3\n</code></pre>\n<h3>How to Build a Docker Image?</h3>\n<h4>Build From the Source Code (Require Maven 3.3+ and JDK 1.8+)</h4>\n<p>In Unix-Like, execute in Terminal:</p>\n<pre><code class=\"language-bash\">$ bash ./docker/build/hooks/build\n</code></pre>\n<p>In Windows, execute in cmd or PowerShell:</p>\n<pre><code class=\"language-bat\"><span class=\"hljs-function\">C:\\<span class=\"hljs-title\">dolphinscheduler</span>-<span class=\"hljs-title\">src</span>&gt;.\\<span class=\"hljs-title\">docker</span>\\<span class=\"hljs-title\">build</span>\\<span class=\"hljs-title\">hooks</span>\\<span class=\"hljs-title\">build.bat</span>\n</span></code></pre>\n<p>Please read <code>./docker/build/hooks/build</code> <code>./docker/build/hooks/build.bat</code> script files if you don't understand.</p>\n<h4>Build From the Binary Distribution (Not require Maven 3.3+ and JDK 1.8+)</h4>\n<p>Please download the binary distribution package <code>apache-dolphinscheduler-1.3.8-bin.tar.gz</code>, download address: <a href=\"/en-us/download/download.html\">download address</a>. And put <code>apache-dolphinscheduler-1.3.8-bin.tar.gz</code> into the <code>apache-dolphinscheduler-1.3.8-src/docker/build</code> directory, execute in Terminal or PowerShell:</p>\n<pre><code>$ cd apache-dolphinscheduler-1.3.8-src/docker/build\n$ docker build --build-arg VERSION=1.3.8 -t apache/dolphinscheduler:1.3.8 .\n</code></pre>\n<blockquote>\n<p>PowerShell should use <code>cd apache-dolphinscheduler-1.3.8-src/docker/build</code></p>\n</blockquote>\n<h4>Build Multi-Platform Images</h4>\n<p>Currently, support build images including <code>linux/amd64</code> and <code>linux/arm64</code> platform architecture, requirements:</p>\n<ol>\n<li>Support <a href=\"https://docs.docker.com/engine/reference/commandline/buildx/\">docker buildx</a></li>\n<li>Own the push permission of <code>https://hub.docker.com/r/apache/dolphinscheduler</code> (<strong>Be cautious</strong>: The build command will automatically push the multi-platform architecture images to the docker hub of <code>apache/dolphinscheduler</code> by default)</li>\n</ol>\n<p>Execute:</p>\n<pre><code class=\"language-bash\">$ docker login <span class=\"hljs-comment\"># login to push apache/dolphinscheduler</span>\n$ bash ./docker/build/hooks/build x\n</code></pre>\n<h3>How to Add an Environment Variable for Docker?</h3>\n<p>If you would like to do additional initialization or add environment variables when compiling or execution, you can add one or more environment variables in the script <code>/root/start-init-conf.sh</code>. If involves configuration modification, modify the script <code>/opt/dolphinscheduler/conf/*.tpl</code>.</p>\n<p>For example, add an environment variable <code>SECURITY_AUTHENTICATION_TYPE</code> in <code>/root/start-init-conf.sh</code>:</p>\n<pre><code>export SECURITY_AUTHENTICATION_TYPE=PASSWORD\n</code></pre>\n<p>Add the <code>SECURITY_AUTHENTICATION_TYPE</code> to the template file <code>application-api.properties.tpl</code>:</p>\n<pre><code>security.authentication.type=${SECURITY_AUTHENTICATION_TYPE}\n</code></pre>\n<p><code>/root/start-init-conf.sh</code> will dynamically generate config file:</p>\n<pre><code class=\"language-sh\"><span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;generate dolphinscheduler config&quot;</span>\nls <span class=\"hljs-variable\">${DOLPHINSCHEDULER_HOME}</span>/conf/ | grep <span class=\"hljs-string\">&quot;.tpl&quot;</span> | <span class=\"hljs-keyword\">while</span> <span class=\"hljs-built_in\">read</span> line; <span class=\"hljs-keyword\">do</span>\n<span class=\"hljs-built_in\">eval</span> <span class=\"hljs-string\">&quot;cat &lt;&lt; EOF\n<span class=\"hljs-subst\">$(cat ${DOLPHINSCHEDULER_HOME}/conf/${line})</span>\nEOF\n&quot;</span> &gt; <span class=\"hljs-variable\">${DOLPHINSCHEDULER_HOME}</span>/conf/<span class=\"hljs-variable\">${line%.*}</span>\n<span class=\"hljs-keyword\">done</span>\n</code></pre>\n<h3>How to Use MySQL as the DolphinScheduler's Database Instead of PostgreSQL?</h3>\n<blockquote>\n<p>Because of the commercial license, we cannot directly use the driver of MySQL.</p>\n<p>If you want to use MySQL, you can build a new image based on the <code>apache/dolphinscheduler</code> image follow the following instructions:</p>\n</blockquote>\n<ol>\n<li>\n<p>Download the MySQL driver <a href=\"https://repo1.maven.org/maven2/mysql/mysql-connector-java/8.0.16/mysql-connector-java-8.0.16.jar\">mysql-connector-java-8.0.16.jar</a>.</p>\n</li>\n<li>\n<p>Create a new <code>Dockerfile</code> to add MySQL driver:</p>\n</li>\n</ol>\n<pre><code>FROM dolphinscheduler.docker.scarf.sh/apache/dolphinscheduler:1.3.8\nCOPY mysql-connector-java-8.0.16.jar /opt/dolphinscheduler/lib\n</code></pre>\n<ol start=\"3\">\n<li>Build a new docker image including MySQL driver:</li>\n</ol>\n<pre><code>docker build -t apache/dolphinscheduler:mysql-driver .\n</code></pre>\n<ol start=\"4\">\n<li>Modify all the <code>image</code> fields to <code>apache/dolphinscheduler:mysql-driver</code> in <code>docker-compose.yml</code>.</li>\n</ol>\n<blockquote>\n<p>If you want to deploy DolphinScheduler on Docker Swarm, you need to modify <code>docker-stack.yml</code></p>\n</blockquote>\n<ol start=\"5\">\n<li>\n<p>Comment the <code>dolphinscheduler-postgresql</code> block in <code>docker-compose.yml</code>.</p>\n</li>\n<li>\n<p>Add <code>dolphinscheduler-mysql</code> service in <code>docker-compose.yml</code> (<strong>Optional</strong>, you can directly use an external MySQL database).</p>\n</li>\n<li>\n<p>Modify DATABASE environment variables in <code>config.env.sh</code>:</p>\n</li>\n</ol>\n<pre><code>DATABASE_TYPE=mysql\nDATABASE_DRIVER=com.mysql.jdbc.Driver\nDATABASE_HOST=dolphinscheduler-mysql\nDATABASE_PORT=3306\nDATABASE_USERNAME=root\nDATABASE_PASSWORD=root\nDATABASE_DATABASE=dolphinscheduler\nDATABASE_PARAMS=useUnicode=true&amp;characterEncoding=UTF-8\n</code></pre>\n<blockquote>\n<p>If you have added <code>dolphinscheduler-mysql</code> service in <code>docker-compose.yml</code>, just set <code>DATABASE_HOST</code> to <code>dolphinscheduler-mysql</code></p>\n</blockquote>\n<ol start=\"8\">\n<li>Run the DolphinScheduler (See <strong>How to use this docker image</strong>)</li>\n</ol>\n<h3>How to Support MySQL Datasource in <code>Datasource manage</code>?</h3>\n<blockquote>\n<p>Because of the commercial license, we cannot directly use the driver of MySQL.</p>\n<p>If you want to add MySQL datasource, you can build a new image based on the <code>apache/dolphinscheduler</code> image follow the following instructions:</p>\n</blockquote>\n<ol>\n<li>\n<p>Download the MySQL driver <a href=\"https://repo1.maven.org/maven2/mysql/mysql-connector-java/8.0.16/mysql-connector-java-8.0.16.jar\">mysql-connector-java-8.0.16.jar</a>.</p>\n</li>\n<li>\n<p>Create a new <code>Dockerfile</code> to add MySQL driver:</p>\n</li>\n</ol>\n<pre><code>FROM dolphinscheduler.docker.scarf.sh/apache/dolphinscheduler:1.3.8\nCOPY mysql-connector-java-8.0.16.jar /opt/dolphinscheduler/lib\n</code></pre>\n<ol start=\"3\">\n<li>Build a new docker image including MySQL driver:</li>\n</ol>\n<pre><code>docker build -t apache/dolphinscheduler:mysql-driver .\n</code></pre>\n<ol start=\"4\">\n<li>Modify all <code>image</code> fields to <code>apache/dolphinscheduler:mysql-driver</code> in <code>docker-compose.yml</code>.</li>\n</ol>\n<blockquote>\n<p>If you want to deploy DolphinScheduler on Docker Swarm, you need to modify <code>docker-stack.yml</code>.</p>\n</blockquote>\n<ol start=\"5\">\n<li>\n<p>Run the DolphinScheduler (See <strong>How to use this docker image</strong>).</p>\n</li>\n<li>\n<p>Add a MySQL datasource in <code>Datasource manage</code>.</p>\n</li>\n</ol>\n<h3>How to Support Oracle Datasource in <code>Datasource manage</code>?</h3>\n<blockquote>\n<p>Because of the commercial license, we cannot directly use the driver of Oracle.</p>\n<p>If you want to add Oracle datasource, you can build a new image based on the <code>apache/dolphinscheduler</code> image follow the following instructions:</p>\n</blockquote>\n<ol>\n<li>\n<p>Download the Oracle driver <a href=\"https://repo1.maven.org/maven2/com/oracle/database/jdbc/ojdbc8/\">ojdbc8.jar</a> (such as <code>ojdbc8-19.9.0.0.jar</code>).</p>\n</li>\n<li>\n<p>Create a new <code>Dockerfile</code> to add Oracle driver:</p>\n</li>\n</ol>\n<pre><code>FROM dolphinscheduler.docker.scarf.sh/apache/dolphinscheduler:1.3.8\nCOPY ojdbc8-19.9.0.0.jar /opt/dolphinscheduler/lib\n</code></pre>\n<ol start=\"3\">\n<li>Build a new docker image including Oracle driver:</li>\n</ol>\n<pre><code>docker build -t apache/dolphinscheduler:oracle-driver .\n</code></pre>\n<ol start=\"4\">\n<li>Modify all <code>image</code> fields to <code>apache/dolphinscheduler:oracle-driver</code> in <code>docker-compose.yml</code>.</li>\n</ol>\n<blockquote>\n<p>If you want to deploy DolphinScheduler on Docker Swarm, you need to modify <code>docker-stack.yml</code>.</p>\n</blockquote>\n<ol start=\"5\">\n<li>\n<p>Run the DolphinScheduler (See <strong>How to use this docker image</strong>).</p>\n</li>\n<li>\n<p>Add an Oracle datasource in <code>Datasource manage</code>.</p>\n</li>\n</ol>\n<h3>How to Support Python 2 pip and Custom requirements.txt?</h3>\n<ol>\n<li>Create a new <code>Dockerfile</code> to install pip:</li>\n</ol>\n<pre><code>FROM dolphinscheduler.docker.scarf.sh/apache/dolphinscheduler:1.3.8\nCOPY requirements.txt /tmp\nRUN apt-get update &amp;&amp; \\\n    apt-get install -y --no-install-recommends python-pip &amp;&amp; \\\n    pip install --no-cache-dir -r /tmp/requirements.txt &amp;&amp; \\\n    rm -rf /var/lib/apt/lists/*\n</code></pre>\n<p>The command will install the default <strong>pip 18.1</strong>. If you need to upgrade the pip, just add one more line.</p>\n<pre><code>    pip install --no-cache-dir -U pip &amp;&amp; \\\n</code></pre>\n<ol start=\"2\">\n<li>Build a new docker image including pip:</li>\n</ol>\n<pre><code>docker build -t apache/dolphinscheduler:pip .\n</code></pre>\n<ol start=\"3\">\n<li>Modify all <code>image</code> fields to <code>apache/dolphinscheduler:pip</code> in <code>docker-compose.yml</code>.</li>\n</ol>\n<blockquote>\n<p>If you want to deploy DolphinScheduler on Docker Swarm, you need to modify <code>docker-stack.yml</code>.</p>\n</blockquote>\n<ol start=\"4\">\n<li>\n<p>Run the DolphinScheduler (See <strong>How to use this docker image</strong>).</p>\n</li>\n<li>\n<p>Verify pip under a new Python task.</p>\n</li>\n</ol>\n<h3>How to Support Python 3?</h3>\n<ol>\n<li>Create a new <code>Dockerfile</code> to install Python 3:</li>\n</ol>\n<pre><code>FROM dolphinscheduler.docker.scarf.sh/apache/dolphinscheduler:1.3.8\nRUN apt-get update &amp;&amp; \\\n    apt-get install -y --no-install-recommends python3 &amp;&amp; \\\n    rm -rf /var/lib/apt/lists/*\n</code></pre>\n<p>The command will install the default <strong>Python 3.7.3</strong>. If you also want to install <strong>pip3</strong>, just replace <code>python3</code> with <code>python3-pip</code>.</p>\n<pre><code>    apt-get install -y --no-install-recommends python3-pip &amp;&amp; \\\n</code></pre>\n<ol start=\"2\">\n<li>Build a new docker image including Python 3:</li>\n</ol>\n<pre><code>docker build -t apache/dolphinscheduler:python3 .\n</code></pre>\n<ol start=\"3\">\n<li>Modify all <code>image</code> fields to <code>apache/dolphinscheduler:python3</code> in <code>docker-compose.yml</code>.</li>\n</ol>\n<blockquote>\n<p>If you want to deploy DolphinScheduler on Docker Swarm, you need to modify <code>docker-stack.yml</code>.</p>\n</blockquote>\n<ol start=\"4\">\n<li>\n<p>Modify <code>PYTHON_HOME</code> to <code>/usr/bin/python3</code> in <code>config.env.sh</code>.</p>\n</li>\n<li>\n<p>Run the DolphinScheduler (See <strong>How to use this docker image</strong>).</p>\n</li>\n<li>\n<p>Verify Python 3 under a new Python task.</p>\n</li>\n</ol>\n<h3>How to Support Hadoop, Spark, Flink, Hive or DataX?</h3>\n<p>Take Spark 2.4.7 as an example:</p>\n<ol>\n<li>\n<p>Download the Spark 2.4.7 release binary <code>spark-2.4.7-bin-hadoop2.7.tgz</code>.</p>\n</li>\n<li>\n<p>Run the DolphinScheduler (See <strong>How to use this docker image</strong>).</p>\n</li>\n<li>\n<p>Copy the Spark 2.4.7 release binary into the Docker container.</p>\n</li>\n</ol>\n<pre><code class=\"language-bash\">docker cp spark-2.4.7-bin-hadoop2.7.tgz docker-swarm_dolphinscheduler-worker_1:/opt/soft\n</code></pre>\n<p>Because the volume <code>dolphinscheduler-shared-local</code> is mounted on <code>/opt/soft</code>, all files in <code>/opt/soft</code> will not be lost.</p>\n<ol start=\"4\">\n<li>Attach the container and ensure that <code>SPARK_HOME2</code> exists.</li>\n</ol>\n<pre><code class=\"language-bash\">docker <span class=\"hljs-built_in\">exec</span> -it docker-swarm_dolphinscheduler-worker_1 bash\n<span class=\"hljs-built_in\">cd</span> /opt/soft\ntar zxf spark-2.4.7-bin-hadoop2.7.tgz\nrm -f spark-2.4.7-bin-hadoop2.7.tgz\nln -s spark-2.4.7-bin-hadoop2.7 spark2 <span class=\"hljs-comment\"># or just mv</span>\n<span class=\"hljs-variable\">$SPARK_HOME2</span>/bin/spark-submit --version\n</code></pre>\n<p>The last command will print the Spark version if everything goes well.</p>\n<ol start=\"5\">\n<li>Verify Spark under a Shell task.</li>\n</ol>\n<pre><code>$SPARK_HOME2/bin/spark-submit --class org.apache.spark.examples.SparkPi $SPARK_HOME2/examples/jars/spark-examples_2.11-2.4.7.jar\n</code></pre>\n<p>Check whether the task log contains the output like <code>Pi is roughly 3.146015</code>.</p>\n<ol start=\"6\">\n<li>Verify Spark under a Spark task.</li>\n</ol>\n<p>The file <code>spark-examples_2.11-2.4.7.jar</code> needs to be uploaded to the resources first, and then create a Spark task with:</p>\n<ul>\n<li>Spark Version: <code>SPARK2</code></li>\n<li>Main Class: <code>org.apache.spark.examples.SparkPi</code></li>\n<li>Main Package: <code>spark-examples_2.11-2.4.7.jar</code></li>\n<li>Deploy Mode: <code>local</code></li>\n</ul>\n<p>Similarly, check whether the task log contains the output like <code>Pi is roughly 3.146015</code>.</p>\n<ol start=\"7\">\n<li>Verify Spark on YARN.</li>\n</ol>\n<p>Spark on YARN (Deploy Mode is <code>cluster</code> or <code>client</code>) requires Hadoop support. Similar to Spark support, the operation of supporting Hadoop is almost the same as the previous steps.</p>\n<p>Ensure that <code>$HADOOP_HOME</code> and <code>$HADOOP_CONF_DIR</code> exists.</p>\n<h3>How to Support Spark 3?</h3>\n<p>In fact, the way to submit applications with <code>spark-submit</code> is the same, regardless of Spark 1, 2 or 3. In other words, the semantics of <code>SPARK_HOME2</code> is the second <code>SPARK_HOME</code> instead of <code>SPARK2</code>'s <code>HOME</code>, so just set <code>SPARK_HOME2=/path/to/spark3</code>.</p>\n<p>Take Spark 3.1.1 as an example:</p>\n<ol>\n<li>\n<p>Download the Spark 3.1.1 release binary <code>spark-3.1.1-bin-hadoop2.7.tgz</code>.</p>\n</li>\n<li>\n<p>Run the DolphinScheduler (See <strong>How to use this docker image</strong>).</p>\n</li>\n<li>\n<p>Copy the Spark 3.1.1 release binary into the Docker container.</p>\n</li>\n</ol>\n<pre><code class=\"language-bash\">docker cp spark-3.1.1-bin-hadoop2.7.tgz docker-swarm_dolphinscheduler-worker_1:/opt/soft\n</code></pre>\n<ol start=\"4\">\n<li>Attach the container and ensure that <code>SPARK_HOME2</code> exists.</li>\n</ol>\n<pre><code class=\"language-bash\">docker <span class=\"hljs-built_in\">exec</span> -it docker-swarm_dolphinscheduler-worker_1 bash\n<span class=\"hljs-built_in\">cd</span> /opt/soft\ntar zxf spark-3.1.1-bin-hadoop2.7.tgz\nrm -f spark-3.1.1-bin-hadoop2.7.tgz\nln -s spark-3.1.1-bin-hadoop2.7 spark2 <span class=\"hljs-comment\"># or just mv</span>\n<span class=\"hljs-variable\">$SPARK_HOME2</span>/bin/spark-submit --version\n</code></pre>\n<p>The last command will print the Spark version if everything goes well.</p>\n<ol start=\"5\">\n<li>Verify Spark under a Shell task.</li>\n</ol>\n<pre><code>$SPARK_HOME2/bin/spark-submit --class org.apache.spark.examples.SparkPi $SPARK_HOME2/examples/jars/spark-examples_2.12-3.1.1.jar\n</code></pre>\n<p>Check whether the task log contains the output like <code>Pi is roughly 3.146015</code>.</p>\n<h3>How to Support Shared Storage between Master, Worker and API server?</h3>\n<blockquote>\n<p><strong>Note</strong>: If it is deployed on a single machine by <code>docker-compose</code>, step 1 and 2 can be skipped directly, and execute the command like <code>docker cp hadoop-3.2.2.tar.gz docker-swarm_dolphinscheduler-worker_1:/opt/soft</code> to put Hadoop into the shared directory <code>/opt/soft</code> in the container.</p>\n</blockquote>\n<p>For example, Master, Worker and API servers may use Hadoop at the same time.</p>\n<ol>\n<li>Modify the volume <code>dolphinscheduler-shared-local</code> to support NFS in <code>docker-compose.yml</code>.</li>\n</ol>\n<blockquote>\n<p>If you want to deploy DolphinScheduler on Docker Swarm, you need to modify <code>docker-stack.yml</code>.</p>\n</blockquote>\n<pre><code class=\"language-yaml\"><span class=\"hljs-attr\">volumes:</span>\n  <span class=\"hljs-attr\">dolphinscheduler-shared-local:</span>\n    <span class=\"hljs-attr\">driver_opts:</span>\n      <span class=\"hljs-attr\">type:</span> <span class=\"hljs-string\">&quot;nfs&quot;</span>\n      <span class=\"hljs-attr\">o:</span> <span class=\"hljs-string\">&quot;addr=10.40.0.199,nolock,soft,rw&quot;</span>\n      <span class=\"hljs-attr\">device:</span> <span class=\"hljs-string\">&quot;:/path/to/shared/dir&quot;</span>\n</code></pre>\n<ol start=\"2\">\n<li>\n<p>Put the Hadoop into the NFS.</p>\n</li>\n<li>\n<p>Ensure that <code>$HADOOP_HOME</code> and <code>$HADOOP_CONF_DIR</code> are correct.</p>\n</li>\n</ol>\n<h3>How to Support Local File Resource Storage Instead of HDFS and S3?</h3>\n<blockquote>\n<p><strong>Note</strong>: If it is deployed on a single machine by <code>docker-compose</code>, step 2 can be skipped directly.</p>\n</blockquote>\n<ol>\n<li>Modify the following environment variables in <code>config.env.sh</code>:</li>\n</ol>\n<pre><code>RESOURCE_STORAGE_TYPE=HDFS\nFS_DEFAULT_FS=file:///\n</code></pre>\n<ol start=\"2\">\n<li>Modify the volume <code>dolphinscheduler-resource-local</code> to support NFS in <code>docker-compose.yml</code>.</li>\n</ol>\n<blockquote>\n<p>If you want to deploy DolphinScheduler on Docker Swarm, you need to modify <code>docker-stack.yml</code>.</p>\n</blockquote>\n<pre><code class=\"language-yaml\"><span class=\"hljs-attr\">volumes:</span>\n  <span class=\"hljs-attr\">dolphinscheduler-resource-local:</span>\n    <span class=\"hljs-attr\">driver_opts:</span>\n      <span class=\"hljs-attr\">type:</span> <span class=\"hljs-string\">&quot;nfs&quot;</span>\n      <span class=\"hljs-attr\">o:</span> <span class=\"hljs-string\">&quot;addr=10.40.0.199,nolock,soft,rw&quot;</span>\n      <span class=\"hljs-attr\">device:</span> <span class=\"hljs-string\">&quot;:/path/to/resource/dir&quot;</span>\n</code></pre>\n<h3>How to Support S3 Resource Storage Like MinIO?</h3>\n<p>Take MinIO as an example: modify the following environment variables in <code>config.env.sh</code>.</p>\n<pre><code>RESOURCE_STORAGE_TYPE=S3\nRESOURCE_UPLOAD_PATH=/dolphinscheduler\nFS_DEFAULT_FS=s3a://BUCKET_NAME\nFS_S3A_ENDPOINT=http://MINIO_IP:9000\nFS_S3A_ACCESS_KEY=MINIO_ACCESS_KEY\nFS_S3A_SECRET_KEY=MINIO_SECRET_KEY\n</code></pre>\n<p>Modify <code>BUCKET_NAME</code>, <code>MINIO_IP</code>, <code>MINIO_ACCESS_KEY</code> and <code>MINIO_SECRET_KEY</code> to actual values.</p>\n<blockquote>\n<p><strong>Note</strong>: <code>MINIO_IP</code> can only use IP instead of the domain name, because DolphinScheduler currently doesn't support S3 path style access.</p>\n</blockquote>\n<h3>How to Configure SkyWalking?</h3>\n<p>Modify SkyWalking environment variables in <code>config.env.sh</code>:</p>\n<pre><code>SKYWALKING_ENABLE=true\nSW_AGENT_COLLECTOR_BACKEND_SERVICES=127.0.0.1:11800\nSW_GRPC_LOG_SERVER_HOST=127.0.0.1\nSW_GRPC_LOG_SERVER_PORT=11800\n</code></pre>\n<h2>Appendix-Environment Variables</h2>\n<h3>Database</h3>\n<p><strong><code>DATABASE_TYPE</code></strong></p>\n<p>This environment variable sets the <code>TYPE</code> for the <code>database</code>. The default value is <code>postgresql</code>.</p>\n<p><strong>Note</strong>: You must specify it when starting a standalone DolphinScheduler server. Like <code>master-server</code>, <code>worker-server</code>, <code>api-server</code>, <code>alert-server</code>.</p>\n<p><strong><code>DATABASE_DRIVER</code></strong></p>\n<p>This environment variable sets the <code>DRIVER</code> for the <code>database</code>. The default value is <code>org.postgresql.Driver</code>.</p>\n<p><strong>Note</strong>: You must specify it when starting a standalone DolphinScheduler server. Like <code>master-server</code>, <code>worker-server</code>, <code>api-server</code>, <code>alert-server</code>.</p>\n<p><strong><code>DATABASE_HOST</code></strong></p>\n<p>This environment variable sets the <code>HOST</code> for the <code>database</code>. The default value is <code>127.0.0.1</code>.</p>\n<p><strong>Note</strong>: You must specify it when starting a standalone DolphinScheduler server. Like <code>master-server</code>, <code>worker-server</code>, <code>api-server</code>, <code>alert-server</code>.</p>\n<p><strong><code>DATABASE_PORT</code></strong></p>\n<p>This environment variable sets the <code>PORT</code> for the <code>database</code>. The default value is <code>5432</code>.</p>\n<p><strong>Note</strong>: You must specify it when starting a standalone DolphinScheduler server. Like <code>master-server</code>, <code>worker-server</code>, <code>api-server</code>, <code>alert-server</code>.</p>\n<p><strong><code>DATABASE_USERNAME</code></strong></p>\n<p>This environment variable sets the <code>USERNAME</code> for the <code>database</code>. The default value is <code>root</code>.</p>\n<p><strong>Note</strong>: You must specify it when starting a standalone DolphinScheduler server. Like <code>master-server</code>, <code>worker-server</code>, <code>api-server</code>, <code>alert-server</code>.</p>\n<p><strong><code>DATABASE_PASSWORD</code></strong></p>\n<p>This environment variable sets the <code>PASSWORD</code> for the <code>database</code>. The default value is <code>root</code>.</p>\n<p><strong>Note</strong>: You must specify it when starting a standalone DolphinScheduler server. Like <code>master-server</code>, <code>worker-server</code>, <code>api-server</code>, <code>alert-server</code>.</p>\n<p><strong><code>DATABASE_DATABASE</code></strong></p>\n<p>This environment variable sets the <code>DATABASE</code> for the <code>database</code>. The default value is <code>dolphinscheduler</code>.</p>\n<p><strong>Note</strong>: You must specify it when starting a standalone DolphinScheduler server. Like <code>master-server</code>, <code>worker-server</code>, <code>api-server</code>, <code>alert-server</code>.</p>\n<p><strong><code>DATABASE_PARAMS</code></strong></p>\n<p>This environment variable sets the <code>PARAMS</code> for the <code>database</code>. The default value is <code>characterEncoding=utf8</code>.</p>\n<p><strong>Note</strong>: You must specify it when starting a standalone DolphinScheduler server. Like <code>master-server</code>, <code>worker-server</code>, <code>api-server</code>, <code>alert-server</code>.</p>\n<h3>ZooKeeper</h3>\n<p><strong><code>ZOOKEEPER_QUORUM</code></strong></p>\n<p>This environment variable sets ZooKeeper quorum. The default value is <code>127.0.0.1:2181</code>.</p>\n<p><strong>Note</strong>: You must specify it when starting a standalone DolphinScheduler server. Like <code>master-server</code>, <code>worker-server</code>, <code>api-server</code>.</p>\n<p><strong><code>ZOOKEEPER_ROOT</code></strong></p>\n<p>This environment variable sets the ZooKeeper root directory for DolphinScheduler. The default value is <code>/dolphinscheduler</code>.</p>\n<h3>Common</h3>\n<p><strong><code>DOLPHINSCHEDULER_OPTS</code></strong></p>\n<p>This environment variable sets JVM options for DolphinScheduler, suitable for <code>master-server</code>, <code>worker-server</code>, <code>api-server</code>, <code>alert-server</code>. The default value is empty.</p>\n<p><strong><code>DATA_BASEDIR_PATH</code></strong></p>\n<p>This environment variable sets user data directory, customized configuration, please make sure the directory exists and have read-write permissions. The default value is <code>/tmp/dolphinscheduler</code></p>\n<p><strong><code>RESOURCE_STORAGE_TYPE</code></strong></p>\n<p>This environment variable sets resource storage types for DolphinScheduler like <code>HDFS</code>, <code>S3</code>, <code>NONE</code>. The default value is <code>HDFS</code>.</p>\n<p><strong><code>RESOURCE_UPLOAD_PATH</code></strong></p>\n<p>This environment variable sets resource store path on <code>HDFS/S3</code> for resource storage. The default value is <code>/dolphinscheduler</code>.</p>\n<p><strong><code>FS_DEFAULT_FS</code></strong></p>\n<p>This environment variable sets <code>fs.defaultFS</code> for resource storage like <code>file:///</code>, <code>hdfs://mycluster:8020</code> or <code>s3a://dolphinscheduler</code>. The default value is <code>file:///</code>.</p>\n<p><strong><code>FS_S3A_ENDPOINT</code></strong></p>\n<p>This environment variable sets <code>s3</code> endpoint for resource storage. The default value is <code>s3.xxx.amazonaws.com</code>.</p>\n<p><strong><code>FS_S3A_ACCESS_KEY</code></strong></p>\n<p>This environment variable sets <code>s3</code> access key for resource storage. The default value is <code>xxxxxxx</code>.</p>\n<p><strong><code>FS_S3A_SECRET_KEY</code></strong></p>\n<p>This environment variable sets <code>s3</code> secret key for resource storage. The default value is <code>xxxxxxx</code>.</p>\n<p><strong><code>HADOOP_SECURITY_AUTHENTICATION_STARTUP_STATE</code></strong></p>\n<p>This environment variable sets whether to startup Kerberos. The default value is <code>false</code>.</p>\n<p><strong><code>JAVA_SECURITY_KRB5_CONF_PATH</code></strong></p>\n<p>This environment variable sets <code>java.security.krb5.conf</code> path. The default value is <code>/opt/krb5.conf</code>.</p>\n<p><strong><code>LOGIN_USER_KEYTAB_USERNAME</code></strong></p>\n<p>This environment variable sets the <code>keytab</code> username for the login user. The default value is <code>hdfs@HADOOP.COM</code>.</p>\n<p><strong><code>LOGIN_USER_KEYTAB_PATH</code></strong></p>\n<p>This environment variable sets the <code>keytab</code> path for the login user. The default value is <code>/opt/hdfs.keytab</code>.</p>\n<p><strong><code>KERBEROS_EXPIRE_TIME</code></strong></p>\n<p>This environment variable sets Kerberos expiration time, use hour as unit. The default value is <code>2</code>.</p>\n<p><strong><code>HDFS_ROOT_USER</code></strong></p>\n<p>This environment variable sets HDFS root user when <code>resource.storage.type=HDFS</code>. The default value is <code>hdfs</code>.</p>\n<p><strong><code>RESOURCE_MANAGER_HTTPADDRESS_PORT</code></strong></p>\n<p>This environment variable sets resource manager HTTP address port. The default value is <code>8088</code>.</p>\n<p><strong><code>YARN_RESOURCEMANAGER_HA_RM_IDS</code></strong></p>\n<p>This environment variable sets yarn <code>resourcemanager</code> ha rm ids. The default value is empty.</p>\n<p><strong><code>YARN_APPLICATION_STATUS_ADDRESS</code></strong></p>\n<p>This environment variable sets yarn application status address. The default value is <code>http://ds1:%s/ws/v1/cluster/apps/%s</code>.</p>\n<p><strong><code>SKYWALKING_ENABLE</code></strong></p>\n<p>This environment variable sets whether to enable SkyWalking. The default value is <code>false</code>.</p>\n<p><strong><code>SW_AGENT_COLLECTOR_BACKEND_SERVICES</code></strong></p>\n<p>This environment variable sets agent collector backend services for SkyWalking. The default value is <code>127.0.0.1:11800</code>.</p>\n<p><strong><code>SW_GRPC_LOG_SERVER_HOST</code></strong></p>\n<p>This environment variable sets <code>gRPC</code> log server host for SkyWalking. The default value is <code>127.0.0.1</code>.</p>\n<p><strong><code>SW_GRPC_LOG_SERVER_PORT</code></strong></p>\n<p>This environment variable sets <code>gRPC</code> log server port for SkyWalking. The default value is <code>11800</code>.</p>\n<p><strong><code>HADOOP_HOME</code></strong></p>\n<p>This environment variable sets <code>HADOOP_HOME</code>. The default value is <code>/opt/soft/hadoop</code>.</p>\n<p><strong><code>HADOOP_CONF_DIR</code></strong></p>\n<p>This environment variable sets <code>HADOOP_CONF_DIR</code>. The default value is <code>/opt/soft/hadoop/etc/hadoop</code>.</p>\n<p><strong><code>SPARK_HOME1</code></strong></p>\n<p>This environment variable sets <code>SPARK_HOME1</code>. The default value is <code>/opt/soft/spark1</code>.</p>\n<p><strong><code>SPARK_HOME2</code></strong></p>\n<p>This environment variable sets <code>SPARK_HOME2</code>. The default value is <code>/opt/soft/spark2</code>.</p>\n<p><strong><code>PYTHON_HOME</code></strong></p>\n<p>This environment variable sets <code>PYTHON_HOME</code>. The default value is <code>/usr/bin/python</code>.</p>\n<p><strong><code>JAVA_HOME</code></strong></p>\n<p>This environment variable sets <code>JAVA_HOME</code>. The default value is <code>/usr/local/openjdk-8</code>.</p>\n<p><strong><code>HIVE_HOME</code></strong></p>\n<p>This environment variable sets <code>HIVE_HOME</code>. The default value is <code>/opt/soft/hive</code>.</p>\n<p><strong><code>FLINK_HOME</code></strong></p>\n<p>This environment variable sets <code>FLINK_HOME</code>. The default value is <code>/opt/soft/flink</code>.</p>\n<p><strong><code>DATAX_HOME</code></strong></p>\n<p>This environment variable sets <code>DATAX_HOME</code>. The default value is <code>/opt/soft/datax</code>.</p>\n<h3>Master Server</h3>\n<p><strong><code>MASTER_SERVER_OPTS</code></strong></p>\n<p>This environment variable sets JVM options for <code>master-server</code>. The default value is <code>-Xms1g -Xmx1g -Xmn512m</code>.</p>\n<p><strong><code>MASTER_EXEC_THREADS</code></strong></p>\n<p>This environment variable sets execute thread number for <code>master-server</code>. The default value is <code>100</code>.</p>\n<p><strong><code>MASTER_EXEC_TASK_NUM</code></strong></p>\n<p>This environment variable sets execute task number for <code>master-server</code>. The default value is <code>20</code>.</p>\n<p><strong><code>MASTER_DISPATCH_TASK_NUM</code></strong></p>\n<p>This environment variable sets dispatch task number for <code>master-server</code>. The default value is <code>3</code>.</p>\n<p><strong><code>MASTER_HOST_SELECTOR</code></strong></p>\n<p>This environment variable sets host selector for <code>master-server</code>. Optional values include <code>Random</code>, <code>RoundRobin</code> and <code>LowerWeight</code>. The default value is <code>LowerWeight</code>.</p>\n<p><strong><code>MASTER_HEARTBEAT_INTERVAL</code></strong></p>\n<p>This environment variable sets heartbeat intervals for <code>master-server</code>. The default value is <code>10</code>.</p>\n<p><strong><code>MASTER_TASK_COMMIT_RETRYTIMES</code></strong></p>\n<p>This environment variable sets task commit retry times for <code>master-server</code>. The default value is <code>5</code>.</p>\n<p><strong><code>MASTER_TASK_COMMIT_INTERVAL</code></strong></p>\n<p>This environment variable sets task commit interval for <code>master-server</code>. The default value is <code>1</code>.</p>\n<p><strong><code>MASTER_MAX_CPULOAD_AVG</code></strong></p>\n<p>This environment variable sets max CPU load avg for <code>master-server</code>. The default value is <code>-1</code>.</p>\n<p><strong><code>MASTER_RESERVED_MEMORY</code></strong></p>\n<p>This environment variable sets reserved memory for <code>master-server</code>, the unit is G. The default value is <code>0.3</code>.</p>\n<h3>Worker Server</h3>\n<p><strong><code>WORKER_SERVER_OPTS</code></strong></p>\n<p>This environment variable sets JVM options for <code>worker-server</code>. The default value is <code>-Xms1g -Xmx1g -Xmn512m</code>.</p>\n<p><strong><code>WORKER_EXEC_THREADS</code></strong></p>\n<p>This environment variable sets execute thread number for <code>worker-server</code>. The default value is <code>100</code>.</p>\n<p><strong><code>WORKER_HEARTBEAT_INTERVAL</code></strong></p>\n<p>This environment variable sets heartbeat interval for <code>worker-server</code>. The default value is <code>10</code>.</p>\n<p><strong><code>WORKER_MAX_CPULOAD_AVG</code></strong></p>\n<p>This environment variable sets max CPU load avg for <code>worker-server</code>. The default value is <code>-1</code>.</p>\n<p><strong><code>WORKER_RESERVED_MEMORY</code></strong></p>\n<p>This environment variable sets reserved memory for <code>worker-server</code>, the unit is G. The default value is <code>0.3</code>.</p>\n<p><strong><code>WORKER_GROUPS</code></strong></p>\n<p>This environment variable sets groups for <code>worker-server</code>. The default value is <code>default</code>.</p>\n<h3>Alert Server</h3>\n<p><strong><code>ALERT_SERVER_OPTS</code></strong></p>\n<p>This environment variable sets JVM options for <code>alert-server</code>. The default value is <code>-Xms512m -Xmx512m -Xmn256m</code>.</p>\n<p><strong><code>XLS_FILE_PATH</code></strong></p>\n<p>This environment variable sets <code>xls</code> file path for <code>alert-server</code>. The default value is <code>/tmp/xls</code>.</p>\n<p><strong><code>MAIL_SERVER_HOST</code></strong></p>\n<p>This environment variable sets mail server host for <code>alert-server</code>. The default value is empty.</p>\n<p><strong><code>MAIL_SERVER_PORT</code></strong></p>\n<p>This environment variable sets mail server port for <code>alert-server</code>. The default value is empty.</p>\n<p><strong><code>MAIL_SENDER</code></strong></p>\n<p>This environment variable sets mail sender for <code>alert-server</code>. The default value is empty.</p>\n<p><strong><code>MAIL_USER=</code></strong></p>\n<p>This environment variable sets mail user for <code>alert-server</code>. The default value is empty.</p>\n<p><strong><code>MAIL_PASSWD</code></strong></p>\n<p>This environment variable sets mail password for <code>alert-server</code>. The default value is empty.</p>\n<p><strong><code>MAIL_SMTP_STARTTLS_ENABLE</code></strong></p>\n<p>This environment variable sets SMTP <code>tls</code> for <code>alert-server</code>. The default value is <code>true</code>.</p>\n<p><strong><code>MAIL_SMTP_SSL_ENABLE</code></strong></p>\n<p>This environment variable sets SMTP <code>ssl</code> for <code>alert-server</code>. The default value is <code>false</code>.</p>\n<p><strong><code>MAIL_SMTP_SSL_TRUST</code></strong></p>\n<p>This environment variable sets SMTP <code>ssl</code> trust for <code>alert-server</code>. The default value is empty.</p>\n<p><strong><code>ENTERPRISE_WECHAT_ENABLE</code></strong></p>\n<p>This environment variable sets enterprise WeChat enables for <code>alert-server</code>. The default value is <code>false</code>.</p>\n<p><strong><code>ENTERPRISE_WECHAT_CORP_ID</code></strong></p>\n<p>This environment variable sets enterprise WeChat corp id for <code>alert-server</code>. The default value is empty.</p>\n<p><strong><code>ENTERPRISE_WECHAT_SECRET</code></strong></p>\n<p>This environment variable sets enterprise WeChat secret for <code>alert-server</code>. The default value is empty.</p>\n<p><strong><code>ENTERPRISE_WECHAT_AGENT_ID</code></strong></p>\n<p>This environment variable sets enterprise WeChat agent id for <code>alert-server</code>. The default value is empty.</p>\n<p><strong><code>ENTERPRISE_WECHAT_USERS</code></strong></p>\n<p>This environment variable sets enterprise WeChat users for <code>alert-server</code>. The default value is empty.</p>\n<h3>API Server</h3>\n<p><strong><code>API_SERVER_OPTS</code></strong></p>\n<p>This environment variable sets JVM options for <code>api-server</code>. The default value is <code>-Xms512m -Xmx512m -Xmn256m</code>.</p>\n",
  "link": "/dist/en-us/docs/dev/user_doc/guide/installation/docker.html",
  "meta": {}
}