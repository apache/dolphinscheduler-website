{
  "filename": "map-reduce.md",
  "__html": "<h1>MapReduce Node</h1>\n<h2>Overview</h2>\n<p>MapReduce(MR) task type used for executing MapReduce programs. For MapReduce nodes, the worker submits the task by using the Hadoop command <code>hadoop jar</code>. See <a href=\"https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/CommandsManual.html#jar\">Hadoop Command Manual</a> for more details.</p>\n<h2>Create Task</h2>\n<ul>\n<li>Click <code>Project -&gt; Management-Project -&gt; Name-Workflow Definition</code>, and click the <code>Create Workflow</code> button to enter the DAG editing page.</li>\n<li>Drag from the toolbar <img src=\"/img/tasks/icons/mr.png\" width=\"15\"/> to the canvas.</li>\n</ul>\n<h2>Task Parameter</h2>\n<ul>\n<li><strong>Node name</strong>: The node name in a workflow definition is unique.</li>\n<li><strong>Run flag</strong>: Identifies whether this node schedules normally, if it does not need to execute, select the <code>prohibition execution</code>.</li>\n<li><strong>Descriptive information</strong>: Describe the function of the node.</li>\n<li><strong>Task priority</strong>: When the number of worker threads is insufficient, execute in the order of priority from high to low, and tasks with the same priority will execute in a first-in first-out order.</li>\n<li><strong>Worker grouping</strong>:  Assign tasks to the machines of the worker group to execute. If <code>Default</code> is selected, randomly select a worker machine for execution.</li>\n<li><strong>Environment Name</strong>: Configure the environment name in which run the script.</li>\n<li><strong>Times of failed retry attempts</strong>: The number of times the task failed to resubmit.</li>\n<li><strong>Failed retry interval</strong>: The time interval (unit minute) for resubmitting the task after a failed task.</li>\n<li><strong>Delayed execution time</strong>: The time (unit minute) that a task delays in execution.</li>\n<li><strong>Timeout alarm</strong>: Check the timeout alarm and timeout failure. When the task runs exceed the &quot;timeout&quot;, an alarm email will send and the task execution will fail.</li>\n<li><strong>Resource</strong>: Refers to the list of resource files that called in the script, and upload or create files by the Resource Center file management.</li>\n<li><strong>Custom parameters</strong>: It is a local user-defined parameter for MapReduce, and will replace the content with <code>${variable}</code> in the script.</li>\n<li><strong>Predecessor task</strong>: Selecting a predecessor task for the current task, will set the selected predecessor task as upstream of the current task.</li>\n</ul>\n<h3>JAVA or SCALA Program</h3>\n<ul>\n<li><strong>Program type</strong>: Select JAVA or SCALA program.</li>\n<li><strong>The class of the main function</strong>: The <strong>full path</strong> of Main Class, the entry point of the MapReduce program.</li>\n<li><strong>Main jar package</strong>: The jar package of the MapReduce program.</li>\n<li><strong>Task name</strong> (optional): MapReduce task name.</li>\n<li><strong>Command line parameters</strong>: Set the input parameters of the MapReduce program and support the substitution of custom parameter variables.</li>\n<li><strong>Other parameters</strong>: support <code>-D</code>, <code>-files</code>, <code>-libjars</code>, <code>-archives</code> format.</li>\n<li><strong>Resource</strong>: Appoint resource files in the <code>Resource</code> if parameters refer to them.</li>\n<li><strong>User-defined parameter</strong>: It is a local user-defined parameter for MapReduce, and will replace the content with <code>${variable}</code> in the script.</li>\n</ul>\n<h2>Python Program</h2>\n<ul>\n<li><strong>Program type</strong>: Select Python language.</li>\n<li><strong>Main jar package</strong>: The Python jar package for running MapReduce.</li>\n<li><strong>Other parameters</strong>: support <code>-D</code>, <code>-mapper</code>, <code>-reducer,</code> <code>-input</code> <code>-output</code> format, and you can set the input of user-defined parameters, such as:</li>\n<li><code>-mapper &quot;mapper.py 1&quot;</code> <code>-file mapper.py</code> <code>-reducer reducer.py</code> <code>-file reducer.py</code> <code>â€“input /journey/words.txt</code> <code>-output /journey/out/mr/\\${currentTimeMillis}</code></li>\n<li>The <code>mapper.py 1</code> after <code>-mapper</code> is two parameters, the first parameter is <code>mapper.py</code>, and the second parameter is <code>1</code>.</li>\n<li><strong>Resource</strong>: Appoint resource files in the <code>Resource</code> if parameters refer to them.</li>\n<li><strong>User-defined parameter</strong>: It is a local user-defined parameter for MapReduce, and will replace the content with <code>${variable}</code> in the script.</li>\n</ul>\n<h2>Task Example</h2>\n<h3>Execute the WordCount Program</h3>\n<p>This example is a common introductory type of MapReduce application, which used to count the number of identical words in the input text.</p>\n<h4>Configure the MapReduce Environment in DolphinScheduler</h4>\n<p>If you are using the MapReduce task type in a production environment, it is necessary to configure the required environment first. The following is the configuration file: <code>/dolphinscheduler/conf/env/dolphinscheduler_env.sh</code>.</p>\n<p><img src=\"/img/tasks/demo/mr_task01.png\" alt=\"mr_configure\"></p>\n<h4>Upload the Main Package</h4>\n<p>When using the MapReduce task node, you need to use the Resource Centre to upload the jar package for the execution. Refer to the <a href=\"../resource.md\">resource centre</a>.</p>\n<p>After finish the Resource Centre configuration, upload the required target files directly by dragging and dropping.</p>\n<p><img src=\"/img/tasks/demo/upload_jar.png\" alt=\"resource_upload\"></p>\n<h4>Configure MapReduce Nodes</h4>\n<p>Configure the required content according to the parameter descriptions above.</p>\n<p><img src=\"/img/tasks/demo/mr_task02.png\" alt=\"demo-mr-simple\"></p>\n",
  "link": "/dist/en-us/docs/dev/user_doc/guide/task/map-reduce.html",
  "meta": {}
}