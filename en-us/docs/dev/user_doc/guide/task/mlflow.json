{
  "filename": "mlflow.md",
  "__html": "<h1>MLflow Node</h1>\n<h2>Overview</h2>\n<p><a href=\"https://mlflow.org\">MLflow</a> is an excellent open source platform to manage the ML lifecycle, including experimentation,\nreproducibility, deployment, and a central model registry.</p>\n<p>MLflow task plugin used to execute MLflow tasks, Currently contains MLflow Projects and MLflow Models. (Model Registry will soon be rewarded for support)</p>\n<ul>\n<li>MLflow Projects: Package data science code in a format to reproduce runs on any platform.</li>\n<li>MLflow Models: Deploy machine learning models in diverse serving environments.</li>\n<li>Model Registry: Store, annotate, discover, and manage models in a central repository.</li>\n</ul>\n<p>The MLflow plugin currently supports and will support the following:</p>\n<ul>\n<li>MLflow Projects\n<ul>\n<li>BasicAlgorithm: contains LogisticRegression, svm, lightgbm, xgboost</li>\n<li>AutoML: AutoML tool, contains autosklean, flaml</li>\n<li>Custom projects: Support for running your own MLflow projects</li>\n</ul>\n</li>\n<li>MLflow Models\n<ul>\n<li>MLFLOW: Use <code>MLflow models serve</code> to deploy a model service</li>\n<li>Docker: Run the container after packaging the docker image</li>\n<li>Docker Compose: Use docker compose to run the container, it will replace the docker run above</li>\n</ul>\n</li>\n</ul>\n<h2>Create Task</h2>\n<ul>\n<li>Click <code>Project Management -&gt; Project Name -&gt; Workflow Definition</code>, and click the <code>Create Workflow</code> button to enter the DAG editing page.</li>\n<li>Drag from the toolbar <img src=\"/img/tasks/icons/mlflow.png\" width=\"15\"/> task node to canvas.</li>\n</ul>\n<h2>Task Parameters and Example</h2>\n<table>\n<thead>\n<tr>\n<th><strong>Parameter</strong></th>\n<th><strong>Description</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Node Name</td>\n<td>Set the name of the task. Node names within a workflow definition are unique.</td>\n</tr>\n<tr>\n<td>Run flag</td>\n<td>Indicates whether the node can be scheduled normally. If it is not necessary to execute, you can turn on the prohibiting execution switch.</td>\n</tr>\n<tr>\n<td>Description</td>\n<td>Describes the function of this node.</td>\n</tr>\n<tr>\n<td>Task priority</td>\n<td>When the number of worker threads is insufficient, they are executed in order from high to low according to the priority, and they are executed according to the first-in, first-out principle when the priority is the same.</td>\n</tr>\n<tr>\n<td>Worker group</td>\n<td>The task is assigned to the machines in the worker group for execution. If Default is selected, a worker machine will be randomly selected for execution.</td>\n</tr>\n<tr>\n<td>Task group name</td>\n<td>The group in Resources, if not configured, it will not be used.</td>\n</tr>\n<tr>\n<td>Environment Name</td>\n<td>Configure the environment in which to run the script.</td>\n</tr>\n<tr>\n<td>Number of failed retries</td>\n<td>The number of times the task is resubmitted after failure. It supports drop-down and manual filling.</td>\n</tr>\n<tr>\n<td>Failure Retry Interval</td>\n<td>The time interval for resubmitting the task if the task fails. It supports drop-down and manual filling.</td>\n</tr>\n<tr>\n<td>Timeout alarm</td>\n<td>Check Timeout Alarm and Timeout Failure. When the task exceeds the &quot;timeout duration&quot;, an alarm email will be sent and the task execution will fail.</td>\n</tr>\n<tr>\n<td>Predecessor task</td>\n<td>Selecting the predecessor task of the current task will set the selected predecessor task as the upstream of the current task.</td>\n</tr>\n<tr>\n<td>MLflow Tracking Server URI</td>\n<td>MLflow Tracking Server URI, default <a href=\"http://localhost:5000\">http://localhost:5000</a>.</td>\n</tr>\n<tr>\n<td>Experiment Name</td>\n<td>Create the experiment where the task is running, if the experiment does not exist. If the name is empty, it is set to <code>Default</code>, the same as MLflow.</td>\n</tr>\n</tbody>\n</table>\n<h3>MLflow Projects</h3>\n<h4>BasicAlgorithm</h4>\n<p><img src=\"/img/tasks/demo/mlflow-basic-algorithm.png\" alt=\"mlflow-conda-env\"></p>\n<p><strong>Task Parameters</strong></p>\n<table>\n<thead>\n<tr>\n<th><strong>Parameter</strong></th>\n<th><strong>Description</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Register Model</td>\n<td>Register the model or not. If register is selected, the following parameters are expanded.</td>\n</tr>\n<tr>\n<td>Model Name</td>\n<td>The registered model name is added to the original model version and registered as Production.</td>\n</tr>\n<tr>\n<td>Data Path</td>\n<td>The absolute path of the file or folder. Ends with .csv for file or contain train.csv and test.csv for folderï¼ˆIn the suggested way, users should build their own test sets for model evaluation.</td>\n</tr>\n<tr>\n<td>Parameters</td>\n<td>Parameter when initializing the algorithm/AutoML model, which can be empty. For example, parameters <code>&quot;time_budget=30;estimator_list=['lgbm']&quot;</code> for flaml. The convention will be passed with '; ' shards each parameter, using the name before the equal sign as the parameter name, and using the name after the equal sign to get the corresponding parameter value through <code>python eval()</code>. <ul><li><a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression\">Logistic Regression</a></li><li><a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html?highlight=svc#sklearn.svm.SVC\">SVM</a></li><li><a href=\"https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMClassifier.html#lightgbm.LGBMClassifier\">lightgbm</a></li><li><a href=\"https://xgboost.readthedocs.io/en/stable/python/python_api.html#xgboost.XGBClassifier\">xgboost</a></li></ul></td>\n</tr>\n<tr>\n<td>Algorithm</td>\n<td>The selected algorithm currently supports <code>LR</code>, <code>SVM</code>, <code>LightGBM</code> and <code>XGboost</code> based on <a href=\"https://scikit-learn.org/\">scikit-learn</a> form.</td>\n</tr>\n<tr>\n<td>Parameter Search Space</td>\n<td>Parameter search space when running the corresponding algorithm, which can be empty. For example, the parameter <code>max_depth=[5, 10];n_estimators=[100, 200]</code> for lightgbm. The convention will be passed with '; 'shards each parameter, using the name before the equal sign as the parameter name, and using the name after the equal sign to get the corresponding parameter value through <code>python eval()</code>.</td>\n</tr>\n</tbody>\n</table>\n<h4>AutoML</h4>\n<p><img src=\"/img/tasks/demo/mlflow-automl.png\" alt=\"mlflow-automl\"></p>\n<p><strong>Task Parameter</strong></p>\n<table>\n<thead>\n<tr>\n<th><strong>Parameter</strong></th>\n<th><strong>Description</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Register Model</td>\n<td>Register the model or not. If register is selected, the following parameters are expanded.</td>\n</tr>\n<tr>\n<td>model name</td>\n<td>The registered model name is added to the original model version and registered as Production.</td>\n</tr>\n<tr>\n<td>Data Path</td>\n<td>The absolute path of the file or folder. Ends with .csv for file or contain train.csv and test.csv for folder(In the suggested way, users should build their own test sets for model evaluation).</td>\n</tr>\n<tr>\n<td>Parameters</td>\n<td>Parameter when initializing the algorithm/AutoML model, which can be empty. For example, parameters <code>n_estimators=200;learning_rate=0.2</code> for flaml. The convention will be passed with '; 'shards each parameter, using the name before the equal sign as the parameter name, and using the name after the equal sign to get the corresponding parameter value through <code>python eval()</code>. The detailed parameter list is as follows: <ul><li><a href=\"https://microsoft.github.io/FLAML/docs/reference/automl#automl-objects\">flaml</a></li><li><a href=\"https://automl.github.io/auto-sklearn/master/api.html\">autosklearn</a></li></ul></td>\n</tr>\n<tr>\n<td>AutoML tool</td>\n<td>The AutoML tool used, currently supports <a href=\"https://github.com/automl/auto-sklearn\">autosklearn</a> and <a href=\"https://github.com/microsoft/FLAML\">flaml</a>.</td>\n</tr>\n</tbody>\n</table>\n<h4>Custom projects</h4>\n<p><img src=\"/img/tasks/demo/mlflow-custom-project.png\" alt=\"mlflow-custom-project.png\"></p>\n<p><strong>Task Parameter</strong></p>\n<table>\n<thead>\n<tr>\n<th><strong>Parameter</strong></th>\n<th><strong>Description</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>parameters</td>\n<td><code>--param-list</code> in <code>mlflow run</code>. For example <code>-P learning_rate=0.2 -P colsample_bytree=0.8 -P subsample=0.9</code>.</td>\n</tr>\n<tr>\n<td>Repository</td>\n<td>Repository url of MLflow Project, Support git address and directory on worker. If it's in a subdirectory, We add <code>#</code> to support this (same as <code>mlflow run</code>) , for example <code>https://github.com/mlflow/mlflow#examples/xgboost/xgboost_native</code>.</td>\n</tr>\n<tr>\n<td>Project Version</td>\n<td>Version of the project, default master.</td>\n</tr>\n</tbody>\n</table>\n<p>You can now use this feature to run all MLFlow projects on Github (For example <a href=\"https://github.com/mlflow/mlflow/tree/master/examples\">MLflow examples</a> ). You can also create your own machine learning library to reuse your work, and then use DolphinScheduler to use your library with one click.</p>\n<h3>MLflow Models</h3>\n<p><strong>General Parameters</strong></p>\n<table>\n<thead>\n<tr>\n<th><strong>Parameter</strong></th>\n<th><strong>Description</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Model-URI</td>\n<td>Model-URI of MLflow , support <code>models:/&lt;model_name&gt;/suffix</code> format and <code>runs:/</code> format. See <a href=\"https://mlflow.org/docs/latest/tracking.html#artifact-stores\">https://mlflow.org/docs/latest/tracking.html#artifact-stores</a></td>\n</tr>\n<tr>\n<td>Port</td>\n<td>The port to listen on.</td>\n</tr>\n</tbody>\n</table>\n<h4>MLflow</h4>\n<p><img src=\"/img/tasks/demo/mlflow-models-mlflow.png\" alt=\"mlflow-models-mlflow\"></p>\n<h4>Docker</h4>\n<p><img src=\"/img/tasks/demo/mlflow-models-docker.png\" alt=\"mlflow-models-docker\"></p>\n<h4>DOCKER COMPOSE</h4>\n<p><img src=\"/img/tasks/demo/mlflow-models-docker-compose.png\" alt=\"mlflow-models-docker-compose\"></p>\n<table>\n<thead>\n<tr>\n<th><strong>Parameter</strong></th>\n<th><strong>Description</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Max Cpu Limit</td>\n<td>For example, <code>1.0</code> or <code>0.5</code>, the same as docker compose.</td>\n</tr>\n<tr>\n<td>Max Memory Limit</td>\n<td>For example <code>1G</code> or <code>500M</code>, the same as docker compose.</td>\n</tr>\n</tbody>\n</table>\n<h2>Environment to Prepare</h2>\n<h3>Conda Environment</h3>\n<p>You need to enter the admin account to configure a conda environment variableï¼ˆPlease\ninstall <a href=\"https://docs.continuum.io/anaconda/install/\">anaconda</a>\nor <a href=\"https://docs.conda.io/en/latest/miniconda.html#installing\">miniconda</a> in advance).</p>\n<p><img src=\"/img/tasks/demo/mlflow-conda-env.png\" alt=\"mlflow-conda-env\"></p>\n<p>Note During the configuration task, select the conda environment created above. Otherwise, the program cannot find the\nConda environment.</p>\n<p><img src=\"/img/tasks/demo/mlflow-set-conda-env.png\" alt=\"mlflow-set-conda-env\"></p>\n<h3>Start the MLflow Service</h3>\n<p>Make sure you have installed MLflow, using 'pip install mlflow'.</p>\n<p>Create a folder where you want to save your experiments and models and start MLflow service.</p>\n<pre><code class=\"language-sh\">mkdir mlflow\n<span class=\"hljs-built_in\">cd</span> mlflow\nmlflow server -h 0.0.0.0 -p 5000 --serve-artifacts --backend-store-uri sqlite:///mlflow.db\n</code></pre>\n<p>After running, an MLflow service is started.</p>\n<p>After this, you can visit the MLflow service (<code>http://localhost:5000</code>) page to view the experiments and models.</p>\n<p><img src=\"/img/tasks/demo/mlflow-server.png\" alt=\"mlflow-server\"></p>\n",
  "link": "/dist/en-us/docs/dev/user_doc/guide/task/mlflow.html",
  "meta": {}
}