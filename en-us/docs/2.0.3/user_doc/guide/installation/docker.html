<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
  <meta name="keywords" content="docker">
  <meta name="description" content="docker">
  <title>docker</title>
  <link rel="shortcut icon" href="/img/favicon.ico">
  <link rel="stylesheet" href="/build/vendor.23870e5.css">
</head>
<body>
  <div id="root"><div class="md2html docs-page" data-reactroot=""><header class="header-container header-container-dark"><div class="header-body"><span class="mobile-menu-btn mobile-menu-btn-dark"></span><a href="/en-us/index.html"><img class="logo" src="/img/hlogo_white.svg"/></a><div class="search search-dark"><span class="icon-search"></span></div><span class="language-switch language-switch-dark">中</span><div class="header-menu"><div><ul class="ant-menu whiteClass ant-menu-light ant-menu-root ant-menu-horizontal" role="menu"><li class="ant-menu-submenu ant-menu-submenu-horizontal ant-menu-overflowed-submenu" style="display:none" role="menuitem"><div class="ant-menu-submenu-title" aria-expanded="false" aria-haspopup="true"><span>···</span><i class="ant-menu-submenu-arrow"></i></div></li><li class="ant-menu-item" role="menuitem"><a href="/en-us/index.html" target="_self">HOME</a></li><li class="ant-menu-submenu ant-menu-submenu-horizontal ant-menu-overflowed-submenu" style="display:none" role="menuitem"><div class="ant-menu-submenu-title" aria-expanded="false" aria-haspopup="true"><span>···</span><i class="ant-menu-submenu-arrow"></i></div></li><li class="ant-menu-submenu ant-menu-submenu-horizontal ant-menu-item-selected" role="menuitem"><div class="ant-menu-submenu-title" aria-expanded="false" aria-haspopup="true"><span class="submenu-title-wrapper"><a href="/en-us/docs/latest/user_doc/guide/quick-start.html" target="_self">DOCS</a></span><i class="ant-menu-submenu-arrow"></i></div></li><li class="ant-menu-submenu ant-menu-submenu-horizontal ant-menu-overflowed-submenu" style="display:none" role="menuitem"><div class="ant-menu-submenu-title" aria-expanded="false" aria-haspopup="true"><span>···</span><i class="ant-menu-submenu-arrow"></i></div></li><li class="ant-menu-item" role="menuitem"><a href="/en-us/download/download.html" target="_self">DOWNLOAD</a></li><li class="ant-menu-submenu ant-menu-submenu-horizontal ant-menu-overflowed-submenu" style="display:none" role="menuitem"><div class="ant-menu-submenu-title" aria-expanded="false" aria-haspopup="true"><span>···</span><i class="ant-menu-submenu-arrow"></i></div></li><li class="ant-menu-item" role="menuitem"><a href="/en-us/blog/index.html" target="_self">BLOG</a></li><li class="ant-menu-submenu ant-menu-submenu-horizontal ant-menu-overflowed-submenu" style="display:none" role="menuitem"><div class="ant-menu-submenu-title" aria-expanded="false" aria-haspopup="true"><span>···</span><i class="ant-menu-submenu-arrow"></i></div></li><li class="ant-menu-item" role="menuitem"><a href="/en-us/development/development-environment-setup.html" target="_self">DEVELOPMENT</a></li><li class="ant-menu-submenu ant-menu-submenu-horizontal ant-menu-overflowed-submenu" style="display:none" role="menuitem"><div class="ant-menu-submenu-title" aria-expanded="false" aria-haspopup="true"><span>···</span><i class="ant-menu-submenu-arrow"></i></div></li><li class="ant-menu-item" role="menuitem"><a href="/en-us/community/team.html" target="_self">COMMUNITY</a></li><li class="ant-menu-submenu ant-menu-submenu-horizontal ant-menu-overflowed-submenu" style="display:none" role="menuitem"><div class="ant-menu-submenu-title" aria-expanded="false" aria-haspopup="true"><span>···</span><i class="ant-menu-submenu-arrow"></i></div></li><li class="ant-menu-submenu ant-menu-submenu-horizontal" role="menuitem"><div class="ant-menu-submenu-title" aria-expanded="false" aria-haspopup="true"><span class="submenu-title-wrapper"><a href="https://www.apache.org/" target="_blank">ASF</a></span><i class="ant-menu-submenu-arrow"></i></div></li><li class="ant-menu-submenu ant-menu-submenu-horizontal ant-menu-overflowed-submenu" style="display:none" role="menuitem"><div class="ant-menu-submenu-title" aria-expanded="false" aria-haspopup="true"><span>···</span><i class="ant-menu-submenu-arrow"></i></div></li><li class="ant-menu-item" role="menuitem"><a href="/en-us/user/index.html" target="_self">USER</a></li><li class="ant-menu-submenu ant-menu-submenu-horizontal ant-menu-overflowed-submenu" style="visibility:hidden;position:absolute" role="menuitem"><div class="ant-menu-submenu-title" aria-expanded="false" aria-haspopup="true"><span>···</span><i class="ant-menu-submenu-arrow"></i></div></li></ul></div></div><div class="mobile-menu"><div class="mobile-menu-content"><div class="mobile-menu-list"><div class="mobile-menu-item"><a class="mobile-menu-title" href="/en-us/index.html" target="_self">HOME</a></div><div class="mobile-menu-item"><a class="mobile-menu-title" href="/en-us/docs/latest/user_doc/guide/quick-start.html" target="_self">DOCS</a><em class="mobile-menu-icon"></em><div class="mobile-sub-menus"><div class="mobile-sub-menu-item"><a href="/en-us/docs/latest/user_doc/guide/quick-start.html" target="_self">latest(2.0.5)</a></div><div class="mobile-sub-menu-item"><a href="/en-us/docs/1.3.9/user_doc/quick-start.html" target="_self">1.3.9</a></div><div class="mobile-sub-menu-item"><a href="/en-us/docs/release/history-versions.html" target="_self">Older Versions</a></div><div class="mobile-sub-menu-item"><a href="/python/index.html" target="_self">PyDolphinScheduler</a></div><div class="mobile-sub-menu-item"><a href="/en-us/docs/dev/user_doc/about/introduction.html" target="_self">dev</a></div></div></div><div class="mobile-menu-item"><a class="mobile-menu-title" href="/en-us/download/download.html" target="_self">DOWNLOAD</a></div><div class="mobile-menu-item"><a class="mobile-menu-title" href="/en-us/blog/index.html" target="_self">BLOG</a></div><div class="mobile-menu-item"><a class="mobile-menu-title" href="/en-us/development/development-environment-setup.html" target="_self">DEVELOPMENT</a></div><div class="mobile-menu-item"><a class="mobile-menu-title" href="/en-us/community/team.html" target="_self">COMMUNITY</a></div><div class="mobile-menu-item"><a class="mobile-menu-title" href="https://www.apache.org/" target="_blank">ASF</a><em class="mobile-menu-icon"></em><div class="mobile-sub-menus"><div class="mobile-sub-menu-item"><a href="https://www.apache.org/" target="_blank">Foundation</a></div><div class="mobile-sub-menu-item"><a href="https://www.apache.org/licenses/" target="_blank">License</a></div><div class="mobile-sub-menu-item"><a href="https://www.apache.org/events/current-event" target="_blank">Events</a></div><div class="mobile-sub-menu-item"><a href="https://www.apache.org/security/" target="_blank">Security</a></div><div class="mobile-sub-menu-item"><a href="https://www.apache.org/foundation/sponsorship.html" target="_blank">Sponsorship</a></div><div class="mobile-sub-menu-item"><a href="https://www.apache.org/foundation/thanks.html" target="_blank">Thanks</a></div></div></div><div class="mobile-menu-item"><a class="mobile-menu-title" href="/en-us/user/index.html" target="_self">USER</a></div></div></div><div class="mobile-menu-dummy"></div></div></div></header><section class="content-section"><div class="sidemenu"><div class="sidemenu-toggle"><img src="https://img.alicdn.com/tfs/TB1E6apXHGYBuNjy0FoXXciBFXa-200-200.png"/></div><ul><li class="menu-item menu-item-level-1"><span>About</span><ul><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/en-us/docs/2.0.3/user_doc/About_DolphinScheduler/About_DolphinScheduler.html" target="_self">Introduction</a></li><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/en-us/docs/2.0.3/user_doc/guide/installation/hardware.html" target="_self">Hardware Environment</a></li><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/en-us/docs/2.0.3/user_doc/architecture/designplus.html" target="_self">Glossary</a></li></ul></li><li class="menu-item menu-item-level-1"><span>Quick Start</span><ul><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/en-us/docs/2.0.3/user_doc/guide/quick-start.html" target="_self">Quick Start</a></li><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/en-us/docs/2.0.3/user_doc/guide/installation/docker.html" target="_self">Docker Deployment</a></li></ul></li><li class="menu-item menu-item-level-1"><span>Installation</span><ul><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/en-us/docs/2.0.3/user_doc/guide/installation/standalone.html" target="_self">Standalone Deployment</a></li><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/en-us/docs/2.0.3/user_doc/guide/installation/pseudo-cluster.html" target="_self">Pseudo Cluster Deployment</a></li><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/en-us/docs/2.0.3/user_doc/guide/installation/cluster.html" target="_self">Cluster Deployment</a></li><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/en-us/docs/2.0.3/user_doc/guide/installation/kubernetes.html" target="_self">Kubernetes Deployment</a></li></ul></li><li class="menu-item menu-item-level-1"><span>Introduction to Functions</span><ul><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/en-us/docs/2.0.3/user_doc/guide/homepage.html" target="_self">Workflow Overview</a></li><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><span>Project<img style="transform:rotate(-90deg)" class="menu-toggle" src="/img/system/arrow_down.png"/></span><ul><li class="menu-item menu-item-level-3"><a href="/en-us/docs/2.0.3/user_doc/guide/project/project-list.html" target="_self">Project List</a></li><li class="menu-item menu-item-level-3"><a href="/en-us/docs/2.0.3/user_doc/guide/project/workflow-definition.html" target="_self">Workflow Definition</a></li><li class="menu-item menu-item-level-3"><a href="/en-us/docs/2.0.3/user_doc/guide/project/workflow-instance.html" target="_self">Workflow Instance</a></li><li class="menu-item menu-item-level-3"><a href="/en-us/docs/2.0.3/user_doc/guide/project/task-instance.html" target="_self">Task Instance</a></li></ul></li><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><span>Task<img style="transform:rotate(-90deg)" class="menu-toggle" src="/img/system/arrow_down.png"/></span><ul><li class="menu-item menu-item-level-3"><a href="/en-us/docs/2.0.3/user_doc/guide/task/shell.html" target="_self">Shell</a></li><li class="menu-item menu-item-level-3"><a href="/en-us/docs/2.0.3/user_doc/guide/task/sub-process.html" target="_self">SubProcess</a></li><li class="menu-item menu-item-level-3"><a href="/en-us/docs/2.0.3/user_doc/guide/task/dependent.html" target="_self">Dependent</a></li><li class="menu-item menu-item-level-3"><a href="/en-us/docs/2.0.3/user_doc/guide/task/stored-procedure.html" target="_self">Stored Procedure</a></li><li class="menu-item menu-item-level-3"><a href="/en-us/docs/2.0.3/user_doc/guide/task/sql.html" target="_self">SQL</a></li><li class="menu-item menu-item-level-3"><a href="/en-us/docs/2.0.3/user_doc/guide/task/spark.html" target="_self">Spark</a></li><li class="menu-item menu-item-level-3"><a href="/en-us/docs/2.0.3/user_doc/guide/task/map-reduce.html" target="_self">MapReduce</a></li><li class="menu-item menu-item-level-3"><a href="/en-us/docs/2.0.3/user_doc/guide/task/python.html" target="_self">Python</a></li><li class="menu-item menu-item-level-3"><a href="/en-us/docs/2.0.3/user_doc/guide/task/flink.html" target="_self">Flink</a></li><li class="menu-item menu-item-level-3"><a href="/en-us/docs/2.0.3/user_doc/guide/task/http.html" target="_self">HTTP</a></li><li class="menu-item menu-item-level-3"><a href="/en-us/docs/2.0.3/user_doc/guide/task/datax.html" target="_self">DataX</a></li><li class="menu-item menu-item-level-3"><a href="/en-us/docs/2.0.3/user_doc/guide/task/pigeon.html" target="_self">Pigeon</a></li><li class="menu-item menu-item-level-3"><a href="/en-us/docs/2.0.3/user_doc/guide/task/conditions.html" target="_self">Conditions</a></li><li class="menu-item menu-item-level-3"><a href="/en-us/docs/2.0.3/user_doc/guide/task/switch.html" target="_self">Switch</a></li></ul></li><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><span>Parameter<img style="transform:rotate(-90deg)" class="menu-toggle" src="/img/system/arrow_down.png"/></span><ul><li class="menu-item menu-item-level-3"><a href="/en-us/docs/2.0.3/user_doc/guide/parameter/built-in.html" target="_self">Built-in Parameter</a></li><li class="menu-item menu-item-level-3"><a href="/en-us/docs/2.0.3/user_doc/guide/parameter/global.html" target="_self">Global Parameter</a></li><li class="menu-item menu-item-level-3"><a href="/en-us/docs/2.0.3/user_doc/guide/parameter/local.html" target="_self">Local Parameter</a></li><li class="menu-item menu-item-level-3"><a href="/en-us/docs/2.0.3/user_doc/guide/parameter/context.html" target="_self">Parameter Context</a></li><li class="menu-item menu-item-level-3"><a href="/en-us/docs/2.0.3/user_doc/guide/parameter/priority.html" target="_self">Parameter Priority</a></li></ul></li><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><span>Data Source<img style="transform:rotate(-90deg)" class="menu-toggle" src="/img/system/arrow_down.png"/></span><ul><li class="menu-item menu-item-level-3"><a href="/en-us/docs/2.0.3/user_doc/guide/datasource/introduction.html" target="_self">Introduction</a></li><li class="menu-item menu-item-level-3"><a href="/en-us/docs/2.0.3/user_doc/guide/datasource/mysql.html" target="_self">MySQL</a></li><li class="menu-item menu-item-level-3"><a href="/en-us/docs/2.0.3/user_doc/guide/datasource/postgresql.html" target="_self">PostgreSQL</a></li><li class="menu-item menu-item-level-3"><a href="/en-us/docs/2.0.3/user_doc/guide/datasource/hive.html" target="_self">HIVE</a></li><li class="menu-item menu-item-level-3"><a href="/en-us/docs/2.0.3/user_doc/guide/datasource/spark.html" target="_self">Spark</a></li></ul></li><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><span>Alert<img style="transform:rotate(-90deg)" class="menu-toggle" src="/img/system/arrow_down.png"/></span><ul><li class="menu-item menu-item-level-3"><a href="/en-us/docs/2.0.3/user_doc/guide/alert/alert_plugin_user_guide.html" target="_self">Alert Component User Guide </a></li><li class="menu-item menu-item-level-3"><a href="/en-us/docs/2.0.3/user_doc/guide/alert/enterprise-wechat.html" target="_self">Enterprise Wechat</a></li></ul></li><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/en-us/docs/2.0.3/user_doc/guide/resource.html" target="_self">Resource</a></li><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/en-us/docs/2.0.3/user_doc/guide/monitor.html" target="_self">Monitor</a></li><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/en-us/docs/2.0.3/user_doc/guide/security.html" target="_self">Security</a></li><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/en-us/docs/2.0.3/user_doc/guide/open-api.html" target="_self">Open API</a></li><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/en-us/docs/2.0.3/user_doc/guide/flink-call.html" target="_self">Flink</a></li><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/en-us/docs/2.0.3/user_doc/guide/upgrade.html" target="_self">Upgrade</a></li><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/en-us/docs/2.0.3/user_doc/guide/expansion-reduction.html" target="_self">Expansion and Reduction</a></li></ul></li><li class="menu-item menu-item-level-1"><span>Advanced Guide</span><ul><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/en-us/docs/2.0.3/user_doc/architecture/design.html" target="_self">Architecture Design</a></li><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/en-us/docs/2.0.3/user_doc/architecture/metadata.html" target="_self">Metadata</a></li><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/en-us/docs/2.0.3/user_doc/architecture/configuration.html" target="_self">Configuration File</a></li><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/en-us/docs/2.0.3/user_doc/architecture/task-structure.html" target="_self">Task Structure</a></li><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/en-us/docs/2.0.3/user_doc/architecture/load-balance.html" target="_self">Load Balance</a></li><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/en-us/docs/2.0.3/user_doc/architecture/cache.html" target="_self">Cache</a></li></ul></li><li class="menu-item menu-item-level-1"><span>Observability</span><ul><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/en-us/docs/2.0.3/user_doc/guide/observability/skywalking-agent.html" target="_self">SkyWalking-Agent</a></li></ul></li><li class="menu-item menu-item-level-1"><span>FAQ</span><ul><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/en-us/docs/release/faq.html" target="_self">FAQ</a></li></ul></li><li class="menu-item menu-item-level-1"><span>Older Versions</span><ul><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/en-us/docs/release/history-versions.html" target="_self">Older Versions</a></li></ul></li></ul></div><div class="doc-content markdown-body"><h1>QuickStart in Docker</h1>
<h2>Prerequisites</h2>
<ul>
<li><a href="https://docs.docker.com/engine/install/">Docker</a> 1.13.1+</li>
<li><a href="https://docs.docker.com/compose/">Docker Compose</a> 1.11.0+</li>
</ul>
<h2>How to Use this Docker Image</h2>
<p>Here're 3 ways to quickly install DolphinScheduler</p>
<h3>The First Way: Start a DolphinScheduler by Docker Compose (Recommended)</h3>
<p>In this way, you need to install <a href="https://docs.docker.com/compose/">docker-compose</a> as a prerequisite, please install it yourself according to the rich docker-compose installation guidance on the Internet</p>
<p>For Windows 7-10, you can install <a href="https://github.com/docker/toolbox/releases">Docker Toolbox</a>. For Windows 10 64-bit, you can install <a href="https://docs.docker.com/docker-for-windows/install/">Docker Desktop</a>, and pay attention to the <a href="https://docs.docker.com/docker-for-windows/install/#system-requirements">system requirements</a></p>
<h4>Configure Memory not Less Than 4GB</h4>
<p>For Mac user, click <code>Docker Desktop -&gt; Preferences -&gt; Resources -&gt; Memory</code></p>
<p>For Windows Docker Toolbox user, two items need to be configured:</p>
<ul>
<li><strong>Memory</strong>: Open Oracle VirtualBox Manager, if you double-click Docker Quickstart Terminal and successfully run Docker Toolbox, you will see a Virtual Machine named <code>default</code>. And click <code>Settings -&gt; System -&gt; Motherboard -&gt; Base Memory</code></li>
<li><strong>Port Forwarding</strong>: Click <code>Settings -&gt; Network -&gt; Advanced -&gt; Port forwarding -&gt; Add</code>. <code>Name</code>, <code>Host Port</code> and <code>Guest Port</code> all fill in <code>12345</code>, regardless of <code>Host IP</code> and <code>Guest IP</code></li>
</ul>
<p>For Windows Docker Desktop user</p>
<ul>
<li><strong>Hyper-V mode</strong>: Click <code>Docker Desktop -&gt; Settings -&gt; Resources -&gt; Memory</code></li>
<li><strong>WSL 2 mode</strong>: Refer to <a href="https://docs.microsoft.com/en-us/windows/wsl/wsl-config#configure-global-options-with-wslconfig">WSL 2 utility VM</a></li>
</ul>
<h4>Download the Source Code Package</h4>
<p>Please download the source code package apache-dolphinscheduler-2.0.3-src.tar.gz, download address: <a href="/en-us/download/download.html">download</a></p>
<h4>Pull Image and Start the Service</h4>
<blockquote>
<p>For Mac and Linux user, open <strong>Terminal</strong>
For Windows Docker Toolbox user, open <strong>Docker Quickstart Terminal</strong>
For Windows Docker Desktop user, open <strong>Windows PowerShell</strong></p>
</blockquote>
<pre><code>$ tar -zxvf apache-dolphinscheduler-2.0.3-src.tar.gz
$ cd apache-dolphinscheduler-2.0.3-src/docker/docker-swarm
$ docker pull dolphinscheduler.docker.scarf.sh/apache/dolphinscheduler:2.0.3
$ docker tag apache/dolphinscheduler:2.0.3 apache/dolphinscheduler:latest
$ docker-compose up -d
</code></pre>
<blockquote>
<p>PowerShell should use <code>cd apache-dolphinscheduler-2.0.3-src\docker\docker-swarm</code></p>
</blockquote>
<p>The <strong>PostgreSQL</strong> (with username <code>root</code>, password <code>root</code> and database <code>dolphinscheduler</code>) and <strong>ZooKeeper</strong> services will start by default</p>
<h4>Login</h4>
<p>Visit the Web UI: <a href="http://localhost:12345/dolphinscheduler">http://localhost:12345/dolphinscheduler</a> (The local address is <a href="http://localhost:12345/dolphinscheduler">http://localhost:12345/dolphinscheduler</a>)</p>
<p>The default username is <code>admin</code> and the default password is <code>dolphinscheduler123</code></p>
<p align="center">
  <img src="/img/login_en.png" width="60%" />
</p>
<p>Please refer to the <code>Quick Start</code> in the chapter <a href="../quick-start.md">Quick Start</a> to explore how to use DolphinScheduler</p>
<h3>The Second Way: Start via Specifying the Existing PostgreSQL and ZooKeeper Service</h3>
<p>In this way, you need to install <a href="https://docs.docker.com/engine/install/">docker</a> as a prerequisite, please install it yourself according to the rich docker installation guidance on the Internet</p>
<h4>Basic Required Software</h4>
<ul>
<li><a href="https://www.postgresql.org/download/">PostgreSQL</a> (8.2.15+)</li>
<li><a href="https://zookeeper.apache.org/releases.html">ZooKeeper</a> (3.4.6+)</li>
<li><a href="https://docs.docker.com/engine/install/">Docker</a> (1.13.1+)</li>
</ul>
<h4>Please Login to the PostgreSQL Database and Create a Database Named <code>dolphinscheduler</code></h4>
<h4>Initialize the Database, Import <code>sql/dolphinscheduler_postgre.sql</code> to Create Tables and Initial Data</h4>
<h4>Download the DolphinScheduler Image</h4>
<p>We have already uploaded user-oriented DolphinScheduler image to the Docker repository so that you can pull the image from the docker repository:</p>
<pre><code>docker pull dolphinscheduler.docker.scarf.sh/apache/dolphinscheduler:2.0.3
</code></pre>
<h4>5. Run a DolphinScheduler Instance</h4>
<pre><code>$ docker run -d --name dolphinscheduler \
-e DATABASE_HOST=&quot;192.168.x.x&quot; -e DATABASE_PORT=&quot;5432&quot; -e DATABASE_DATABASE=&quot;dolphinscheduler&quot; \
-e DATABASE_USERNAME=&quot;test&quot; -e DATABASE_PASSWORD=&quot;test&quot; \
-e ZOOKEEPER_QUORUM=&quot;192.168.x.x:2181&quot; \
-p 12345:12345 \
apache/dolphinscheduler:2.0.3 all
</code></pre>
<p>Note: database username test and password test need to be replaced with your actual PostgreSQL username and password, 192.168.x.x need to be replaced with your relate PostgreSQL and ZooKeeper host IP</p>
<h4>Login</h4>
<p>Same as above</p>
<h3>The Third Way: Start a Standalone DolphinScheduler Server</h3>
<p>The following services are automatically started when the container starts:</p>
<pre><code>     MasterServer         ----- master service
     WorkerServer         ----- worker service
     LoggerServer         ----- logger service
     ApiApplicationServer ----- api service
     AlertServer          ----- alert service
     PythonGatewayServer  ----- python gateway service
</code></pre>
<p>If you just want to run part of the services in the DolphinScheduler</p>
<p>You can start some services in DolphinScheduler by running the following commands.</p>
<ul>
<li>Start a <strong>master server</strong>, For example:</li>
</ul>
<pre><code>$ docker run -d --name dolphinscheduler-master \
-e DATABASE_HOST=&quot;192.168.x.x&quot; -e DATABASE_PORT=&quot;5432&quot; -e DATABASE_DATABASE=&quot;dolphinscheduler&quot; \
-e DATABASE_USERNAME=&quot;test&quot; -e DATABASE_PASSWORD=&quot;test&quot; \
-e ZOOKEEPER_QUORUM=&quot;192.168.x.x:2181&quot; \
apache/dolphinscheduler:2.0.3 master-server
</code></pre>
<ul>
<li>Start a <strong>worker server</strong> (including <strong>logger server</strong>), For example:</li>
</ul>
<pre><code>$ docker run -d --name dolphinscheduler-worker \
-e DATABASE_HOST=&quot;192.168.x.x&quot; -e DATABASE_PORT=&quot;5432&quot; -e DATABASE_DATABASE=&quot;dolphinscheduler&quot; \
-e DATABASE_USERNAME=&quot;test&quot; -e DATABASE_PASSWORD=&quot;test&quot; \
-e ZOOKEEPER_QUORUM=&quot;192.168.x.x:2181&quot; \
apache/dolphinscheduler:2.0.3 worker-server
</code></pre>
<ul>
<li>Start a <strong>api server</strong>, For example:</li>
</ul>
<pre><code>$ docker run -d --name dolphinscheduler-api \
-e DATABASE_HOST=&quot;192.168.x.x&quot; -e DATABASE_PORT=&quot;5432&quot; -e DATABASE_DATABASE=&quot;dolphinscheduler&quot; \
-e DATABASE_USERNAME=&quot;test&quot; -e DATABASE_PASSWORD=&quot;test&quot; \
-e ZOOKEEPER_QUORUM=&quot;192.168.x.x:2181&quot; \
-p 12345:12345 \
apache/dolphinscheduler:2.0.3 api-server
</code></pre>
<ul>
<li>Start a <strong>alert server</strong>, For example:</li>
</ul>
<pre><code>$ docker run -d --name dolphinscheduler-alert \
-e DATABASE_HOST=&quot;192.168.x.x&quot; -e DATABASE_PORT=&quot;5432&quot; -e DATABASE_DATABASE=&quot;dolphinscheduler&quot; \
-e DATABASE_USERNAME=&quot;test&quot; -e DATABASE_PASSWORD=&quot;test&quot; \
apache/dolphinscheduler:2.0.3 alert-server
</code></pre>
<ul>
<li>Start a <strong>python gateway server</strong>, For example:</li>
</ul>
<pre><code>$ docker run -d --name dolphinscheduler-python-gateway \
-e DATABASE_HOST=&quot;192.168.x.x&quot; -e DATABASE_PORT=&quot;5432&quot; -e DATABASE_DATABASE=&quot;dolphinscheduler&quot; \
-e DATABASE_USERNAME=&quot;test&quot; -e DATABASE_PASSWORD=&quot;test&quot; \
apache/dolphinscheduler:2.0.3 python-gateway
</code></pre>
<p><strong>Note</strong>: You must be specify <code>DATABASE_HOST</code>, <code>DATABASE_PORT</code>, <code>DATABASE_DATABASE</code>, <code>DATABASE_USERNAME</code>, <code>DATABASE_PASSWORD</code>, <code>ZOOKEEPER_QUORUM</code> when start a standalone dolphinscheduler server.</p>
<h2>Environment Variables</h2>
<p>The Docker container is configured through environment variables, and the <a href="#appendix-environment-variables">Appendix-Environment Variables</a> lists the configurable environment variables of the DolphinScheduler and their default values</p>
<p>Especially, it can be configured through the environment variable configuration file <code>config.env.sh</code> in Docker Compose and Docker Swarm</p>
<h2>Support Matrix</h2>
<table>
<thead>
<tr>
<th>Type</th>
<th>Support</th>
<th>Notes</th>
</tr>
</thead>
<tbody>
<tr>
<td>Shell</td>
<td>Yes</td>
<td></td>
</tr>
<tr>
<td>Python2</td>
<td>Yes</td>
<td></td>
</tr>
<tr>
<td>Python3</td>
<td>Indirect Yes</td>
<td>Refer to FAQ</td>
</tr>
<tr>
<td>Hadoop2</td>
<td>Indirect Yes</td>
<td>Refer to FAQ</td>
</tr>
<tr>
<td>Hadoop3</td>
<td>Not Sure</td>
<td>Not tested</td>
</tr>
<tr>
<td>Spark-Local(client)</td>
<td>Indirect Yes</td>
<td>Refer to FAQ</td>
</tr>
<tr>
<td>Spark-YARN(cluster)</td>
<td>Indirect Yes</td>
<td>Refer to FAQ</td>
</tr>
<tr>
<td>Spark-Standalone(cluster)</td>
<td>Not Yet</td>
<td></td>
</tr>
<tr>
<td>Spark-Kubernetes(cluster)</td>
<td>Not Yet</td>
<td></td>
</tr>
<tr>
<td>Flink-Local(local&gt;=1.11)</td>
<td>Not Yet</td>
<td>Generic CLI mode is not yet supported</td>
</tr>
<tr>
<td>Flink-YARN(yarn-cluster)</td>
<td>Indirect Yes</td>
<td>Refer to FAQ</td>
</tr>
<tr>
<td>Flink-YARN(yarn-session/yarn-per-job/yarn-application&gt;=1.11)</td>
<td>Not Yet</td>
<td>Generic CLI mode is not yet supported</td>
</tr>
<tr>
<td>Flink-Standalone(default)</td>
<td>Not Yet</td>
<td></td>
</tr>
<tr>
<td>Flink-Standalone(remote&gt;=1.11)</td>
<td>Not Yet</td>
<td>Generic CLI mode is not yet supported</td>
</tr>
<tr>
<td>Flink-Kubernetes(default)</td>
<td>Not Yet</td>
<td></td>
</tr>
<tr>
<td>Flink-Kubernetes(remote&gt;=1.11)</td>
<td>Not Yet</td>
<td>Generic CLI mode is not yet supported</td>
</tr>
<tr>
<td>Flink-NativeKubernetes(kubernetes-session/application&gt;=1.11)</td>
<td>Not Yet</td>
<td>Generic CLI mode is not yet supported</td>
</tr>
<tr>
<td>MapReduce</td>
<td>Indirect Yes</td>
<td>Refer to FAQ</td>
</tr>
<tr>
<td>Kerberos</td>
<td>Indirect Yes</td>
<td>Refer to FAQ</td>
</tr>
<tr>
<td>HTTP</td>
<td>Yes</td>
<td></td>
</tr>
<tr>
<td>DataX</td>
<td>Indirect Yes</td>
<td>Refer to FAQ</td>
</tr>
<tr>
<td>Sqoop</td>
<td>Indirect Yes</td>
<td>Refer to FAQ</td>
</tr>
<tr>
<td>SQL-MySQL</td>
<td>Indirect Yes</td>
<td>Refer to FAQ</td>
</tr>
<tr>
<td>SQL-PostgreSQL</td>
<td>Yes</td>
<td></td>
</tr>
<tr>
<td>SQL-Hive</td>
<td>Indirect Yes</td>
<td>Refer to FAQ</td>
</tr>
<tr>
<td>SQL-Spark</td>
<td>Indirect Yes</td>
<td>Refer to FAQ</td>
</tr>
<tr>
<td>SQL-ClickHouse</td>
<td>Indirect Yes</td>
<td>Refer to FAQ</td>
</tr>
<tr>
<td>SQL-Oracle</td>
<td>Indirect Yes</td>
<td>Refer to FAQ</td>
</tr>
<tr>
<td>SQL-SQLServer</td>
<td>Indirect Yes</td>
<td>Refer to FAQ</td>
</tr>
<tr>
<td>SQL-DB2</td>
<td>Indirect Yes</td>
<td>Refer to FAQ</td>
</tr>
</tbody>
</table>
<h2>FAQ</h2>
<h3>How to Manage DolphinScheduler by Docker Compose?</h3>
<p>Start, restart, stop or list containers:</p>
<pre><code>docker-compose start
docker-compose restart
docker-compose stop
docker-compose ps
</code></pre>
<p>Stop containers and remove containers, networks:</p>
<pre><code>docker-compose down
</code></pre>
<p>Stop containers and remove containers, networks and volumes:</p>
<pre><code>docker-compose down -v
</code></pre>
<h3>How to View the Logs of a Container?</h3>
<p>List all running containers:</p>
<pre><code>docker ps
docker ps --format &quot;{{.Names}}&quot; # only print names
</code></pre>
<p>View the logs of a container named docker-swarm_dolphinscheduler-api_1:</p>
<pre><code>docker logs docker-swarm_dolphinscheduler-api_1
docker logs -f docker-swarm_dolphinscheduler-api_1 # follow log output
docker logs --tail 10 docker-swarm_dolphinscheduler-api_1 # show last 10 lines from the end of the logs
</code></pre>
<h3>How to Scale Master and Worker by Docker Compose?</h3>
<p>Scale master to 2 instances:</p>
<pre><code>docker-compose up -d --scale dolphinscheduler-master=2 dolphinscheduler-master
</code></pre>
<p>Scale worker to 3 instances:</p>
<pre><code>docker-compose up -d --scale dolphinscheduler-worker=3 dolphinscheduler-worker
</code></pre>
<h3>How to Deploy DolphinScheduler on Docker Swarm?</h3>
<p>Assuming that the Docker Swarm cluster has been created (If there is no Docker Swarm cluster, please refer to <a href="https://docs.docker.com/engine/swarm/swarm-tutorial/create-swarm/">create-swarm</a>)</p>
<p>Start a stack named dolphinscheduler:</p>
<pre><code>docker stack deploy -c docker-stack.yml dolphinscheduler
</code></pre>
<p>List the services in the stack named dolphinscheduler:</p>
<pre><code>docker stack services dolphinscheduler
</code></pre>
<p>Stop and remove the stack named dolphinscheduler:</p>
<pre><code>docker stack rm dolphinscheduler
</code></pre>
<p>Remove the volumes of the stack named dolphinscheduler:</p>
<pre><code>docker volume rm -f $(docker volume ls --format &quot;{{.Name}}&quot; | grep -e &quot;^dolphinscheduler&quot;)
</code></pre>
<h3>How to Scale Master and Worker on Docker Swarm?</h3>
<p>Scale master of the stack named dolphinscheduler to 2 instances:</p>
<pre><code>docker service scale dolphinscheduler_dolphinscheduler-master=2
</code></pre>
<p>Scale worker of the stack named dolphinscheduler to 3 instances:</p>
<pre><code>docker service scale dolphinscheduler_dolphinscheduler-worker=3
</code></pre>
<h3>How to Build a Docker Image?</h3>
<h4>Build from the Source Code (Require Maven 3.3+ and JDK 1.8+)</h4>
<p>In Unix-Like, execute in Terminal:</p>
<pre><code class="language-bash">$ bash ./docker/build/hooks/build
</code></pre>
<p>In Windows, execute in cmd or PowerShell:</p>
<pre><code class="language-bat"><span class="hljs-function">C:\<span class="hljs-title">dolphinscheduler</span>-<span class="hljs-title">src</span>&gt;.\<span class="hljs-title">docker</span>\<span class="hljs-title">build</span>\<span class="hljs-title">hooks</span>\<span class="hljs-title">build.bat</span>
</span></code></pre>
<p>Please read <code>./docker/build/hooks/build</code> <code>./docker/build/hooks/build.bat</code> script files if you don't understand</p>
<h4>Build from the Binary Distribution (Not require Maven 3.3+ and JDK 1.8+)</h4>
<p>Please download the binary distribution package apache-dolphinscheduler-2.0.3-bin.tar.gz, download address: <a href="/en-us/download/download.html">download</a>. And put apache-dolphinscheduler-2.0.3-bin.tar.gz into the <code>apache-dolphinscheduler-2.0.3-src/docker/build</code> directory, execute in Terminal or PowerShell:</p>
<pre><code>$ cd apache-dolphinscheduler-2.0.3-src/docker/build
$ docker build --build-arg VERSION=2.0.3 -t apache/dolphinscheduler:2.0.3 .
</code></pre>
<blockquote>
<p>PowerShell should use <code>cd apache-dolphinscheduler-2.0.3-src/docker/build</code></p>
</blockquote>
<h4>Build Multi-Platform Images</h4>
<p>Currently support to build images including <code>linux/amd64</code> and <code>linux/arm64</code> platform architecture, requirements:</p>
<ol>
<li>Support <a href="https://docs.docker.com/engine/reference/commandline/buildx/">docker buildx</a></li>
<li>Own the push permission of <a href="https://hub.docker.com/r/apache/dolphinscheduler">https://hub.docker.com/r/apache/dolphinscheduler</a> (<strong>Be cautious</strong>: The build command will automatically push the multi-platform architecture images to the docker hub of apache/dolphinscheduler by default)</li>
</ol>
<p>Execute:</p>
<pre><code class="language-bash">$ docker login <span class="hljs-comment"># login to push apache/dolphinscheduler</span>
$ bash ./docker/build/hooks/build
</code></pre>
<h3>How to Add an Environment Variable for Docker?</h3>
<p>If you would like to do additional initialization in an image derived from this one, add one or more environment variables under <code>/root/start-init-conf.sh</code>, and modify template files in <code>/opt/dolphinscheduler/conf/*.tpl</code>.</p>
<p>For example, to add an environment variable <code>SECURITY_AUTHENTICATION_TYPE</code> in <code>/root/start-init-conf.sh</code>:</p>
<pre><code>export SECURITY_AUTHENTICATION_TYPE=PASSWORD
</code></pre>
<p>and to modify <code>application-api.properties.tpl</code> template file, add the <code>SECURITY_AUTHENTICATION_TYPE</code>:</p>
<pre><code>security.authentication.type=${SECURITY_AUTHENTICATION_TYPE}
</code></pre>
<p><code>/root/start-init-conf.sh</code> will dynamically generate config file:</p>
<pre><code class="language-sh"><span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;generate dolphinscheduler config&quot;</span>
ls <span class="hljs-variable">${DOLPHINSCHEDULER_HOME}</span>/conf/ | grep <span class="hljs-string">&quot;.tpl&quot;</span> | <span class="hljs-keyword">while</span> <span class="hljs-built_in">read</span> line; <span class="hljs-keyword">do</span>
<span class="hljs-built_in">eval</span> <span class="hljs-string">&quot;cat &lt;&lt; EOF
<span class="hljs-subst">$(cat ${DOLPHINSCHEDULER_HOME}/conf/${line})</span>
EOF
&quot;</span> &gt; <span class="hljs-variable">${DOLPHINSCHEDULER_HOME}</span>/conf/<span class="hljs-variable">${line%.*}</span>
<span class="hljs-keyword">done</span>
</code></pre>
<h3>How to Use MySQL as the DolphinScheduler's Database Instead of PostgreSQL?</h3>
<blockquote>
<p>Because of the commercial license, we cannot directly use the driver of MySQL.</p>
<p>If you want to use MySQL, you can build a new image based on the <code>apache/dolphinscheduler</code> image as follows.</p>
</blockquote>
<ol>
<li>
<p>Download the MySQL driver <a href="https://repo1.maven.org/maven2/mysql/mysql-connector-java/8.0.16/mysql-connector-java-8.0.16.jar">mysql-connector-java-8.0.16.jar</a></p>
</li>
<li>
<p>Create a new <code>Dockerfile</code> to add MySQL driver:</p>
</li>
</ol>
<pre><code>FROM dolphinscheduler.docker.scarf.sh/apache/dolphinscheduler:2.0.3
COPY mysql-connector-java-8.0.16.jar /opt/dolphinscheduler/lib
</code></pre>
<ol start="3">
<li>Build a new docker image including MySQL driver:</li>
</ol>
<pre><code>docker build -t apache/dolphinscheduler:mysql-driver .
</code></pre>
<ol start="4">
<li>Modify all <code>image</code> fields to <code>apache/dolphinscheduler:mysql-driver</code> in <code>docker-compose.yml</code></li>
</ol>
<blockquote>
<p>If you want to deploy dolphinscheduler on Docker Swarm, you need to modify <code>docker-stack.yml</code></p>
</blockquote>
<ol start="5">
<li>
<p>Comment the <code>dolphinscheduler-postgresql</code> block in <code>docker-compose.yml</code></p>
</li>
<li>
<p>Add <code>dolphinscheduler-mysql</code> service in <code>docker-compose.yml</code> (<strong>Optional</strong>, you can directly use an external MySQL database)</p>
</li>
<li>
<p>Modify DATABASE environment variables in <code>config.env.sh</code></p>
</li>
</ol>
<pre><code>DATABASE_TYPE=mysql
DATABASE_DRIVER=com.mysql.jdbc.Driver
DATABASE_HOST=dolphinscheduler-mysql
DATABASE_PORT=3306
DATABASE_USERNAME=root
DATABASE_PASSWORD=root
DATABASE_DATABASE=dolphinscheduler
DATABASE_PARAMS=useUnicode=true&amp;characterEncoding=UTF-8
</code></pre>
<blockquote>
<p>If you have added <code>dolphinscheduler-mysql</code> service in <code>docker-compose.yml</code>, just set <code>DATABASE_HOST</code> to <code>dolphinscheduler-mysql</code></p>
</blockquote>
<ol start="8">
<li>Run a dolphinscheduler (See <strong>How to use this docker image</strong>)</li>
</ol>
<h3>How to Support MySQL Datasource in <code>Datasource manage</code>?</h3>
<blockquote>
<p>Because of the commercial license, we cannot directly use the driver of MySQL.</p>
<p>If you want to add MySQL datasource, you can build a new image based on the <code>apache/dolphinscheduler</code> image as follows.</p>
</blockquote>
<ol>
<li>
<p>Download the MySQL driver <a href="https://repo1.maven.org/maven2/mysql/mysql-connector-java/8.0.16/mysql-connector-java-8.0.16.jar">mysql-connector-java-8.0.16.jar</a></p>
</li>
<li>
<p>Create a new <code>Dockerfile</code> to add MySQL driver:</p>
</li>
</ol>
<pre><code>FROM dolphinscheduler.docker.scarf.sh/apache/dolphinscheduler:2.0.3
COPY mysql-connector-java-8.0.16.jar /opt/dolphinscheduler/lib
</code></pre>
<ol start="3">
<li>Build a new docker image including MySQL driver:</li>
</ol>
<pre><code>docker build -t apache/dolphinscheduler:mysql-driver .
</code></pre>
<ol start="4">
<li>Modify all <code>image</code> fields to <code>apache/dolphinscheduler:mysql-driver</code> in <code>docker-compose.yml</code></li>
</ol>
<blockquote>
<p>If you want to deploy dolphinscheduler on Docker Swarm, you need to modify <code>docker-stack.yml</code></p>
</blockquote>
<ol start="5">
<li>
<p>Run a dolphinscheduler (See <strong>How to use this docker image</strong>)</p>
</li>
<li>
<p>Add a MySQL datasource in <code>Datasource manage</code></p>
</li>
</ol>
<h3>How to Support Oracle Datasource in <code>Datasource manage</code>?</h3>
<blockquote>
<p>Because of the commercial license, we cannot directly use the driver of Oracle.</p>
<p>If you want to add Oracle datasource, you can build a new image based on the <code>apache/dolphinscheduler</code> image as follows.</p>
</blockquote>
<ol>
<li>
<p>Download the Oracle driver <a href="https://repo1.maven.org/maven2/com/oracle/database/jdbc/ojdbc8/">ojdbc8.jar</a> (such as <code>ojdbc8-19.9.0.0.jar</code>)</p>
</li>
<li>
<p>Create a new <code>Dockerfile</code> to add Oracle driver:</p>
</li>
</ol>
<pre><code>FROM dolphinscheduler.docker.scarf.sh/apache/dolphinscheduler:2.0.3
COPY ojdbc8-19.9.0.0.jar /opt/dolphinscheduler/lib
</code></pre>
<ol start="3">
<li>Build a new docker image including Oracle driver:</li>
</ol>
<pre><code>docker build -t apache/dolphinscheduler:oracle-driver .
</code></pre>
<ol start="4">
<li>Modify all <code>image</code> fields to <code>apache/dolphinscheduler:oracle-driver</code> in <code>docker-compose.yml</code></li>
</ol>
<blockquote>
<p>If you want to deploy dolphinscheduler on Docker Swarm, you need to modify <code>docker-stack.yml</code></p>
</blockquote>
<ol start="5">
<li>
<p>Run a dolphinscheduler (See <strong>How to use this docker image</strong>)</p>
</li>
<li>
<p>Add an Oracle datasource in <code>Datasource manage</code></p>
</li>
</ol>
<h3>How to Support Python 2 pip and Custom requirements.txt?</h3>
<ol>
<li>Create a new <code>Dockerfile</code> to install pip:</li>
</ol>
<pre><code>FROM dolphinscheduler.docker.scarf.sh/apache/dolphinscheduler:2.0.3
COPY requirements.txt /tmp
RUN apt-get update &amp;&amp; \
    apt-get install -y --no-install-recommends python-pip &amp;&amp; \
    pip install --no-cache-dir -r /tmp/requirements.txt &amp;&amp; \
    rm -rf /var/lib/apt/lists/*
</code></pre>
<p>The command will install the default <strong>pip 18.1</strong>. If you upgrade the pip, just add one line</p>
<pre><code>    pip install --no-cache-dir -U pip &amp;&amp; \
</code></pre>
<ol start="2">
<li>Build a new docker image including pip:</li>
</ol>
<pre><code>docker build -t apache/dolphinscheduler:pip .
</code></pre>
<ol start="3">
<li>Modify all <code>image</code> fields to <code>apache/dolphinscheduler:pip</code> in <code>docker-compose.yml</code></li>
</ol>
<blockquote>
<p>If you want to deploy dolphinscheduler on Docker Swarm, you need to modify <code>docker-stack.yml</code></p>
</blockquote>
<ol start="4">
<li>
<p>Run a dolphinscheduler (See <strong>How to use this docker image</strong>)</p>
</li>
<li>
<p>Verify pip under a new Python task</p>
</li>
</ol>
<h3>How to Support Python 3?</h3>
<ol>
<li>Create a new <code>Dockerfile</code> to install Python 3:</li>
</ol>
<pre><code>FROM dolphinscheduler.docker.scarf.sh/apache/dolphinscheduler:2.0.3
RUN apt-get update &amp;&amp; \
    apt-get install -y --no-install-recommends python3 &amp;&amp; \
    rm -rf /var/lib/apt/lists/*
</code></pre>
<p>The command will install the default <strong>Python 3.7.3</strong>. If you also want to install <strong>pip3</strong>, just replace <code>python3</code> with <code>python3-pip</code> like</p>
<pre><code>    apt-get install -y --no-install-recommends python3-pip &amp;&amp; \
</code></pre>
<ol start="2">
<li>Build a new docker image including Python 3:</li>
</ol>
<pre><code>docker build -t apache/dolphinscheduler:python3 .
</code></pre>
<ol start="3">
<li>Modify all <code>image</code> fields to <code>apache/dolphinscheduler:python3</code> in <code>docker-compose.yml</code></li>
</ol>
<blockquote>
<p>If you want to deploy dolphinscheduler on Docker Swarm, you need to modify <code>docker-stack.yml</code></p>
</blockquote>
<ol start="4">
<li>
<p>Modify <code>PYTHON_HOME</code> to <code>/usr/bin/python3</code> in <code>config.env.sh</code></p>
</li>
<li>
<p>Run a dolphinscheduler (See <strong>How to use this docker image</strong>)</p>
</li>
<li>
<p>Verify Python 3 under a new Python task</p>
</li>
</ol>
<h3>How to Support Hadoop, Spark, Flink, Hive or DataX?</h3>
<p>Take Spark 2.4.7 as an example:</p>
<ol>
<li>
<p>Download the Spark 2.4.7 release binary <code>spark-2.4.7-bin-hadoop2.7.tgz</code></p>
</li>
<li>
<p>Run a dolphinscheduler (See <strong>How to use this docker image</strong>)</p>
</li>
<li>
<p>Copy the Spark 2.4.7 release binary into Docker container</p>
</li>
</ol>
<pre><code class="language-bash">docker cp spark-2.4.7-bin-hadoop2.7.tgz docker-swarm_dolphinscheduler-worker_1:/opt/soft
</code></pre>
<p>Because the volume <code>dolphinscheduler-shared-local</code> is mounted on <code>/opt/soft</code>, all files in <code>/opt/soft</code> will not be lost</p>
<ol start="4">
<li>Attach the container and ensure that <code>SPARK_HOME2</code> exists</li>
</ol>
<pre><code class="language-bash">docker <span class="hljs-built_in">exec</span> -it docker-swarm_dolphinscheduler-worker_1 bash
<span class="hljs-built_in">cd</span> /opt/soft
tar zxf spark-2.4.7-bin-hadoop2.7.tgz
rm -f spark-2.4.7-bin-hadoop2.7.tgz
ln -s spark-2.4.7-bin-hadoop2.7 spark2 <span class="hljs-comment"># or just mv</span>
<span class="hljs-variable">$SPARK_HOME2</span>/bin/spark-submit --version
</code></pre>
<p>The last command will print the Spark version if everything goes well</p>
<ol start="5">
<li>Verify Spark under a Shell task</li>
</ol>
<pre><code>$SPARK_HOME2/bin/spark-submit --class org.apache.spark.examples.SparkPi $SPARK_HOME2/examples/jars/spark-examples_2.11-2.4.7.jar
</code></pre>
<p>Check whether the task log contains the output like <code>Pi is roughly 3.146015</code></p>
<ol start="6">
<li>Verify Spark under a Spark task</li>
</ol>
<p>The file <code>spark-examples_2.11-2.4.7.jar</code> needs to be uploaded to the resources first, and then create a Spark task with:</p>
<ul>
<li>Spark Version: <code>SPARK2</code></li>
<li>Main Class: <code>org.apache.spark.examples.SparkPi</code></li>
<li>Main Package: <code>spark-examples_2.11-2.4.7.jar</code></li>
<li>Deploy Mode: <code>local</code></li>
</ul>
<p>Similarly, check whether the task log contains the output like <code>Pi is roughly 3.146015</code></p>
<ol start="7">
<li>Verify Spark on YARN</li>
</ol>
<p>Spark on YARN (Deploy Mode is <code>cluster</code> or <code>client</code>) requires Hadoop support. Similar to Spark support, the operation of supporting Hadoop is almost the same as the previous steps</p>
<p>Ensure that <code>$HADOOP_HOME</code> and <code>$HADOOP_CONF_DIR</code> exists</p>
<h3>How to Support Spark 3?</h3>
<p>In fact, the way to submit applications with <code>spark-submit</code> is the same, regardless of Spark 1, 2 or 3. In other words, the semantics of <code>SPARK_HOME2</code> is the second <code>SPARK_HOME</code> instead of <code>SPARK2</code>'s <code>HOME</code>, so just set <code>SPARK_HOME2=/path/to/spark3</code></p>
<p>Take Spark 3.1.1 as an example:</p>
<ol>
<li>
<p>Download the Spark 3.1.1 release binary <code>spark-3.1.1-bin-hadoop2.7.tgz</code></p>
</li>
<li>
<p>Run a dolphinscheduler (See <strong>How to use this docker image</strong>)</p>
</li>
<li>
<p>Copy the Spark 3.1.1 release binary into Docker container</p>
</li>
</ol>
<pre><code class="language-bash">docker cp spark-3.1.1-bin-hadoop2.7.tgz docker-swarm_dolphinscheduler-worker_1:/opt/soft
</code></pre>
<ol start="4">
<li>Attach the container and ensure that <code>SPARK_HOME2</code> exists</li>
</ol>
<pre><code class="language-bash">docker <span class="hljs-built_in">exec</span> -it docker-swarm_dolphinscheduler-worker_1 bash
<span class="hljs-built_in">cd</span> /opt/soft
tar zxf spark-3.1.1-bin-hadoop2.7.tgz
rm -f spark-3.1.1-bin-hadoop2.7.tgz
ln -s spark-3.1.1-bin-hadoop2.7 spark2 <span class="hljs-comment"># or just mv</span>
<span class="hljs-variable">$SPARK_HOME2</span>/bin/spark-submit --version
</code></pre>
<p>The last command will print the Spark version if everything goes well</p>
<ol start="5">
<li>Verify Spark under a Shell task</li>
</ol>
<pre><code>$SPARK_HOME2/bin/spark-submit --class org.apache.spark.examples.SparkPi $SPARK_HOME2/examples/jars/spark-examples_2.12-3.1.1.jar
</code></pre>
<p>Check whether the task log contains the output like <code>Pi is roughly 3.146015</code></p>
<h3>How to Support Shared Storage between Master, Worker and Api server?</h3>
<blockquote>
<p><strong>Note</strong>: If it is deployed on a single machine by <code>docker-compose</code>, step 1 and 2 can be skipped directly, and execute the command like <code>docker cp hadoop-3.2.2.tar.gz docker-swarm_dolphinscheduler-worker_1:/opt/soft</code> to put Hadoop into the shared directory <code>/opt/soft</code> in the container</p>
</blockquote>
<p>For example, Master, Worker and Api server may use Hadoop at the same time</p>
<ol>
<li>Modify the volume <code>dolphinscheduler-shared-local</code> to support NFS in <code>docker-compose.yml</code></li>
</ol>
<blockquote>
<p>If you want to deploy dolphinscheduler on Docker Swarm, you need to modify <code>docker-stack.yml</code></p>
</blockquote>
<pre><code class="language-yaml"><span class="hljs-attr">volumes:</span>
  <span class="hljs-attr">dolphinscheduler-shared-local:</span>
    <span class="hljs-attr">driver_opts:</span>
      <span class="hljs-attr">type:</span> <span class="hljs-string">&quot;nfs&quot;</span>
      <span class="hljs-attr">o:</span> <span class="hljs-string">&quot;addr=10.40.0.199,nolock,soft,rw&quot;</span>
      <span class="hljs-attr">device:</span> <span class="hljs-string">&quot;:/path/to/shared/dir&quot;</span>
</code></pre>
<ol start="2">
<li>
<p>Put the Hadoop into the NFS</p>
</li>
<li>
<p>Ensure that <code>$HADOOP_HOME</code> and <code>$HADOOP_CONF_DIR</code> are correct</p>
</li>
</ol>
<h3>How to Support Local File Resource Storage Instead of HDFS and S3?</h3>
<blockquote>
<p><strong>Note</strong>: If it is deployed on a single machine by <code>docker-compose</code>, step 2 can be skipped directly</p>
</blockquote>
<ol>
<li>Modify the following environment variables in <code>config.env.sh</code>:</li>
</ol>
<pre><code>RESOURCE_STORAGE_TYPE=HDFS
FS_DEFAULT_FS=file:///
</code></pre>
<ol start="2">
<li>Modify the volume <code>dolphinscheduler-resource-local</code> to support NFS in <code>docker-compose.yml</code></li>
</ol>
<blockquote>
<p>If you want to deploy dolphinscheduler on Docker Swarm, you need to modify <code>docker-stack.yml</code></p>
</blockquote>
<pre><code class="language-yaml"><span class="hljs-attr">volumes:</span>
  <span class="hljs-attr">dolphinscheduler-resource-local:</span>
    <span class="hljs-attr">driver_opts:</span>
      <span class="hljs-attr">type:</span> <span class="hljs-string">&quot;nfs&quot;</span>
      <span class="hljs-attr">o:</span> <span class="hljs-string">&quot;addr=10.40.0.199,nolock,soft,rw&quot;</span>
      <span class="hljs-attr">device:</span> <span class="hljs-string">&quot;:/path/to/resource/dir&quot;</span>
</code></pre>
<h3>How to Support S3 Resource Storage Like MinIO?</h3>
<p>Take MinIO as an example: Modify the following environment variables in <code>config.env.sh</code></p>
<pre><code>RESOURCE_STORAGE_TYPE=S3
RESOURCE_UPLOAD_PATH=/dolphinscheduler
FS_DEFAULT_FS=s3a://BUCKET_NAME
FS_S3A_ENDPOINT=http://MINIO_IP:9000
FS_S3A_ACCESS_KEY=MINIO_ACCESS_KEY
FS_S3A_SECRET_KEY=MINIO_SECRET_KEY
</code></pre>
<p><code>BUCKET_NAME</code>, <code>MINIO_IP</code>, <code>MINIO_ACCESS_KEY</code> and <code>MINIO_SECRET_KEY</code> need to be modified to actual values</p>
<blockquote>
<p><strong>Note</strong>: <code>MINIO_IP</code> can only use IP instead of the domain name, because DolphinScheduler currently doesn't support S3 path style access</p>
</blockquote>
<h3>How to Configure SkyWalking?</h3>
<p>Modify SkyWalking environment variables in <code>config.env.sh</code>:</p>
<pre><code>SKYWALKING_ENABLE=true
SW_AGENT_COLLECTOR_BACKEND_SERVICES=127.0.0.1:11800
SW_GRPC_LOG_SERVER_HOST=127.0.0.1
SW_GRPC_LOG_SERVER_PORT=11800
</code></pre>
<h2>Appendix-Environment Variables</h2>
<h3>Database</h3>
<p><strong><code>DATABASE_TYPE</code></strong></p>
<p>This environment variable sets the type for the database. The default value is <code>postgresql</code>.</p>
<p><strong>Note</strong>: You must be specify it when start a standalone dolphinscheduler server. Like <code>master-server</code>, <code>worker-server</code>, <code>api-server</code>, <code>alert-server</code>.</p>
<p><strong><code>DATABASE_DRIVER</code></strong></p>
<p>This environment variable sets the type for the database. The default value is <code>org.postgresql.Driver</code>.</p>
<p><strong>Note</strong>: You must specify it when starting a standalone dolphinscheduler server. Like <code>master-server</code>, <code>worker-server</code>, <code>api-server</code>, <code>alert-server</code>.</p>
<p><strong><code>DATABASE_HOST</code></strong></p>
<p>This environment variable sets the host for the database. The default value is <code>127.0.0.1</code>.</p>
<p><strong>Note</strong>: You must specify it when start a standalone dolphinscheduler server. Like <code>master-server</code>, <code>worker-server</code>, <code>api-server</code>, <code>alert-server</code>.</p>
<p><strong><code>DATABASE_PORT</code></strong></p>
<p>This environment variable sets the port for the database. The default value is <code>5432</code>.</p>
<p><strong>Note</strong>: You must specify it when start a standalone dolphinscheduler server. Like <code>master-server</code>, <code>worker-server</code>, <code>api-server</code>, <code>alert-server</code>.</p>
<p><strong><code>DATABASE_USERNAME</code></strong></p>
<p>This environment variable sets the username for the database. The default value is <code>root</code>.</p>
<p><strong>Note</strong>: You must specify it when start a standalone dolphinscheduler server. Like <code>master-server</code>, <code>worker-server</code>, <code>api-server</code>, <code>alert-server</code>.</p>
<p><strong><code>DATABASE_PASSWORD</code></strong></p>
<p>This environment variable sets the password for the database. The default value is <code>root</code>.</p>
<p><strong>Note</strong>: You must specify it when start a standalone dolphinscheduler server. Like <code>master-server</code>, <code>worker-server</code>, <code>api-server</code>, <code>alert-server</code>.</p>
<p><strong><code>DATABASE_DATABASE</code></strong></p>
<p>This environment variable sets the database for the database. The default value is <code>dolphinscheduler</code>.</p>
<p><strong>Note</strong>: You must specify it when start a standalone dolphinscheduler server. Like <code>master-server</code>, <code>worker-server</code>, <code>api-server</code>, <code>alert-server</code>.</p>
<p><strong><code>DATABASE_PARAMS</code></strong></p>
<p>This environment variable sets the database for the database. The default value is <code>characterEncoding=utf8</code>.</p>
<p><strong>Note</strong>: You must specify it when starting a standalone dolphinscheduler server. Like <code>master-server</code>, <code>worker-server</code>, <code>api-server</code>, <code>alert-server</code>.</p>
<h3>ZooKeeper</h3>
<p><strong><code>ZOOKEEPER_QUORUM</code></strong></p>
<p>This environment variable sets ZooKeeper quorum. The default value is <code>127.0.0.1:2181</code>.</p>
<p><strong>Note</strong>: You must specify it when starting a standalone dolphinscheduler server. Like <code>master-server</code>, <code>worker-server</code>, <code>api-server</code>.</p>
<p><strong><code>ZOOKEEPER_ROOT</code></strong></p>
<p>This environment variable sets ZooKeeper root directory for dolphinscheduler. The default value is <code>/dolphinscheduler</code>.</p>
<h3>Common</h3>
<p><strong><code>DOLPHINSCHEDULER_OPTS</code></strong></p>
<p>This environment variable sets JVM options for dolphinscheduler, suitable for <code>master-server</code>, <code>worker-server</code>, <code>api-server</code>, <code>alert-server</code>, <code>logger-server</code>. The default value is empty.</p>
<p><strong><code>DATA_BASEDIR_PATH</code></strong></p>
<p>User data directory path, self configuration, please make sure the directory exists and have read-write permissions. The default value is <code>/tmp/dolphinscheduler</code></p>
<p><strong><code>RESOURCE_STORAGE_TYPE</code></strong></p>
<p>This environment variable sets resource storage types for dolphinscheduler like <code>HDFS</code>, <code>S3</code>, <code>NONE</code>. The default value is <code>HDFS</code>.</p>
<p><strong><code>RESOURCE_UPLOAD_PATH</code></strong></p>
<p>This environment variable sets resource store path on HDFS/S3 for resource storage. The default value is <code>/dolphinscheduler</code>.</p>
<p><strong><code>FS_DEFAULT_FS</code></strong></p>
<p>This environment variable sets fs.defaultFS for resource storage like <code>file:///</code>, <code>hdfs://mycluster:8020</code> or <code>s3a://dolphinscheduler</code>. The default value is <code>file:///</code>.</p>
<p><strong><code>FS_S3A_ENDPOINT</code></strong></p>
<p>This environment variable sets s3 endpoint for resource storage. The default value is <code>s3.xxx.amazonaws.com</code>.</p>
<p><strong><code>FS_S3A_ACCESS_KEY</code></strong></p>
<p>This environment variable sets s3 access key for resource storage. The default value is <code>xxxxxxx</code>.</p>
<p><strong><code>FS_S3A_SECRET_KEY</code></strong></p>
<p>This environment variable sets s3 secret key for resource storage. The default value is <code>xxxxxxx</code>.</p>
<p><strong><code>HADOOP_SECURITY_AUTHENTICATION_STARTUP_STATE</code></strong></p>
<p>This environment variable sets whether to startup Kerberos. The default value is <code>false</code>.</p>
<p><strong><code>JAVA_SECURITY_KRB5_CONF_PATH</code></strong></p>
<p>This environment variable sets java.security.krb5.conf path. The default value is <code>/opt/krb5.conf</code>.</p>
<p><strong><code>LOGIN_USER_KEYTAB_USERNAME</code></strong></p>
<p>This environment variable sets login user from the keytab username. The default value is <code>hdfs@HADOOP.COM</code>.</p>
<p><strong><code>LOGIN_USER_KEYTAB_PATH</code></strong></p>
<p>This environment variable sets login user from the keytab path. The default value is <code>/opt/hdfs.keytab</code>.</p>
<p><strong><code>KERBEROS_EXPIRE_TIME</code></strong></p>
<p>This environment variable sets Kerberos expire time, the unit is hour. The default value is <code>2</code>.</p>
<p><strong><code>HDFS_ROOT_USER</code></strong></p>
<p>This environment variable sets HDFS root user when resource.storage.type=HDFS. The default value is <code>hdfs</code>.</p>
<p><strong><code>RESOURCE_MANAGER_HTTPADDRESS_PORT</code></strong></p>
<p>This environment variable sets resource manager HTTP address port. The default value is <code>8088</code>.</p>
<p><strong><code>YARN_RESOURCEMANAGER_HA_RM_IDS</code></strong></p>
<p>This environment variable sets yarn resourcemanager ha rm ids. The default value is empty.</p>
<p><strong><code>YARN_APPLICATION_STATUS_ADDRESS</code></strong></p>
<p>This environment variable sets yarn application status address. The default value is <code>http://ds1:%s/ws/v1/cluster/apps/%s</code>.</p>
<p><strong><code>SKYWALKING_ENABLE</code></strong></p>
<p>This environment variable sets whether to enable SkyWalking. The default value is <code>false</code>.</p>
<p><strong><code>SW_AGENT_COLLECTOR_BACKEND_SERVICES</code></strong></p>
<p>This environment variable sets agent collector backend services for SkyWalking. The default value is <code>127.0.0.1:11800</code>.</p>
<p><strong><code>SW_GRPC_LOG_SERVER_HOST</code></strong></p>
<p>This environment variable sets gRPC log server host for SkyWalking. The default value is <code>127.0.0.1</code>.</p>
<p><strong><code>SW_GRPC_LOG_SERVER_PORT</code></strong></p>
<p>This environment variable sets gRPC log server port for SkyWalking. The default value is <code>11800</code>.</p>
<p><strong><code>HADOOP_HOME</code></strong></p>
<p>This environment variable sets <code>HADOOP_HOME</code>. The default value is <code>/opt/soft/hadoop</code>.</p>
<p><strong><code>HADOOP_CONF_DIR</code></strong></p>
<p>This environment variable sets <code>HADOOP_CONF_DIR</code>. The default value is <code>/opt/soft/hadoop/etc/hadoop</code>.</p>
<p><strong><code>SPARK_HOME1</code></strong></p>
<p>This environment variable sets <code>SPARK_HOME1</code>. The default value is <code>/opt/soft/spark1</code>.</p>
<p><strong><code>SPARK_HOME2</code></strong></p>
<p>This environment variable sets <code>SPARK_HOME2</code>. The default value is <code>/opt/soft/spark2</code>.</p>
<p><strong><code>PYTHON_HOME</code></strong></p>
<p>This environment variable sets <code>PYTHON_HOME</code>. The default value is <code>/usr/bin/python</code>.</p>
<p><strong><code>JAVA_HOME</code></strong></p>
<p>This environment variable sets <code>JAVA_HOME</code>. The default value is <code>/usr/local/openjdk-8</code>.</p>
<p><strong><code>HIVE_HOME</code></strong></p>
<p>This environment variable sets <code>HIVE_HOME</code>. The default value is <code>/opt/soft/hive</code>.</p>
<p><strong><code>FLINK_HOME</code></strong></p>
<p>This environment variable sets <code>FLINK_HOME</code>. The default value is <code>/opt/soft/flink</code>.</p>
<p><strong><code>DATAX_HOME</code></strong></p>
<p>This environment variable sets <code>DATAX_HOME</code>. The default value is <code>/opt/soft/datax</code>.</p>
<h3>Master Server</h3>
<p><strong><code>MASTER_SERVER_OPTS</code></strong></p>
<p>This environment variable sets JVM options for <code>master-server</code>. The default value is <code>-Xms1g -Xmx1g -Xmn512m</code>.</p>
<p><strong><code>MASTER_EXEC_THREADS</code></strong></p>
<p>This environment variable sets exec thread number for <code>master-server</code>. The default value is <code>100</code>.</p>
<p><strong><code>MASTER_EXEC_TASK_NUM</code></strong></p>
<p>This environment variable sets exec task number for <code>master-server</code>. The default value is <code>20</code>.</p>
<p><strong><code>MASTER_DISPATCH_TASK_NUM</code></strong></p>
<p>This environment variable sets dispatch task number for <code>master-server</code>. The default value is <code>3</code>.</p>
<p><strong><code>MASTER_HOST_SELECTOR</code></strong></p>
<p>This environment variable sets host selector for <code>master-server</code>. Optional values include <code>Random</code>, <code>RoundRobin</code> and <code>LowerWeight</code>. The default value is <code>LowerWeight</code>.</p>
<p><strong><code>MASTER_HEARTBEAT_INTERVAL</code></strong></p>
<p>This environment variable sets heartbeat interval for <code>master-server</code>. The default value is <code>10</code>.</p>
<p><strong><code>MASTER_TASK_COMMIT_RETRYTIMES</code></strong></p>
<p>This environment variable sets task commit retry times for <code>master-server</code>. The default value is <code>5</code>.</p>
<p><strong><code>MASTER_TASK_COMMIT_INTERVAL</code></strong></p>
<p>This environment variable sets task commit interval for <code>master-server</code>. The default value is <code>1</code>.</p>
<p><strong><code>MASTER_MAX_CPULOAD_AVG</code></strong></p>
<p>This environment variable sets max CPU load avg for <code>master-server</code>. The default value is <code>-1</code>.</p>
<p><strong><code>MASTER_RESERVED_MEMORY</code></strong></p>
<p>This environment variable sets reserved memory for <code>master-server</code>, the unit is G. The default value is <code>0.3</code>.</p>
<h3>Worker Server</h3>
<p><strong><code>WORKER_SERVER_OPTS</code></strong></p>
<p>This environment variable sets JVM options for <code>worker-server</code>. The default value is <code>-Xms1g -Xmx1g -Xmn512m</code>.</p>
<p><strong><code>WORKER_EXEC_THREADS</code></strong></p>
<p>This environment variable sets exec thread number for <code>worker-server</code>. The default value is <code>100</code>.</p>
<p><strong><code>WORKER_HEARTBEAT_INTERVAL</code></strong></p>
<p>This environment variable sets heartbeat interval for <code>worker-server</code>. The default value is <code>10</code>.</p>
<p><strong><code>WORKER_MAX_CPULOAD_AVG</code></strong></p>
<p>This environment variable sets max CPU load avg for <code>worker-server</code>. The default value is <code>-1</code>.</p>
<p><strong><code>WORKER_RESERVED_MEMORY</code></strong></p>
<p>This environment variable sets reserved memory for <code>worker-server</code>, the unit is G. The default value is <code>0.3</code>.</p>
<p><strong><code>WORKER_GROUPS</code></strong></p>
<p>This environment variable sets groups for <code>worker-server</code>. The default value is <code>default</code>.</p>
<h3>Alert Server</h3>
<p><strong><code>ALERT_SERVER_OPTS</code></strong></p>
<p>This environment variable sets JVM options for <code>alert-server</code>. The default value is <code>-Xms512m -Xmx512m -Xmn256m</code>.</p>
<p><strong><code>XLS_FILE_PATH</code></strong></p>
<p>This environment variable sets xls file path for <code>alert-server</code>. The default value is <code>/tmp/xls</code>.</p>
<p><strong><code>MAIL_SERVER_HOST</code></strong></p>
<p>This environment variable sets mail server host for <code>alert-server</code>. The default value is empty.</p>
<p><strong><code>MAIL_SERVER_PORT</code></strong></p>
<p>This environment variable sets mail server port for <code>alert-server</code>. The default value is empty.</p>
<p><strong><code>MAIL_SENDER</code></strong></p>
<p>This environment variable sets mail sender for <code>alert-server</code>. The default value is empty.</p>
<p><strong><code>MAIL_USER=</code></strong></p>
<p>This environment variable sets mail user for <code>alert-server</code>. The default value is empty.</p>
<p><strong><code>MAIL_PASSWD</code></strong></p>
<p>This environment variable sets mail password for <code>alert-server</code>. The default value is empty.</p>
<p><strong><code>MAIL_SMTP_STARTTLS_ENABLE</code></strong></p>
<p>This environment variable sets SMTP tls for <code>alert-server</code>. The default value is <code>true</code>.</p>
<p><strong><code>MAIL_SMTP_SSL_ENABLE</code></strong></p>
<p>This environment variable sets SMTP ssl for <code>alert-server</code>. The default value is <code>false</code>.</p>
<p><strong><code>MAIL_SMTP_SSL_TRUST</code></strong></p>
<p>This environment variable sets SMTP ssl truest for <code>alert-server</code>. The default value is empty.</p>
<p><strong><code>ENTERPRISE_WECHAT_ENABLE</code></strong></p>
<p>This environment variable sets enterprise wechat enable for <code>alert-server</code>. The default value is <code>false</code>.</p>
<p><strong><code>ENTERPRISE_WECHAT_CORP_ID</code></strong></p>
<p>This environment variable sets enterprise wechat corp id for <code>alert-server</code>. The default value is empty.</p>
<p><strong><code>ENTERPRISE_WECHAT_SECRET</code></strong></p>
<p>This environment variable sets enterprise wechat secret for <code>alert-server</code>. The default value is empty.</p>
<p><strong><code>ENTERPRISE_WECHAT_AGENT_ID</code></strong></p>
<p>This environment variable sets enterprise wechat agent id for <code>alert-server</code>. The default value is empty.</p>
<p><strong><code>ENTERPRISE_WECHAT_USERS</code></strong></p>
<p>This environment variable sets enterprise wechat users for <code>alert-server</code>. The default value is empty.</p>
<h3>Api Server</h3>
<p><strong><code>API_SERVER_OPTS</code></strong></p>
<p>This environment variable sets JVM options for <code>api-server</code>. The default value is <code>-Xms512m -Xmx512m -Xmn256m</code>.</p>
<h3>Logger Server</h3>
<p><strong><code>LOGGER_SERVER_OPTS</code></strong></p>
<p>This environment variable sets JVM options for <code>logger-server</code>. The default value is <code>-Xms512m -Xmx512m -Xmn256m</code>.</p>
</div></section><footer class="footer-container"><div class="footer-body"><div><h3>About us</h3><h4>Do you need feedback? Please contact us through the following ways.</h4></div><div class="contact-container"><ul><li><a href="/en-us/community/development/subscribe.html"><img class="img-base" src="/img/emailgray.png"/><img class="img-change" src="/img/emailblue.png"/><p>Email List</p></a></li><li><a href="https://twitter.com/dolphinschedule"><img class="img-base" src="/img/twittergray.png"/><img class="img-change" src="/img/twitterblue.png"/><p>Twitter</p></a></li><li><a href="https://stackoverflow.com/questions/tagged/apache-dolphinscheduler"><img class="img-base" src="/img/stackoverflow.png"/><img class="img-change" src="/img/stackoverflow-selected.png"/><p>Stack Overflow</p></a></li><li><a href="https://join.slack.com/t/asf-dolphinscheduler/shared_invite/zt-omtdhuio-_JISsxYhiVsltmC5h38yfw"><img class="img-base" src="/img/slack.png"/><img class="img-change" src="/img/slack-selected.png"/><p>Slack</p></a></li></ul></div><div class="cols-container"><div class="docu-container"><h4>Documentation</h4><ul><li><a href="/en-us/development/architecture-design.html"><p>Overview</p></a></li><li><a href="/en-us/docs/latest/user_doc/guide/quick-start.html"><p>Quick start</p></a></li><li><a href="/en-us/development/development-environment-setup.html"><p>Developer guide</p></a></li></ul></div><div></div><div class="asf-container"><h4>ASF</h4><ul><li><a href="http://www.apache.org"><p>Foundation</p></a></li><li><a href="http://www.apache.org/licenses/"><p>License</p></a></li><li><a href="http://www.apache.org/events/current-event"><p>Events</p></a></li><li><a href="http://www.apache.org/foundation/sponsorship.html"><p>Sponsorship</p></a></li><li><a href="http://www.apache.org/foundation/thanks.html"><p>Thanks</p></a></li></ul></div></div><div class="copyright"><span>Copyright © 2019-2021 The Apache Software Foundation. Apache DolphinScheduler, DolphinScheduler, and its feather logo are trademarks of The Apache Software Foundation.</span></div></div></footer></div></div>
  <script src="//cdn.jsdelivr.net/npm/react@15.6.2/dist/react-with-addons.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/react-dom@15.6.2/dist/react-dom.min.js"></script>
  <script>window.rootPath = '';</script>
  <script src="/build/vendor.90dcf97.js"></script>
  <script src="/build/docs.md.8182f21.js"></script>
  <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?4e7b4b400dd31fa015018a435c64d06f";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-899J8PYKJZ"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-899J8PYKJZ');
  </script>
</body>
</html>