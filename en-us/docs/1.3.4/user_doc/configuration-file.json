{
  "filename": "configuration-file.md",
  "__html": "<!-- markdown-link-check-disable -->\n<h1>Preface</h1>\n<p>This document explains the DolphinScheduler application configurations according to DolphinScheduler-1.3.x versions.</p>\n<h1>Directory Structure</h1>\n<p>Currently, all the configuration files are under [conf ] directory. Please check the following simplified DolphinScheduler installation directories to have a direct view about the position [conf] directory in and configuration files inside. This document only describes DolphinScheduler configurations and other modules are not going into.</p>\n<p>[Note: the DolphinScheduler (hereinafter called the ‘DS’) .]</p>\n<pre><code>\n├─bin                               DS application commands directory\n│  ├─dolphinscheduler-daemon.sh         startup/shutdown DS application \n│  ├─start-all.sh                       startup all DS services with configurations\n│  ├─stop-all.sh                        shutdown all DS services with configurations\n├─conf                              configurations directory\n│  ├─application-api.properties         API-service config properties\n│  ├─datasource.properties              datasource config properties\n│  ├─zookeeper.properties               zookeeper config properties\n│  ├─master.properties                  master config properties\n│  ├─worker.properties                  worker config properties\n│  ├─quartz.properties                  quartz config properties\n│  ├─common.properties                  common-service[storage] config properties\n│  ├─alert.properties                   alert-service config properties\n│  ├─config                             environment variables config directory\n│      ├─install_config.conf                DS environment variables configuration script[install/start DS]\n│  ├─env                                load environment variables configs script directory\n│      ├─dolphinscheduler_env.sh            load environment variables configs [eg: JAVA_HOME,HADOOP_HOME, HIVE_HOME ...]\n│  ├─org                                mybatis mapper files directory\n│  ├─i18n                               i18n configs directory\n│  ├─logback-api.xml                    API-service log config\n│  ├─logback-master.xml                 master-service log config\n│  ├─logback-worker.xml                 worker-service log config\n│  ├─logback-alert.xml                  alert-service log config\n├─sql                                   DS metadata to create/upgrade .sql directory\n│  ├─create                             create SQL scripts directory\n│  ├─upgrade                            upgrade SQL scripts directory\n│  ├─dolphinscheduler-postgre.sql       postgre database init script\n│  ├─dolphinscheduler_mysql.sql         mysql database init script\n│  ├─soft_version                       current DS version-id file\n├─script                            DS services deployment, database create/upgrade scripts directory\n│  ├─create-dolphinscheduler.sh         DS database init script\n│  ├─upgrade-dolphinscheduler.sh        DS database upgrade script\n│  ├─monitor-server.sh                  DS monitor-server start script       \n│  ├─scp-hosts.sh                       transfer installation files script                                     \n│  ├─remove-zk-node.sh                  cleanup zookeeper caches script       \n├─ui                                front-end web resources directory\n├─lib                               DS .jar dependencies directory\n├─install.sh                        auto-setup DS services script\n\n\n</code></pre>\n<h1>Configurations in Details</h1>\n<table>\n<thead>\n<tr>\n<th>serial number</th>\n<th>service classification</th>\n<th>config file</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>startup/shutdown DS application</td>\n<td><a href=\"http://dolphinscheduler-daemon.sh\">dolphinscheduler-daemon.sh</a></td>\n</tr>\n<tr>\n<td>2</td>\n<td>datasource config properties</td>\n<td>datasource.properties</td>\n</tr>\n<tr>\n<td>3</td>\n<td>zookeeper config properties</td>\n<td>zookeeper.properties</td>\n</tr>\n<tr>\n<td>4</td>\n<td>common-service[storage] config properties</td>\n<td>common.properties</td>\n</tr>\n<tr>\n<td>5</td>\n<td>API-service config properties</td>\n<td>application-api.properties</td>\n</tr>\n<tr>\n<td>6</td>\n<td>master config properties</td>\n<td>master.properties</td>\n</tr>\n<tr>\n<td>7</td>\n<td>worker config properties</td>\n<td>worker.properties</td>\n</tr>\n<tr>\n<td>8</td>\n<td>alert-service config properties</td>\n<td>alert.properties</td>\n</tr>\n<tr>\n<td>9</td>\n<td>quartz config properties</td>\n<td>quartz.properties</td>\n</tr>\n<tr>\n<td>10</td>\n<td>DS environment variables configuration script[install/start DS]</td>\n<td>install_config.conf</td>\n</tr>\n<tr>\n<td>11</td>\n<td>load environment variables configs <br /> [eg: JAVA_HOME,HADOOP_HOME, HIVE_HOME ...]</td>\n<td>dolphinscheduler_env.sh</td>\n</tr>\n<tr>\n<td>12</td>\n<td>services log config files</td>\n<td>API-service log config : logback-api.xml  <br /> master-service log config  : logback-master.xml    <br /> worker-service log config : logback-worker.xml  <br /> alert-service log config : logback-alert.xml</td>\n</tr>\n</tbody>\n</table>\n<h2><a href=\"http://1.dolphinscheduler-daemon.sh\">1.dolphinscheduler-daemon.sh</a> [startup/shutdown DS application]</h2>\n<p><a href=\"http://dolphinscheduler-daemon.sh\">dolphinscheduler-daemon.sh</a> is responsible for DS startup &amp; shutdown.\nEssentially, <a href=\"http://start-all.sh/stop-all.sh\">start-all.sh/stop-all.sh</a> startup/shutdown the cluster via <a href=\"http://dolphinscheduler-daemon.sh\">dolphinscheduler-daemon.sh</a>.\nCurrently, DS just makes a basic config, please config further JVＭ options based on your practical situation of resources.</p>\n<p>Default simplified parameters are:</p>\n<pre><code class=\"language-bash\"><span class=\"hljs-built_in\">export</span> DOLPHINSCHEDULER_OPTS=<span class=\"hljs-string\">&quot;\n-server \n-Xmx16g \n-Xms1g \n-Xss512k \n-XX:+UseConcMarkSweepGC \n-XX:+CMSParallelRemarkEnabled \n-XX:+UseFastAccessorMethods \n-XX:+UseCMSInitiatingOccupancyOnly \n-XX:CMSInitiatingOccupancyFraction=70\n&quot;</span>\n</code></pre>\n<blockquote>\n<p>&quot;-XX:DisableExplicitGC&quot; is not recommended due to may lead to memory link (DS dependent on Netty to communicate).</p>\n</blockquote>\n<h2>2.datasource.properties [datasource config properties]</h2>\n<p>DS uses Druid to manage database connections and default simplified configs are:</p>\n<table>\n<thead>\n<tr>\n<th>Parameters</th>\n<th>Default value</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>spring.datasource.driver-class-name</td>\n<td></td>\n<td>datasource driver</td>\n</tr>\n<tr>\n<td>spring.datasource.url</td>\n<td></td>\n<td>datasource connection url</td>\n</tr>\n<tr>\n<td>spring.datasource.username</td>\n<td></td>\n<td>datasource username</td>\n</tr>\n<tr>\n<td>spring.datasource.password</td>\n<td></td>\n<td>datasource password</td>\n</tr>\n<tr>\n<td>spring.datasource.initialSize</td>\n<td>5</td>\n<td>initail connection pool size number</td>\n</tr>\n<tr>\n<td>spring.datasource.minIdle</td>\n<td>5</td>\n<td>minimum connection pool size number</td>\n</tr>\n<tr>\n<td>spring.datasource.maxActive</td>\n<td>5</td>\n<td>maximum connection pool size number</td>\n</tr>\n<tr>\n<td>spring.datasource.maxWait</td>\n<td>60000</td>\n<td>max wait mili-seconds</td>\n</tr>\n<tr>\n<td>spring.datasource.timeBetweenEvictionRunsMillis</td>\n<td>60000</td>\n<td>idle connection check interval</td>\n</tr>\n<tr>\n<td>spring.datasource.timeBetweenConnectErrorMillis</td>\n<td>60000</td>\n<td>retry interval</td>\n</tr>\n<tr>\n<td>spring.datasource.minEvictableIdleTimeMillis</td>\n<td>300000</td>\n<td>connections over minEvictableIdleTimeMillis will be collect when idle check</td>\n</tr>\n<tr>\n<td>spring.datasource.validationQuery</td>\n<td>SELECT 1</td>\n<td>validate connection by running the SQL</td>\n</tr>\n<tr>\n<td>spring.datasource.validationQueryTimeout</td>\n<td>3</td>\n<td>validate connection timeout[seconds]</td>\n</tr>\n<tr>\n<td>spring.datasource.testWhileIdle</td>\n<td>true</td>\n<td>set whether the pool validates the allocated connection when a new connection request comes</td>\n</tr>\n<tr>\n<td>spring.datasource.testOnBorrow</td>\n<td>true</td>\n<td>validity check when the program requests a new connection</td>\n</tr>\n<tr>\n<td>spring.datasource.testOnReturn</td>\n<td>false</td>\n<td>validity check when the program recalls a connection</td>\n</tr>\n<tr>\n<td>spring.datasource.defaultAutoCommit</td>\n<td>true</td>\n<td>whether auto commit</td>\n</tr>\n<tr>\n<td>spring.datasource.keepAlive</td>\n<td>true</td>\n<td>runs validationQuery SQL to avoid the connection closed by pool when the connection idles over minEvictableIdleTimeMillis</td>\n</tr>\n<tr>\n<td>spring.datasource.poolPreparedStatements</td>\n<td>true</td>\n<td>Open PSCache</td>\n</tr>\n<tr>\n<td>spring.datasource.maxPoolPreparedStatementPerConnectionSize</td>\n<td>20</td>\n<td>specify the size of PSCache on each connection</td>\n</tr>\n</tbody>\n</table>\n<h2>3.zookeeper.properties [zookeeper config properties]</h2>\n<table>\n<thead>\n<tr>\n<th>Parameters</th>\n<th>Default value</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>zookeeper.quorum</td>\n<td>localhost:2181</td>\n<td>zookeeper cluster connection info</td>\n</tr>\n<tr>\n<td>zookeeper.dolphinscheduler.root</td>\n<td>/dolphinscheduler</td>\n<td>DS is stored under zookeeper root directory</td>\n</tr>\n<tr>\n<td>zookeeper.session.timeout</td>\n<td>60000</td>\n<td>session timeout</td>\n</tr>\n<tr>\n<td>zookeeper.connection.timeout</td>\n<td>30000</td>\n<td>connection timeout</td>\n</tr>\n<tr>\n<td>zookeeper.retry.base.sleep</td>\n<td>100</td>\n<td>time to wait between subsequent retries</td>\n</tr>\n<tr>\n<td>zookeeper.retry.max.sleep</td>\n<td>30000</td>\n<td>maximum time to wait between subsequent retries</td>\n</tr>\n<tr>\n<td>zookeeper.retry.maxtime</td>\n<td>10</td>\n<td>maximum retry times</td>\n</tr>\n</tbody>\n</table>\n<h2>4.common.properties [hadoop、s3、yarn config properties]</h2>\n<p>Currently, common.properties mainly configures hadoop/s3a related configurations.</p>\n<table>\n<thead>\n<tr>\n<th>Parameters</th>\n<th>Default value</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>resource.storage.type</td>\n<td>NONE</td>\n<td>type of resource files: HDFS, S3, NONE</td>\n</tr>\n<tr>\n<td>resource.upload.path</td>\n<td>/dolphinscheduler</td>\n<td>storage path of resource files</td>\n</tr>\n<tr>\n<td>data.basedir.path</td>\n<td>/tmp/dolphinscheduler</td>\n<td>local directory used to store temp files</td>\n</tr>\n<tr>\n<td>hadoop.security.authentication.startup.state</td>\n<td>false</td>\n<td>whether hadoop grant kerberos permission</td>\n</tr>\n<tr>\n<td>java.security.krb5.conf.path</td>\n<td>/opt/krb5.conf</td>\n<td>kerberos config directory</td>\n</tr>\n<tr>\n<td>login.user.keytab.username</td>\n<td><a href=\"mailto:hdfs-mycluster@ESZ.COM\">hdfs-mycluster@ESZ.COM</a></td>\n<td>kerberos username</td>\n</tr>\n<tr>\n<td>login.user.keytab.path</td>\n<td>/opt/hdfs.headless.keytab</td>\n<td>kerberos user keytab</td>\n</tr>\n<tr>\n<td>resource.view.suffixs</td>\n<td>txt,log,sh,conf,cfg,py,java,sql,hql,xml,properties</td>\n<td>file types supported by resource center</td>\n</tr>\n<tr>\n<td>hdfs.root.user</td>\n<td>hdfs</td>\n<td>configure users with corresponding permissions if storage type is HDFS</td>\n</tr>\n<tr>\n<td>fs.defaultFS</td>\n<td>hdfs://mycluster:8020</td>\n<td>If resource.storage.type=S3, then the request url would be similar to 's3a://dolphinscheduler'. Otherwise if resource.storage.type=HDFS and hadoop supports HA, please copy core-site.xml and hdfs-site.xml into 'conf' directory</td>\n</tr>\n<tr>\n<td>fs.s3a.endpoint</td>\n<td></td>\n<td>s3 endpoint url</td>\n</tr>\n<tr>\n<td>fs.s3a.access.key</td>\n<td></td>\n<td>s3 access key</td>\n</tr>\n<tr>\n<td>fs.s3a.secret.key</td>\n<td></td>\n<td>s3 secret key</td>\n</tr>\n<tr>\n<td>yarn.resourcemanager.ha.rm.ids</td>\n<td></td>\n<td>specify the yarn resourcemanager url. if resourcemanager supports HA, input HA IP addresses (separated by comma), or input null for standalone</td>\n</tr>\n<tr>\n<td>yarn.application.status.address</td>\n<td><a href=\"http://ds1:8088/ws/v1/cluster/apps/%25s\">http://ds1:8088/ws/v1/cluster/apps/%s</a></td>\n<td>keep default if resourcemanager supports HA or not use resourcemanager. Or replace ds1 with corresponding hostname if resourcemanager in standalone mode</td>\n</tr>\n<tr>\n<td>dolphinscheduler.env.path</td>\n<td>env/dolphinscheduler_env.sh</td>\n<td>load environment variables configs [eg: JAVA_HOME,HADOOP_HOME, HIVE_HOME ...]</td>\n</tr>\n<tr>\n<td>development.state</td>\n<td>false</td>\n<td>specify whether in development state</td>\n</tr>\n<tr>\n<td>kerberos.expire.time</td>\n<td>7</td>\n<td>kerberos expire time,integer,the unit is day</td>\n</tr>\n</tbody>\n</table>\n<h2>5.application-api.properties [API-service log config]</h2>\n<table>\n<thead>\n<tr>\n<th>Parameters</th>\n<th>Default value</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>server.port</td>\n<td>12345</td>\n<td>api service communication port</td>\n</tr>\n<tr>\n<td>server.servlet.session.timeout</td>\n<td>7200</td>\n<td>session timeout</td>\n</tr>\n<tr>\n<td>server.servlet.context-path</td>\n<td>/dolphinscheduler</td>\n<td>request path</td>\n</tr>\n<tr>\n<td>spring.servlet.multipart.max-file-size</td>\n<td>1024MB</td>\n<td>maximum file size</td>\n</tr>\n<tr>\n<td>spring.servlet.multipart.max-request-size</td>\n<td>1024MB</td>\n<td>maximum request size</td>\n</tr>\n<tr>\n<td>server.jetty.max-http-post-size</td>\n<td>5000000</td>\n<td>jetty maximum post size</td>\n</tr>\n<tr>\n<td>spring.messages.encoding</td>\n<td>UTF-8</td>\n<td>message encoding</td>\n</tr>\n<tr>\n<td>spring.jackson.time-zone</td>\n<td>GMT+8</td>\n<td>time zone</td>\n</tr>\n<tr>\n<td>spring.messages.basename</td>\n<td>i18n/messages</td>\n<td>i18n config</td>\n</tr>\n<tr>\n<td>security.authentication.type</td>\n<td>PASSWORD</td>\n<td>authentication type</td>\n</tr>\n</tbody>\n</table>\n<h2>6.master.properties [master-service log config]</h2>\n<table>\n<thead>\n<tr>\n<th>Parameters</th>\n<th>Default value</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>master.listen.port</td>\n<td>5678</td>\n<td>master listen port</td>\n</tr>\n<tr>\n<td>master.exec.threads</td>\n<td>100</td>\n<td>master execute thread number to limit process instances in parallel</td>\n</tr>\n<tr>\n<td>master.exec.task.num</td>\n<td>20</td>\n<td>master execute task number in parallel per process instance</td>\n</tr>\n<tr>\n<td>master.dispatch.task.num</td>\n<td>3</td>\n<td>master dispatch task number per batch</td>\n</tr>\n<tr>\n<td>master.host.selector</td>\n<td>LowerWeight</td>\n<td>master host selector to select a suitable worker, default value: LowerWeight. Optional values include Random, RoundRobin, LowerWeight</td>\n</tr>\n<tr>\n<td>master.heartbeat.interval</td>\n<td>10</td>\n<td>master heartbeat interval, the unit is second</td>\n</tr>\n<tr>\n<td>master.task.commit.retryTimes</td>\n<td>5</td>\n<td>master commit task retry times</td>\n</tr>\n<tr>\n<td>master.task.commit.interval</td>\n<td>1000</td>\n<td>master commit task interval, the unit is millisecond</td>\n</tr>\n<tr>\n<td>master.max.cpuload.avg</td>\n<td>-1</td>\n<td>master max cpuload avg, only higher than the system cpu load average, master server can schedule. default value -1: the number of cpu cores * 2</td>\n</tr>\n<tr>\n<td>master.reserved.memory</td>\n<td>0.3</td>\n<td>master reserved memory, only lower than system available memory, master server can schedule. default value 0.3, the unit is G</td>\n</tr>\n</tbody>\n</table>\n<h2>7.worker.properties [worker-service log config]</h2>\n<table>\n<thead>\n<tr>\n<th>Parameters</th>\n<th>Default value</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>worker.listen.port</td>\n<td>1234</td>\n<td>worker listen port</td>\n</tr>\n<tr>\n<td>worker.exec.threads</td>\n<td>100</td>\n<td>worker execute thread number to limit task instances in parallel</td>\n</tr>\n<tr>\n<td>worker.heartbeat.interval</td>\n<td>10</td>\n<td>worker heartbeat interval, the unit is second</td>\n</tr>\n<tr>\n<td>worker.max.cpuload.avg</td>\n<td>-1</td>\n<td>worker max cpuload avg, only higher than the system cpu load average, worker server can be dispatched tasks. default value -1: the number of cpu cores * 2</td>\n</tr>\n<tr>\n<td>worker.reserved.memory</td>\n<td>0.3</td>\n<td>worker reserved memory, only lower than system available memory, worker server can be dispatched tasks. default value 0.3, the unit is G</td>\n</tr>\n<tr>\n<td>worker.groups</td>\n<td>default</td>\n<td>worker groups separated by comma, like 'worker.groups=default,test' <br> worker will join corresponding group according to this config when startup</td>\n</tr>\n</tbody>\n</table>\n<h2>8.alert.properties [alert-service log config]</h2>\n<table>\n<thead>\n<tr>\n<th>Parameters</th>\n<th>Default value</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>alert.type</td>\n<td>EMAIL</td>\n<td>alter type</td>\n</tr>\n<tr>\n<td>mail.protocol</td>\n<td>SMTP</td>\n<td>mail server protocol</td>\n</tr>\n<tr>\n<td>mail.server.host</td>\n<td><a href=\"http://xxx.xxx.com\">xxx.xxx.com</a></td>\n<td>mail server host</td>\n</tr>\n<tr>\n<td>mail.server.port</td>\n<td>25</td>\n<td>mail server port</td>\n</tr>\n<tr>\n<td>mail.sender</td>\n<td><a href=\"mailto:xxx@xxx.com\">xxx@xxx.com</a></td>\n<td>mail sender email</td>\n</tr>\n<tr>\n<td>mail.user</td>\n<td><a href=\"mailto:xxx@xxx.com\">xxx@xxx.com</a></td>\n<td>mail sender email name</td>\n</tr>\n<tr>\n<td>mail.passwd</td>\n<td>111111</td>\n<td>mail sender email password</td>\n</tr>\n<tr>\n<td>mail.smtp.starttls.enable</td>\n<td>true</td>\n<td>specify mail whether open tls</td>\n</tr>\n<tr>\n<td>mail.smtp.ssl.enable</td>\n<td>false</td>\n<td>specify mail whether open ssl</td>\n</tr>\n<tr>\n<td>mail.smtp.ssl.trust</td>\n<td><a href=\"http://xxx.xxx.com\">xxx.xxx.com</a></td>\n<td>specify mail ssl trust list</td>\n</tr>\n<tr>\n<td>xls.file.path</td>\n<td>/tmp/xls</td>\n<td>mail attachment temp storage directory</td>\n</tr>\n<tr>\n<td></td>\n<td>following configure WeCom[optional]</td>\n<td></td>\n</tr>\n<tr>\n<td>enterprise.wechat.enable</td>\n<td>false</td>\n<td>specify whether enable WeCom</td>\n</tr>\n<tr>\n<td><a href=\"http://enterprise.wechat.corp.id\">enterprise.wechat.corp.id</a></td>\n<td>xxxxxxx</td>\n<td>WeCom corp id</td>\n</tr>\n<tr>\n<td>enterprise.wechat.secret</td>\n<td>xxxxxxx</td>\n<td>WeCom secret</td>\n</tr>\n<tr>\n<td><a href=\"http://enterprise.wechat.agent.id\">enterprise.wechat.agent.id</a></td>\n<td>xxxxxxx</td>\n<td>WeCom agent id</td>\n</tr>\n<tr>\n<td>enterprise.wechat.users</td>\n<td>xxxxxxx</td>\n<td>WeCom users</td>\n</tr>\n<tr>\n<td>enterprise.wechat.token.url</td>\n<td><a href=\"https://qyapi.weixin.qq.com/cgi-bin/gettoken\">https://qyapi.weixin.qq.com/cgi-bin/gettoken</a>?  <br /> corpid=corpId&corpsecret=secret</td>\n<td>WeCom token url</td>\n</tr>\n<tr>\n<td>enterprise.wechat.push.url</td>\n<td><a href=\"https://qyapi.weixin.qq.com/cgi-bin/message/send\">https://qyapi.weixin.qq.com/cgi-bin/message/send</a>?  <br /> access_token=$token</td>\n<td>WeCom push url</td>\n</tr>\n<tr>\n<td>enterprise.wechat.user.send.msg</td>\n<td></td>\n<td>send message format</td>\n</tr>\n<tr>\n<td>enterprise.wechat.team.send.msg</td>\n<td></td>\n<td>group message format</td>\n</tr>\n<tr>\n<td>plugin.dir</td>\n<td>/Users/xx/your/path/to/plugin/dir</td>\n<td>plugin directory</td>\n</tr>\n</tbody>\n</table>\n<h2>9.quartz.properties [quartz config properties]</h2>\n<p>This part describes quartz configs and please configure them based on your practical situation and resources.</p>\n<table>\n<thead>\n<tr>\n<th>Parameters</th>\n<th>Default value</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>org.quartz.jobStore.driverDelegateClass</td>\n<td>org.quartz.impl.jdbcjobstore.StdJDBCDelegate</td>\n<td></td>\n</tr>\n<tr>\n<td>org.quartz.jobStore.driverDelegateClass</td>\n<td>org.quartz.impl.jdbcjobstore.PostgreSQLDelegate</td>\n<td></td>\n</tr>\n<tr>\n<td>org.quartz.scheduler.instanceName</td>\n<td>DolphinScheduler</td>\n<td></td>\n</tr>\n<tr>\n<td>org.quartz.scheduler.instanceId</td>\n<td>AUTO</td>\n<td></td>\n</tr>\n<tr>\n<td>org.quartz.scheduler.makeSchedulerThreadDaemon</td>\n<td>true</td>\n<td></td>\n</tr>\n<tr>\n<td>org.quartz.jobStore.useProperties</td>\n<td>false</td>\n<td></td>\n</tr>\n<tr>\n<td>org.quartz.threadPool.class</td>\n<td>org.quartz.simpl.SimpleThreadPool</td>\n<td></td>\n</tr>\n<tr>\n<td>org.quartz.threadPool.makeThreadsDaemons</td>\n<td>true</td>\n<td></td>\n</tr>\n<tr>\n<td>org.quartz.threadPool.threadCount</td>\n<td>25</td>\n<td></td>\n</tr>\n<tr>\n<td>org.quartz.threadPool.threadPriority</td>\n<td>5</td>\n<td></td>\n</tr>\n<tr>\n<td>org.quartz.jobStore.class</td>\n<td>org.quartz.impl.jdbcjobstore.JobStoreTX</td>\n<td></td>\n</tr>\n<tr>\n<td>org.quartz.jobStore.tablePrefix</td>\n<td>QRTZ_</td>\n<td></td>\n</tr>\n<tr>\n<td>org.quartz.jobStore.isClustered</td>\n<td>true</td>\n<td></td>\n</tr>\n<tr>\n<td>org.quartz.jobStore.misfireThreshold</td>\n<td>60000</td>\n<td></td>\n</tr>\n<tr>\n<td>org.quartz.jobStore.clusterCheckinInterval</td>\n<td>5000</td>\n<td></td>\n</tr>\n<tr>\n<td>org.quartz.jobStore.acquireTriggersWithinLock</td>\n<td>true</td>\n<td></td>\n</tr>\n<tr>\n<td>org.quartz.jobStore.dataSource</td>\n<td>myDs</td>\n<td></td>\n</tr>\n<tr>\n<td>org.quartz.dataSource.myDs.connectionProvider.class</td>\n<td>org.apache.dolphinscheduler.service.quartz.DruidConnectionProvider</td>\n<td></td>\n</tr>\n</tbody>\n</table>\n<h2>10.install_config.conf [DS environment variables configuration script[install/start DS]]</h2>\n<p>install_config.conf is a bit complicated and is mainly used in the following two places.</p>\n<ul>\n<li>1.DS cluster auto installation</li>\n</ul>\n<blockquote>\n<p>System will load configs in the install_config.conf and auto-configure files below, based on the file content when executing '<a href=\"http://install.sh\">install.sh</a>'.\nFiles such as <a href=\"http://dolphinscheduler-daemon.sh\">dolphinscheduler-daemon.sh</a>、datasource.properties、zookeeper.properties、common.properties、application-api.properties、master.properties、worker.properties、alert.properties、quartz.properties and etc.</p>\n</blockquote>\n<ul>\n<li>2.Startup/shutdown DS cluster</li>\n</ul>\n<blockquote>\n<p>The system will load masters, workers, alertServer, apiServers and other parameters inside the file to startup/shutdown DS cluster.</p>\n</blockquote>\n<p>File content as follows:</p>\n<pre><code class=\"language-bash\">\n<span class=\"hljs-comment\"># Note:  please escape the character if the file contains special characters such as `.*[]^${}\\+?|()@#&amp;`.</span>\n<span class=\"hljs-comment\">#   eg: `[` escape to `\\[`</span>\n\n<span class=\"hljs-comment\"># Database type (DS currently only supports postgresql and mysql)</span>\ndbtype=<span class=\"hljs-string\">&quot;mysql&quot;</span>\n\n<span class=\"hljs-comment\"># Database url &amp; port</span>\ndbhost=<span class=\"hljs-string\">&quot;192.168.xx.xx:3306&quot;</span>\n\n<span class=\"hljs-comment\"># Database name</span>\ndbname=<span class=\"hljs-string\">&quot;dolphinscheduler&quot;</span>\n\n\n<span class=\"hljs-comment\"># Database username</span>\nusername=<span class=\"hljs-string\">&quot;xx&quot;</span>\n\n<span class=\"hljs-comment\"># Database password</span>\npassword=<span class=\"hljs-string\">&quot;xx&quot;</span>\n\n<span class=\"hljs-comment\"># Zookeeper url</span>\nzkQuorum=<span class=\"hljs-string\">&quot;192.168.xx.xx:2181,192.168.xx.xx:2181,192.168.xx.xx:2181&quot;</span>\n\n<span class=\"hljs-comment\"># DS installation path, such as &#x27;/data1_1T/dolphinscheduler&#x27;</span>\ninstallPath=<span class=\"hljs-string\">&quot;/data1_1T/dolphinscheduler&quot;</span>\n\n<span class=\"hljs-comment\"># Deployment user</span>\n<span class=\"hljs-comment\"># Note: Deployment user needs &#x27;sudo&#x27; privilege and has rights to operate HDFS</span>\n<span class=\"hljs-comment\">#     Root directory must be created by the same user if using HDFS, otherwise permission related issues will be raised.</span>\ndeployUser=<span class=\"hljs-string\">&quot;dolphinscheduler&quot;</span>\n\n\n<span class=\"hljs-comment\"># Followings are alert-service configs</span>\n<span class=\"hljs-comment\"># Mail server host</span>\nmailServerHost=<span class=\"hljs-string\">&quot;smtp.exmail.qq.com&quot;</span>\n\n<span class=\"hljs-comment\"># Mail server port</span>\nmailServerPort=<span class=\"hljs-string\">&quot;25&quot;</span>\n\n<span class=\"hljs-comment\"># Mail sender</span>\nmailSender=<span class=\"hljs-string\">&quot;xxxxxxxxxx&quot;</span>\n\n<span class=\"hljs-comment\"># Mail user</span>\nmailUser=<span class=\"hljs-string\">&quot;xxxxxxxxxx&quot;</span>\n\n<span class=\"hljs-comment\"># Mail password</span>\nmailPassword=<span class=\"hljs-string\">&quot;xxxxxxxxxx&quot;</span>\n\n<span class=\"hljs-comment\"># Mail supports TLS set true if not set false</span>\nstarttlsEnable=<span class=\"hljs-string\">&quot;true&quot;</span>\n\n<span class=\"hljs-comment\"># Mail supports SSL set true if not set false. Note: starttlsEnable and sslEnable cannot both set true</span>\nsslEnable=<span class=\"hljs-string\">&quot;false&quot;</span>\n\n<span class=\"hljs-comment\"># Mail server host, same as mailServerHost</span>\nsslTrust=<span class=\"hljs-string\">&quot;smtp.exmail.qq.com&quot;</span>\n\n<span class=\"hljs-comment\"># Specify which resource upload function to use for resources storage such as sql files. And supported options are HDFS, S3 and NONE. HDFS for upload to HDFS and NONE for not using this function.</span>\nresourceStorageType=<span class=\"hljs-string\">&quot;NONE&quot;</span>\n\n<span class=\"hljs-comment\"># if S3, write S3 address. HA, for example: s3a://dolphinscheduler，</span>\n<span class=\"hljs-comment\"># Note: s3 make sure to create the root directory /dolphinscheduler</span>\ndefaultFS=<span class=\"hljs-string\">&quot;hdfs://mycluster:8020&quot;</span>\n\n<span class=\"hljs-comment\"># If parameter &#x27;resourceStorageType&#x27; is S3, following configs are needed:</span>\ns3Endpoint=<span class=\"hljs-string\">&quot;http://192.168.xx.xx:9010&quot;</span>\ns3AccessKey=<span class=\"hljs-string\">&quot;xxxxxxxxxx&quot;</span>\ns3SecretKey=<span class=\"hljs-string\">&quot;xxxxxxxxxx&quot;</span>\n\n<span class=\"hljs-comment\"># If ResourceManager supports HA, then input master and standby node IP or hostname, eg: &#x27;192.168.xx.xx,192.168.xx.xx&#x27;. Or else ResourceManager run in standalone mode, please set yarnHaIps=&quot;&quot; and &quot;&quot; for not using yarn.</span>\nyarnHaIps=<span class=\"hljs-string\">&quot;192.168.xx.xx,192.168.xx.xx&quot;</span>\n\n\n<span class=\"hljs-comment\"># If ResourceManager runs in standalone, then set ResourceManager node ip or hostname, or else remain default.</span>\nsingleYarnIp=<span class=\"hljs-string\">&quot;yarnIp1&quot;</span>\n\n<span class=\"hljs-comment\"># Storage path when using HDFS/S3</span>\nresourceUploadPath=<span class=\"hljs-string\">&quot;/dolphinscheduler&quot;</span>\n\n\n<span class=\"hljs-comment\"># HDFS/S3 root user</span>\nhdfsRootUser=<span class=\"hljs-string\">&quot;hdfs&quot;</span>\n\n<span class=\"hljs-comment\"># Followings are kerberos configs</span>\n\n<span class=\"hljs-comment\"># Spicify kerberos enable or not</span>\nkerberosStartUp=<span class=\"hljs-string\">&quot;false&quot;</span>\n\n<span class=\"hljs-comment\"># Kdc krb5 config file path</span>\nkrb5ConfPath=<span class=\"hljs-string\">&quot;<span class=\"hljs-variable\">$installPath</span>/conf/krb5.conf&quot;</span>\n\n<span class=\"hljs-comment\"># Keytab username</span>\nkeytabUserName=<span class=\"hljs-string\">&quot;hdfs-mycluster@ESZ.COM&quot;</span>\n\n<span class=\"hljs-comment\"># Username keytab path</span>\nkeytabPath=<span class=\"hljs-string\">&quot;<span class=\"hljs-variable\">$installPath</span>/conf/hdfs.headless.keytab&quot;</span>\n\n\n<span class=\"hljs-comment\"># API-service port</span>\napiServerPort=<span class=\"hljs-string\">&quot;12345&quot;</span>\n\n\n<span class=\"hljs-comment\"># All hosts deploy DS</span>\nips=<span class=\"hljs-string\">&quot;ds1,ds2,ds3,ds4,ds5&quot;</span>\n\n<span class=\"hljs-comment\"># Ssh port, default 22</span>\nsshPort=<span class=\"hljs-string\">&quot;22&quot;</span>\n\n<span class=\"hljs-comment\"># Master service hosts</span>\nmasters=<span class=\"hljs-string\">&quot;ds1,ds2&quot;</span>\n\n<span class=\"hljs-comment\"># All hosts deploy worker service</span>\n<span class=\"hljs-comment\"># Note: Each worker needs to set a worker group name and default name is &quot;default&quot;</span>\nworkers=<span class=\"hljs-string\">&quot;ds1:default,ds2:default,ds3:default,ds4:default,ds5:default&quot;</span>\n\n<span class=\"hljs-comment\">#  Host deploy alert-service</span>\nalertServer=<span class=\"hljs-string\">&quot;ds3&quot;</span>\n\n<span class=\"hljs-comment\"># Host deploy API-service</span>\napiServers=<span class=\"hljs-string\">&quot;ds1&quot;</span>\n</code></pre>\n<h2>11.dolphinscheduler_env.sh [load environment variables configs]</h2>\n<p>When using shell to commit tasks, DS will load environment variables inside dolphinscheduler_env.sh into the host.\nTypes of tasks involved are: Shell task、Python task、Spark task、Flink task、Datax task and etc.</p>\n<pre><code class=\"language-bash\"><span class=\"hljs-built_in\">export</span> HADOOP_HOME=/opt/soft/hadoop\n<span class=\"hljs-built_in\">export</span> HADOOP_CONF_DIR=/opt/soft/hadoop/etc/hadoop\n<span class=\"hljs-built_in\">export</span> SPARK_HOME1=/opt/soft/spark1\n<span class=\"hljs-built_in\">export</span> SPARK_HOME2=/opt/soft/spark2\n<span class=\"hljs-built_in\">export</span> PYTHON_HOME=/opt/soft/python\n<span class=\"hljs-built_in\">export</span> JAVA_HOME=/opt/soft/java\n<span class=\"hljs-built_in\">export</span> HIVE_HOME=/opt/soft/hive\n<span class=\"hljs-built_in\">export</span> FLINK_HOME=/opt/soft/flink\n<span class=\"hljs-built_in\">export</span> DATAX_HOME=/opt/soft/datax/bin/datax.py\n\n<span class=\"hljs-built_in\">export</span> PATH=<span class=\"hljs-variable\">$HADOOP_HOME</span>/bin:<span class=\"hljs-variable\">$SPARK_HOME1</span>/bin:<span class=\"hljs-variable\">$SPARK_HOME2</span>/bin:<span class=\"hljs-variable\">$PYTHON_HOME</span>:<span class=\"hljs-variable\">$JAVA_HOME</span>/bin:<span class=\"hljs-variable\">$HIVE_HOME</span>/bin:<span class=\"hljs-variable\">$PATH</span>:<span class=\"hljs-variable\">$FLINK_HOME</span>/bin:<span class=\"hljs-variable\">$DATAX_HOME</span>:<span class=\"hljs-variable\">$PATH</span>\n\n</code></pre>\n<h2>12. Services logback configs</h2>\n<table>\n<thead>\n<tr>\n<th>Services name</th>\n<th>logback config name</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>API-service logback config</td>\n<td>logback-api.xml</td>\n</tr>\n<tr>\n<td>master-service logback config</td>\n<td>logback-master.xml</td>\n</tr>\n<tr>\n<td>worker-service logback config</td>\n<td>logback-worker.xml</td>\n</tr>\n<tr>\n<td>alert-service logback config</td>\n<td>logback-alert.xml</td>\n</tr>\n</tbody>\n</table>\n",
  "link": "/dist/en-us/docs/1.3.4/user_doc/configuration-file.html",
  "meta": {}
}