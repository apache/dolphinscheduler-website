<!DOCTYPE html>
<html lang="en">

<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
	<meta name="keywords" content="cluster-deployment" />
	<meta name="description" content="cluster-deployment" />
	<!-- 网页标签标题 -->
	<title>cluster-deployment</title>
	<link rel="shortcut icon" href="/img/docsite.ico"/>
	<link rel="stylesheet" href="/build/documentation.md.css" />
</head>
<body>
	<div id="root"><div class="md2html documentation-page" data-reactroot=""><header class="header-container header-container-normal"><div class="header-body"><a href="/en-us/index.html"><img class="logo" src="/img/hlogo_colorful.svg"/></a><div class="search search-normal"><span class="icon-search"></span></div><span class="language-switch language-switch-normal">中</span><div class="header-menu"><img class="header-menu-toggle" src="/img/system/menu_gray.png"/><div><ul class="nav"><li><a href="/en-us/index.html">HOME</a></li><li><a href="/en-us/docs/1.3.4/user_doc/quick-start.html">DOCS</a><ul><li><a href="/en-us/docs/1.3.4/user_doc/quick-start.html">1.3.4(Recommend)</a></li><li><a href="/en-us/docs/1.3.3/user_doc/quick-start.html">1.3.3</a></li><li><a href="/en-us/docs/1.3.2/user_doc/quick-start.html">1.3.2</a></li><li><a href="/en-us/docs/1.3.1/user_doc/quick-start.html">1.3.1</a></li><li><a href="/en-us/docs/1.2.1/user_doc/quick-start.html">1.2.1</a></li><li><a href="/en-us/docs/1.2.0/user_doc/quick-start.html">1.2.0</a></li><li><a href="https://analysys.github.io/easyscheduler_docs_cn/">1.1.0(Not Apache Release)</a></li></ul></li><li><a href="/en-us/docs/release/download.html">DOWNLOAD</a></li><li><a href="/en-us/blog/index.html">BLOG</a></li><li><a href="/en-us/docs/development/subscribe.html">DEVELOPMENT</a></li><li><a href="/en-us/community/index.html">COMMUNITY</a></li><li><a href="https://www.apache.org/" target="_blank">ASF</a><ul><li><a href="https://www.apache.org/" target="_blank">Foundation</a></li><li><a href="https://www.apache.org/licenses/" target="_blank">License</a></li><li><a href="https://www.apache.org/events/current-event" target="_blank">Events</a></li><li><a href="https://www.apache.org/security/" target="_blank">Security</a></li><li><a href="https://www.apache.org/foundation/sponsorship.html" target="_blank">Sponsorship</a></li><li><a href="https://www.apache.org/foundation/thanks.html" target="_blank">Thanks</a></li></ul></li></ul></div></div></div></header><div class="bar"><div class="bar-body"><img src="/img/system/docs.png" class="front-img"/><span>Documentation</span><img src="/img/system/docs.png" class="back-img"/></div></div><section class="content-section"><div class="sidemenu"><div class="sidemenu-toggle"><img src="https://img.alicdn.com/tfs/TB1E6apXHGYBuNjy0FoXXciBFXa-200-200.png"/></div><ul><li class="menu-item menu-item-level-1"><span>Deployment Document</span><ul><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/en-us/docs/1.2.1/user_doc/hardware-environment.html" target="_self">Hareware Environment</a></li><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/en-us/docs/1.2.1/user_doc/backend-deployment.html" target="_self">Backend deploy</a></li><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/en-us/docs/1.2.1/user_doc/frontend-deployment.html" target="_self">Frontend deploy</a></li></ul></li><li class="menu-item menu-item-level-1"><span>User Manual</span><ul><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/en-us/docs/1.2.1/user_doc/quick-start.html" target="_self">Quick Start</a></li><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/en-us/docs/1.2.1/user_doc/system-manual.html" target="_self">User Manual</a></li><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/en-us/docs/1.2.1/user_doc/metadata-1.2.html" target="_self">Metadata</a></li></ul></li><li class="menu-item menu-item-level-1"><span>Api Document</span><ul><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="http://106.75.43.194:8888/dolphinscheduler/doc.html?language=en&amp;lang=en" target="_blank">Api Document</a></li></ul></li><li class="menu-item menu-item-level-1"><span>Upgrade</span><ul><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/en-us/docs/1.2.1/user_doc/upgrade.html" target="_self">Upgrade</a></li></ul></li><li class="menu-item menu-item-level-1"><span>FAQ</span><ul><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/en-us/docs/release/faq.html" target="_self">FAQ</a></li></ul></li></ul></div><div class="doc-content markdown-body"><h1>Cluster Deployment</h1>
<h1>1、Before you begin (please install requirement basic software by yourself)</h1>
<ul>
<li>PostgreSQL (8.2.15+) or MySQL (5.7)  :  Choose One</li>
<li><a href="https://www.oracle.com/technetwork/java/javase/downloads/index.html">JDK</a> (1.8+) :  Required. Double-check configure JAVA_HOME and PATH environment variables in /etc/profile</li>
<li>ZooKeeper (3.4.6+) ：Required</li>
<li>Hadoop (2.6+) or MinIO ：Optional. If you need to upload a resource function, you can choose a local file directory as the upload folder for a single machine (this operation does not need to deploy Hadoop). Of course, you can also choose to upload to Hadoop or MinIO.</li>
</ul>
<pre><code class="language-markdown"> Tips：DolphinScheduler itself does not rely on Hadoop, Hive, Spark, only use their clients for the corresponding task of running.
</code></pre>
<h1>2、Download the binary package.</h1>
<ul>
<li>Please download the latest version of the default installation package to the server deployment directory. For example, use /opt/dolphinscheduler as the installation and deployment directory. Download address: <a href="https://dolphinscheduler.apache.org/en-us/docs/release/download.html">Download</a>，Download the package and move to the installation and deployment directory. Then unzip it.</li>
</ul>
<pre><code class="language-shell"><span class="hljs-meta">#</span><span class="bash"> Create the deployment directory. Do not choose a deployment directory with a high-privilege directory such as / root or / home.</span>
mkdir -p /opt/dolphinscheduler;
cd /opt/dolphinscheduler;
<span class="hljs-meta">#</span><span class="bash"> unzip</span>
tar -zxvf apache-dolphinscheduler-incubating-1.3.2-dolphinscheduler-bin.tar.gz -C /opt/dolphinscheduler;

mv apache-dolphinscheduler-incubating-1.3.2-dolphinscheduler-bin  dolphinscheduler-bin
</code></pre>
<h1>3、Create deployment user and hosts mapping</h1>
<ul>
<li>Create a deployment user on the ** all ** deployment machines, and be sure to configure sudo passwordless. If we plan to deploy DolphinScheduler on 4 machines: ds1, ds2, ds3, and ds4, we first need to create a deployment user on each machine.</li>
</ul>
<pre><code class="language-shell"><span class="hljs-meta">#</span><span class="bash"> To create a user, you need to <span class="hljs-built_in">log</span> <span class="hljs-keyword">in</span> as root and <span class="hljs-built_in">set</span> the deployment user name. Please modify it yourself. The following uses dolphinscheduler as an example.</span>
useradd dolphinscheduler;
<span class="hljs-meta">
#</span><span class="bash"> Set the user password, please modify it yourself. The following takes dolphinscheduler123 as an example.</span>
echo "dolphinscheduler123" | passwd --stdin dolphinscheduler
<span class="hljs-meta">
#</span><span class="bash"> Configure sudo passwordless</span>
echo 'dolphinscheduler  ALL=(ALL)  NOPASSWD: NOPASSWD: ALL' &gt;&gt; /etc/sudoers
sed -i 's/Defaults    requirett/#Defaults    requirett/g' /etc/sudoers

</code></pre>
<pre><code> Notes：
 - Because the task execution service is based on 'sudo -u {linux-user}' to switch between different Linux users to implement multi-tenant running jobs, the deployment user needs to have sudo permissions and is passwordless. The first-time learners who can ignore it if they don't understand.
 - If find the &quot;Default requiretty&quot; in the &quot;/etc/sudoers&quot; file, also comment out.
 - If you need to use resource upload, you need to assign the user of permission to operate the local file system, HDFS or MinIO.
</code></pre>
<h1>4、Configure hosts mapping and ssh access and modify directory permissions.</h1>
<ul>
<li>
<p>Use the first machine (hostname is ds1) as the deployment machine, configure the hosts of all machines to be deployed on ds1, and login as root on ds1.</p>
<pre><code class="language-shell">vi /etc/hosts
<span class="hljs-meta">
#</span><span class="bash">add ip hostname</span>
192.168.xxx.xxx ds1
192.168.xxx.xxx ds2
192.168.xxx.xxx ds3
192.168.xxx.xxx ds4
</code></pre>
<p><em>Note: Please delete or comment out the line 127.0.0.1</em></p>
</li>
<li>
<p>Sync /etc/hosts on ds1 to all deployment machines</p>
<pre><code class="language-shell">for ip in ds2 ds3;     # Please replace ds2 ds3 here with the hostname of machines you want to deploy
do
    sudo scp -r /etc/hosts  $ip:/etc/          # Need to enter root password during operation
done
</code></pre>
<p><em>Note: can use <code>sshpass -p xxx sudo scp -r /etc/hosts $ip:/etc/</code> to avoid type password.</em></p>
<blockquote>
<p>Install sshpass in Centos：</p>
<ol>
<li>
<p>Install epel</p>
<p>yum install -y epel-release</p>
<p>yum repolist</p>
</li>
<li>
<p>After installing epel, you can install sshpass</p>
<p>yum install -y sshpass</p>
</li>
</ol>
</blockquote>
</li>
<li>
<p>On ds1, switch to the deployment user and configure ssh passwordless login</p>
<pre><code class="language-shell"> su dolphinscheduler;

ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa
cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys
chmod 600 ~/.ssh/authorized_keys
</code></pre>
</li>
</ul>
<p>​      Note: <em>If configure success, the dolphinscheduler user does not need to enter a password when executing the command <code>ssh localhost</code></em></p>
<ul>
<li>
<p>On ds1, configure the deployment user dolphinscheduler ssh to connect to other machines to be deployed.</p>
<pre><code class="language-shell">su dolphinscheduler;
for ip in ds2 ds3;     # Please replace ds2 ds3 here with the hostname of the machine you want to deploy.
do
    ssh-copy-id  $ip   # You need to manually enter the password of the dolphinscheduler user during the operation.
done
<span class="hljs-meta">#</span><span class="bash"> can use `sshpass -p xxx ssh-copy-id <span class="hljs-variable">$ip</span>` to avoid <span class="hljs-built_in">type</span> password.</span>
</code></pre>
</li>
<li>
<p>On ds1, modify the directory permissions so that the deployment user has operation permissions on the dolphinscheduler-bin directory.</p>
<pre><code class="language-shell">sudo chown -R dolphinscheduler:dolphinscheduler dolphinscheduler-bin
</code></pre>
</li>
</ul>
<h1>5、Database initialization</h1>
<ul>
<li>Into the database. The default database is PostgreSQL. If you select MySQL, you need to add the mysql-connector-java driver package to the lib directory of DolphinScheduler.</li>
</ul>
<pre><code>mysql -h192.168.xx.xx -P3306 -uroot -p
</code></pre>
<ul>
<li>After entering the database command line window, execute the database initialization command and set the user and password. <strong>Note: {user} and {password} need to be replaced with a specific database username and password</strong></li>
</ul>
<pre><code class="language-mysql">   mysql&gt; CREATE DATABASE dolphinscheduler DEFAULT CHARACTER SET utf8 DEFAULT COLLATE utf8_general_ci;
   mysql&gt; GRANT ALL PRIVILEGES ON dolphinscheduler.* TO '{user}'@'%' IDENTIFIED BY '{password}';
   mysql&gt; GRANT ALL PRIVILEGES ON dolphinscheduler.* TO '{user}'@'localhost' IDENTIFIED BY '{password}';
   mysql&gt; flush privileges;
</code></pre>
<ul>
<li>
<p>Create tables and import basic data</p>
<ul>
<li>Modify the following configuration in datasource.properties under the conf directory</li>
</ul>
<pre><code class="language-shell">  vi conf/datasource.properties
</code></pre>
<ul>
<li>If you choose Mysql, please comment out the relevant configuration of PostgreSQL (vice versa), you also need to manually add the [[mysql-connector-java driver jar] (<a href="https://downloads.mysql.com/archives/c-j/">https://downloads.mysql.com/archives/c-j/</a>)] package to lib under the directory, and then configure the database connection information correctly.</li>
</ul>
<pre><code class="language-properties"><span class="hljs-comment">  #postgre</span>
<span class="hljs-comment">  #spring.datasource.driver-class-name=org.postgresql.Driver</span>
<span class="hljs-comment">  #spring.datasource.url=jdbc:postgresql://localhost:5432/dolphinscheduler</span>
<span class="hljs-comment">  # mysql</span>
  <span class="hljs-meta">spring.datasource.driver-class-name</span>=<span class="hljs-string">com.mysql.jdbc.Driver</span>
  <span class="hljs-meta">spring.datasource.url</span>=<span class="hljs-string">jdbc:mysql://xxx:3306/dolphinscheduler?useUnicode=true&amp;characterEncoding=UTF-8&amp;allowMultiQueries=true     # Replace the correct IP address</span>
  <span class="hljs-meta">spring.datasource.username</span>=<span class="hljs-string">xxx						# replace the correct {user} value</span>
  <span class="hljs-meta">spring.datasource.password</span>=<span class="hljs-string">xxx						# replace the correct {password} value</span>
</code></pre>
<ul>
<li>After modifying and saving, execute the create table and import data script in the script directory.</li>
</ul>
<pre><code class="language-shell">sh script/create-dolphinscheduler.sh
</code></pre>
</li>
</ul>
<p>​       <em>Note: If you execute the above script and report &quot;/bin/java: No such file or directory&quot; error, please configure JAVA_HOME and PATH variables in /etc/profile</em></p>
<h1>6、Modify runtime parameters.</h1>
<ul>
<li>
<p>Modify the environment variable in <code>dolphinscheduler_env.sh</code> file which on the 'conf/env' directory (take the relevant software installed under '/opt/soft' as an example)</p>
<pre><code class="language-shell">    export HADOOP_HOME=/opt/soft/hadoop
    export HADOOP_CONF_DIR=/opt/soft/hadoop/etc/hadoop
    #export SPARK_HOME1=/opt/soft/spark1
    export SPARK_HOME2=/opt/soft/spark2
    export PYTHON_HOME=/opt/soft/python
    export JAVA_HOME=/opt/soft/java
    export HIVE_HOME=/opt/soft/hive
    export FLINK_HOME=/opt/soft/flink
    export DATAX_HOME=/opt/soft/datax/bin/datax.py
    export PATH=$HADOOP_HOME/bin:$SPARK_HOME2/bin:$PYTHON_HOME:$JAVA_HOME/bin:$HIVE_HOME/bin:$PATH:$FLINK_HOME/bin:$DATAX_HOME:$PATH

    ```

 `Note: This step is very important. For example, JAVA_HOME and PATH must be configured. Those that are not used can be ignored or commented out.`



</code></pre>
</li>
<li>
<p>Create Soft link jdk to /usr/bin/java (still JAVA_HOME=/opt/soft/java as an example)</p>
<pre><code class="language-shell">sudo ln -s /opt/soft/java/bin/java /usr/bin/java
</code></pre>
</li>
<li>
<p>Modify the parameters in the one-click deployment config file <code>conf/config/install_config.conf</code>, pay special attention to the configuration of the following parameters.</p>
<pre><code class="language-shell"><span class="hljs-meta">#</span><span class="bash"> choose mysql or postgresql</span>
dbtype="mysql"
<span class="hljs-meta">
#</span><span class="bash"> Database connection address and port</span>
dbhost="192.168.xx.xx:3306"
<span class="hljs-meta">
#</span><span class="bash"> database name</span>
dbname="dolphinscheduler"
<span class="hljs-meta">
#</span><span class="bash"> database username</span>
username="xxx"
<span class="hljs-meta">
#</span><span class="bash"> database password</span>
<span class="hljs-meta">#</span><span class="bash"> NOTICE: <span class="hljs-keyword">if</span> there are special characters, please use the \ to escape, <span class="hljs-keyword">for</span> example, `[` escape to `\[`</span>
password="xxx"
<span class="hljs-meta">
#</span><span class="bash">Zookeeper cluster</span>
zkQuorum="192.168.xx.xx:2181,192.168.xx.xx:2181,192.168.xx.xx:2181"
<span class="hljs-meta">
#</span><span class="bash"> Note: the target installation path <span class="hljs-keyword">for</span> dolphinscheduler, please not config as the same as the current path (<span class="hljs-built_in">pwd</span>)</span>
installPath="/opt/soft/dolphinscheduler"
<span class="hljs-meta">
#</span><span class="bash"> deployment user</span>
<span class="hljs-meta">#</span><span class="bash"> Note: the deployment user needs to have sudo privileges and permissions to operate hdfs. If hdfs is enabled, the root directory needs to be created by itself</span>
deployUser="dolphinscheduler"
<span class="hljs-meta">
#</span><span class="bash"> alert config，take QQ email <span class="hljs-keyword">for</span> example</span>
<span class="hljs-meta">#</span><span class="bash"> mail protocol</span>
mailProtocol="SMTP"
<span class="hljs-meta">
#</span><span class="bash"> mail server host</span>
mailServerHost="smtp.qq.com"
<span class="hljs-meta">
#</span><span class="bash"> mail server port</span>
<span class="hljs-meta">#</span><span class="bash"> note: Different protocols and encryption methods correspond to different ports, when SSL/TLS is enabled, make sure the port is correct.</span>
mailServerPort="25"
<span class="hljs-meta">
#</span><span class="bash"> mail sender</span>
mailSender="xxx@qq.com"
<span class="hljs-meta">
#</span><span class="bash"> mail user</span>
mailUser="xxx@qq.com"
<span class="hljs-meta">
#</span><span class="bash"> mail sender password</span>
<span class="hljs-meta">#</span><span class="bash"> note: The mail.passwd is email service authorization code, not the email login password.</span>
mailPassword="xxx"
<span class="hljs-meta">
#</span><span class="bash"> Whether TLS mail protocol is supported,<span class="hljs-literal">true</span> is supported and <span class="hljs-literal">false</span> is not supported</span>
starttlsEnable="true"
<span class="hljs-meta">
#</span><span class="bash"> Whether TLS mail protocol is supported,<span class="hljs-literal">true</span> is supported and <span class="hljs-literal">false</span> is not supported。</span>
<span class="hljs-meta">#</span><span class="bash"> note: only one of TLS and SSL can be <span class="hljs-keyword">in</span> the <span class="hljs-literal">true</span> state.</span>
sslEnable="false"
<span class="hljs-meta">
#</span><span class="bash"> note: sslTrust is the same as mailServerHost</span>
sslTrust="smtp.qq.com"
<span class="hljs-meta">

#</span><span class="bash"> resource storage <span class="hljs-built_in">type</span>：HDFS,S3,NONE</span>
resourceStorageType="HDFS"
<span class="hljs-meta">
#</span><span class="bash"> If resourceStorageType = HDFS, and your Hadoop Cluster NameNode has HA enabled, you need to put core-site.xml and hdfs-site.xml <span class="hljs-keyword">in</span> the installPath/conf directory. In this example, it is placed under /opt/soft/dolphinscheduler/conf, and configure the namenode cluster name; <span class="hljs-keyword">if</span> the NameNode is not HA, modify it to a specific IP or host name.</span>
<span class="hljs-meta">#</span><span class="bash"> <span class="hljs-keyword">if</span> S3，write S3 address，HA，<span class="hljs-keyword">for</span> example ：s3a://dolphinscheduler，</span>
<span class="hljs-meta">#</span><span class="bash"> Note，s3 be sure to create the root directory /dolphinscheduler</span>
defaultFS="hdfs://mycluster:8020"
<span class="hljs-meta">

#</span><span class="bash"> <span class="hljs-keyword">if</span> not use hadoop resourcemanager, please keep default value; <span class="hljs-keyword">if</span> resourcemanager HA <span class="hljs-built_in">enable</span>, please <span class="hljs-built_in">type</span> the HA ips ; <span class="hljs-keyword">if</span> resourcemanager is single, make this value empty</span>
yarnHaIps="192.168.xx.xx,192.168.xx.xx"
<span class="hljs-meta">
#</span><span class="bash"> <span class="hljs-keyword">if</span> resourcemanager HA <span class="hljs-built_in">enable</span> or not use resourcemanager, please skip this value setting; If resourcemanager is single, you only need to replace yarnIp1 to actual resourcemanager hostname.</span>
singleYarnIp="yarnIp1"
<span class="hljs-meta">
#</span><span class="bash"> resource store on HDFS/S3 path, resource file will store to this hadoop hdfs path, self configuration, please make sure the directory exists on hdfs and have <span class="hljs-built_in">read</span> write permissions。/dolphinscheduler is recommended</span>
resourceUploadPath="/dolphinscheduler"
<span class="hljs-meta">
#</span><span class="bash"> who have permissions to create directory under HDFS/S3 root path</span>
<span class="hljs-meta">#</span><span class="bash"> Note: <span class="hljs-keyword">if</span> kerberos is enabled, please config hdfsRootUser=</span>
hdfsRootUser="hdfs"
<span class="hljs-meta">


#</span><span class="bash"> install hosts</span>
<span class="hljs-meta">#</span><span class="bash"> Note: install the scheduled hostname list. If it is pseudo-distributed, just write a pseudo-distributed hostname</span>
ips="ds1,ds2,ds3,ds4"
<span class="hljs-meta">
#</span><span class="bash"> ssh port, default 22</span>
<span class="hljs-meta">#</span><span class="bash"> Note: <span class="hljs-keyword">if</span> ssh port is not default, modify here</span>
sshPort="22"
<span class="hljs-meta">
#</span><span class="bash"> run master machine</span>
<span class="hljs-meta">#</span><span class="bash"> Note: list of hosts hostname <span class="hljs-keyword">for</span> deploying master</span>
masters="ds1,ds2"
<span class="hljs-meta">
#</span><span class="bash"> run worker machine</span>
<span class="hljs-meta">#</span><span class="bash"> note: need to write the worker group name of each worker, the default value is <span class="hljs-string">"default"</span></span>
workers="ds3:default,ds4:default"
<span class="hljs-meta">
#</span><span class="bash"> run alert machine</span>
<span class="hljs-meta">#</span><span class="bash"> note: list of machine hostnames <span class="hljs-keyword">for</span> deploying alert server</span>
alertServer="ds2"
<span class="hljs-meta">
#</span><span class="bash"> run api machine</span>
<span class="hljs-meta">#</span><span class="bash"> note: list of machine hostnames <span class="hljs-keyword">for</span> deploying api server</span>
apiServers="ds1"

</code></pre>
<p><em>Attention:</em></p>
<ul>
<li>If you need to upload resources to the Hadoop cluster, and the NameNode of the Hadoop cluster is configured with HA, you need to enable HDFS resource upload, and you need to copy the core-site.xml and hdfs-site.xml in the Hadoop cluster to /opt/ dolphinscheduler/conf. Non-NameNode HA skips the next step.</li>
</ul>
</li>
</ul>
<h1>7、Automated Deployment</h1>
<ul>
<li>
<p>Switch to the deployment user and execute the one-click deployment script</p>
<p><code>sh install.sh</code></p>
<pre><code>Note:
For the first deployment, the following message appears in step 3 of `3, stop server` during operation. This message can be ignored.
sh: bin/dolphinscheduler-daemon.sh: No such file or directory
</code></pre>
</li>
<li>
<p>After the script is completed, the following 5 services will be started. Use the <code>jps</code> command to check whether the services are started (<code>jps</code> comes with <code>java JDK</code>)</p>
</li>
</ul>
<pre><code class="language-aidl">    MasterServer         ----- master service
    WorkerServer         ----- worker service
    LoggerServer         ----- logger service
    ApiApplicationServer ----- api service
    AlertServer          ----- alert service
</code></pre>
<p>If the above services are started normally, the automatic deployment is successful.</p>
<p>After the deployment is successful, you can view the logs. The logs are stored in the logs folder.</p>
<pre><code class="language-log"> logs/
    ├── dolphinscheduler-alert-server.log
    ├── dolphinscheduler-master-server.log
    |—— dolphinscheduler-worker-server.log
    |—— dolphinscheduler-api-server.log
    |—— dolphinscheduler-logger-server.log
</code></pre>
<h1>8、login</h1>
<ul>
<li>
<p>Access the address of the front page, interface IP (self-modified)
<a href="http://192.168.xx.xx:12345/dolphinscheduler">http://192.168.xx.xx:12345/dolphinscheduler</a></p>
 <p align="center">
   <img src="/img/login_en.png" width="60%" />
 </p>
</li>
</ul>
<h1>9、Start and stop service</h1>
<ul>
<li>
<p>Stop all services</p>
<p><code>sh ./bin/stop-all.sh</code></p>
</li>
<li>
<p>Start all services</p>
<p><code>sh ./bin/start-all.sh</code></p>
</li>
<li>
<p>Start and stop master service</p>
</li>
</ul>
<pre><code class="language-shell">sh ./bin/dolphinscheduler-daemon.sh start master-server
sh ./bin/dolphinscheduler-daemon.sh stop master-server
</code></pre>
<ul>
<li>Start and stop worker Service</li>
</ul>
<pre><code class="language-shell">sh ./bin/dolphinscheduler-daemon.sh start worker-server
sh ./bin/dolphinscheduler-daemon.sh stop worker-server
</code></pre>
<ul>
<li>Start and stop api Service</li>
</ul>
<pre><code class="language-shell">sh ./bin/dolphinscheduler-daemon.sh start api-server
sh ./bin/dolphinscheduler-daemon.sh stop api-server
</code></pre>
<ul>
<li>Start and stop logger Service</li>
</ul>
<pre><code class="language-shell">sh ./bin/dolphinscheduler-daemon.sh start logger-server
sh ./bin/dolphinscheduler-daemon.sh stop logger-server
</code></pre>
<ul>
<li>Start and stop alert service</li>
</ul>
<pre><code class="language-shell">sh ./bin/dolphinscheduler-daemon.sh start alert-server
sh ./bin/dolphinscheduler-daemon.sh stop alert-server
</code></pre>
<p><code>Note: Please refer to the &quot;Architecture Design&quot; section for service usage</code></p>
</div></section><footer class="footer-container"><div class="footer-body"><img src="/img/ds_gray.svg"/><div class="cols-container"><div class="col col-12"><h3>Disclaimer</h3><p>Apache DolphinScheduler (incubating) is an effort undergoing incubation at The Apache Software Foundation (ASF), sponsored by Incubator. 
Incubation is required of all newly accepted projects until a further review indicates 
that the infrastructure, communications, and decision making process have stabilized in a manner consistent with other successful ASF projects. 
While incubation status is not necessarily a reflection of the completeness or stability of the code, 
it does indicate that the project has yet to be fully endorsed by the ASF.</p></div><div class="col col-6"><dl><dt>Documentation</dt><dd><a href="/en-us/docs/development/architecture-design.html" target="_self">Overview</a></dd><dd><a href="/en-us/docs/1.3.4/user_doc/quick-start.html" target="_self">Quick start</a></dd><dd><a href="/en-us/docs/development/backend-development.html" target="_self">Developer guide</a></dd></dl></div><div class="col col-6"><dl><dt>ASF</dt><dd><a href="http://www.apache.org" target="_self">Foundation</a></dd><dd><a href="http://www.apache.org/licenses/" target="_self">License</a></dd><dd><a href="http://www.apache.org/events/current-event" target="_self">Events</a></dd><dd><a href="http://www.apache.org/foundation/sponsorship.html" target="_self">Sponsorship</a></dd><dd><a href="http://www.apache.org/foundation/thanks.html" target="_self">Thanks</a></dd></dl></div></div><div class="copyright"><span>Copyright © 2018-2020 The Apache Software Foundation. Apache DolphinScheduler, DolphinScheduler, and its feather logo are trademarks of The Apache Software Foundation.</span></div></div></footer></div></div>
	<script src="https://f.alicdn.com/react/15.4.1/react-with-addons.min.js"></script>
	<script src="https://f.alicdn.com/react/15.4.1/react-dom.min.js"></script>
	<script>window.rootPath = '';</script>
	<script src="/build/documentation.md.js"></script>
	<script>
	  var _hmt = _hmt || [];
	  (function() {
		var hm = document.createElement("script");
		hm.src = "https://hm.baidu.com/hm.js?4e7b4b400dd31fa015018a435c64d06f";
		var s = document.getElementsByTagName("script")[0];
		s.parentNode.insertBefore(hm, s);
	  })();
	</script>
</body>
</html>