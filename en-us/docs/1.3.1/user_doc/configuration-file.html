<!DOCTYPE html>
<html lang="en">

<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
	<meta name="keywords" content="configuration-file" />
	<meta name="description" content="configuration-file" />
	<!-- 网页标签标题 -->
	<title>configuration-file</title>
	<link rel="shortcut icon" href="/img/docsite.ico"/>
	<link rel="stylesheet" href="/build/documentation.md.css" />
</head>
<body>
	<div id="root"><div class="md2html documentation-page" data-reactroot=""><header class="header-container header-container-normal"><div class="header-body"><a href="/en-us/index.html"><img class="logo" src="/img/hlogo_colorful.svg"/></a><div class="search search-normal"><span class="icon-search"></span></div><span class="language-switch language-switch-normal">中</span><div class="header-menu"><img class="header-menu-toggle" src="/img/system/menu_gray.png"/><div><ul class="nav"><li><a href="/en-us/index.html">HOME</a></li><li><a href="/en-us/docs/1.3.4/user_doc/quick-start.html">DOCS</a><ul><li><a href="/en-us/docs/1.3.4/user_doc/quick-start.html">1.3.4(Recommend)</a></li><li><a href="/en-us/docs/1.3.3/user_doc/quick-start.html">1.3.3</a></li><li><a href="/en-us/docs/1.3.2/user_doc/quick-start.html">1.3.2</a></li><li><a href="/en-us/docs/1.3.1/user_doc/quick-start.html">1.3.1</a></li><li><a href="/en-us/docs/1.2.1/user_doc/quick-start.html">1.2.1</a></li><li><a href="/en-us/docs/1.2.0/user_doc/quick-start.html">1.2.0</a></li><li><a href="https://analysys.github.io/easyscheduler_docs_cn/">1.1.0(Not Apache Release)</a></li></ul></li><li><a href="/en-us/docs/release/download.html">DOWNLOAD</a></li><li><a href="/en-us/blog/index.html">BLOG</a></li><li><a href="/en-us/docs/development/subscribe.html">DEVELOPMENT</a></li><li><a href="/en-us/community/index.html">COMMUNITY</a></li><li><a href="https://www.apache.org/" target="_blank">ASF</a><ul><li><a href="https://www.apache.org/" target="_blank">Foundation</a></li><li><a href="https://www.apache.org/licenses/" target="_blank">License</a></li><li><a href="https://www.apache.org/events/current-event" target="_blank">Events</a></li><li><a href="https://www.apache.org/security/" target="_blank">Security</a></li><li><a href="https://www.apache.org/foundation/sponsorship.html" target="_blank">Sponsorship</a></li><li><a href="https://www.apache.org/foundation/thanks.html" target="_blank">Thanks</a></li></ul></li></ul></div></div></div></header><div class="bar"><div class="bar-body"><img src="/img/system/docs.png" class="front-img"/><span>Documentation</span><img src="/img/system/docs.png" class="back-img"/></div></div><section class="content-section"><div class="sidemenu"><div class="sidemenu-toggle"><img src="https://img.alicdn.com/tfs/TB1E6apXHGYBuNjy0FoXXciBFXa-200-200.png"/></div><ul><li class="menu-item menu-item-level-1"><span>Deployment Document</span><ul><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/en-us/docs/1.2.1/user_doc/hardware-environment.html" target="_self">Hareware Environment</a></li><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/en-us/docs/1.2.1/user_doc/backend-deployment.html" target="_self">Backend deploy</a></li><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/en-us/docs/1.2.1/user_doc/frontend-deployment.html" target="_self">Frontend deploy</a></li></ul></li><li class="menu-item menu-item-level-1"><span>User Manual</span><ul><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/en-us/docs/1.2.1/user_doc/quick-start.html" target="_self">Quick Start</a></li><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/en-us/docs/1.2.1/user_doc/system-manual.html" target="_self">User Manual</a></li><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/en-us/docs/1.2.1/user_doc/metadata-1.2.html" target="_self">Metadata</a></li></ul></li><li class="menu-item menu-item-level-1"><span>Api Document</span><ul><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="http://106.75.43.194:8888/dolphinscheduler/doc.html?language=en&amp;lang=en" target="_blank">Api Document</a></li></ul></li><li class="menu-item menu-item-level-1"><span>Upgrade</span><ul><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/en-us/docs/1.2.1/user_doc/upgrade.html" target="_self">Upgrade</a></li></ul></li><li class="menu-item menu-item-level-1"><span>FAQ</span><ul><li style="height:36px;overflow:hidden" class="menu-item menu-item-level-2"><a href="/en-us/docs/release/faq.html" target="_self">FAQ</a></li></ul></li></ul></div><div class="doc-content markdown-body"><h1>Foreword</h1>
<p>This document is a description of the dolphinscheduler configuration file, and the version is for dolphinscheduler-1.3.x.</p>
<h1>Directory Structure</h1>
<p>All configuration files of dolphinscheduler are currently in the [conf] directory.</p>
<p>For a more intuitive understanding of the location of the [conf] directory and the configuration files it contains, please see the simplified description of the dolphinscheduler installation directory below.</p>
<p>This article mainly talks about the configuration file of dolphinscheduler. I won't go into details in other parts.</p>
<p>[Note: The following dolphinscheduler is referred to as DS.]</p>
<pre><code>
├─bin                               DS command storage directory
│  ├─dolphinscheduler-daemon.sh         Activate/deactivate DS service script
│  ├─start-all.sh                       Start all DS services according to the configuration file
│  ├─stop-all.sh                        Close all DS services according to the configuration file
├─conf                              Configuration file directory
│  ├─application-api.properties         api service configuration file
│  ├─datasource.properties              Database configuration file
│  ├─zookeeper.properties               zookeeper configuration file
│  ├─master.properties                  Master service configuration file
│  ├─worker.properties                  Worker service configuration file
│  ├─quartz.properties                  Quartz service configuration file
│  ├─common.properties                  Public service [storage] configuration file
│  ├─alert.properties                   alert service configuration file
│  ├─config                             Environment variable configuration folder
│      ├─install_config.conf                DS environment variable configuration script [for DS installation/startup]
│  ├─env                                Run script environment variable configuration directory
│      ├─dolphinscheduler_env.sh            Run the script to load the environment variable configuration file [such as: JAVA_HOME, HADOOP_HOME, HIVE_HOME ...]
│  ├─org                                mybatis mapper file directory
│  ├─i18n                               i18n configuration file directory
│  ├─logback-api.xml                    api service log configuration file
│  ├─logback-master.xml                 Master service log configuration file
│  ├─logback-worker.xml                 Worker service log configuration file
│  ├─logback-alert.xml                  alert service log configuration file
├─sql                               DS metadata creation and upgrade sql file
│  ├─create                             Create SQL script directory
│  ├─upgrade                            Upgrade SQL script directory
│  ├─dolphinscheduler-postgre.sql       Postgre database initialization script
│  ├─dolphinscheduler_mysql.sql         mysql database initialization version
│  ├─soft_version                       Current DS version identification file
├─script                            DS service deployment, database creation/upgrade script directory
│  ├─create-dolphinscheduler.sh         DS database initialization script      
│  ├─upgrade-dolphinscheduler.sh        DS database upgrade script                
│  ├─monitor-server.sh                  DS service monitoring startup script               
│  ├─scp-hosts.sh                       Install file transfer script                                                    
│  ├─remove-zk-node.sh                  Clean Zookeeper cache file script       
├─ui                                Front-end WEB resource directory
├─lib                               DS dependent jar storage directory
├─install.sh                        Automatically install DS service script


</code></pre>
<h1>Detailed configuration file</h1>
<table>
<thead>
<tr>
<th>Serial number</th>
<th>Service classification</th>
<th>Configuration file</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>Activate/deactivate DS service script</td>
<td><a href="http://dolphinscheduler-daemon.sh">dolphinscheduler-daemon.sh</a></td>
</tr>
<tr>
<td>2</td>
<td>Database connection configuration</td>
<td>datasource.properties</td>
</tr>
<tr>
<td>3</td>
<td>Zookeeper connection configuration</td>
<td>zookeeper.properties</td>
</tr>
<tr>
<td>4</td>
<td>Common [storage] configuration</td>
<td>common.properties</td>
</tr>
<tr>
<td>5</td>
<td>API service configuration</td>
<td>application-api.properties</td>
</tr>
<tr>
<td>6</td>
<td>Master service configuration</td>
<td>master.properties</td>
</tr>
<tr>
<td>7</td>
<td>Worker service configuration</td>
<td>worker.properties</td>
</tr>
<tr>
<td>8</td>
<td>Alert service configuration</td>
<td>alert.properties</td>
</tr>
<tr>
<td>9</td>
<td>Quartz configuration</td>
<td>quartz.properties</td>
</tr>
<tr>
<td>10</td>
<td>DS environment variable configuration script [for DS installation/startup]</td>
<td>install_config.conf</td>
</tr>
<tr>
<td>11</td>
<td>Run the script to load the environment variable configuration file <br />[for example: JAVA_HOME,HADOOP_HOME, HIVE_HOME ...</td>
<td>dolphinscheduler_env.sh</td>
</tr>
<tr>
<td>12</td>
<td>Service log configuration files</td>
<td>api service log configuration file : logback-api.xml  <br /> Master service log configuration file  : logback-master.xml    <br /> Worker service log configuration file : logback-worker.xml  <br /> alertService log configuration file : logback-alert.xml</td>
</tr>
</tbody>
</table>
<h2><a href="http://1.dolphinscheduler-daemon.sh">1.dolphinscheduler-daemon.sh</a> [Activate/deactivate DS service script]</h2>
<p>The <a href="http://dolphinscheduler-daemon.sh">dolphinscheduler-daemon.sh</a> script is responsible for DS startup &amp; shutdown
<a href="http://start-all.sh/stop-all.sh">start-all.sh/stop-all.sh</a> eventually starts and shuts down the cluster through <a href="http://dolphinscheduler-daemon.sh">dolphinscheduler-daemon.sh</a>.
At present, DS has only made a basic setting. Please set the JVM parameters according to the actual situation of their resources.</p>
<p>The default simplified parameters are as follows:</p>
<pre><code class="language-bash"><span class="hljs-built_in">export</span> DOLPHINSCHEDULER_OPTS=<span class="hljs-string">"
-server 
-Xmx16g 
-Xms1g 
-Xss512k 
-XX:+UseConcMarkSweepGC 
-XX:+CMSParallelRemarkEnabled 
-XX:+UseFastAccessorMethods 
-XX:+UseCMSInitiatingOccupancyOnly 
-XX:CMSInitiatingOccupancyFraction=70
"</span>
</code></pre>
<blockquote>
<p>It is not recommended to set &quot;-XX:DisableExplicitGC&quot;, DS uses Netty for communication. Setting this parameter may cause memory leaks.</p>
</blockquote>
<h2>2.datasource.properties [Database Connectivity]</h2>
<p>Use Druid to manage the database connection in DS.The default simplified configuration is as follows.</p>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Defaults</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>spring.datasource.driver-class-name</td>
<td></td>
<td>Database driver</td>
</tr>
<tr>
<td>spring.datasource.url</td>
<td></td>
<td>Database connection address</td>
</tr>
<tr>
<td>spring.datasource.username</td>
<td></td>
<td>Database username</td>
</tr>
<tr>
<td>spring.datasource.password</td>
<td></td>
<td>Database password</td>
</tr>
<tr>
<td>spring.datasource.initialSize</td>
<td>5</td>
<td>Number of initial connection pools</td>
</tr>
<tr>
<td>spring.datasource.minIdle</td>
<td>5</td>
<td>Minimum number of connection pools</td>
</tr>
<tr>
<td>spring.datasource.maxActive</td>
<td>5</td>
<td>Maximum number of connection pools</td>
</tr>
<tr>
<td>spring.datasource.maxWait</td>
<td>60000</td>
<td>Maximum waiting time</td>
</tr>
<tr>
<td>spring.datasource.timeBetweenEvictionRunsMillis</td>
<td>60000</td>
<td>Connection detection cycle</td>
</tr>
<tr>
<td>spring.datasource.timeBetweenConnectErrorMillis</td>
<td>60000</td>
<td>Retry interval</td>
</tr>
<tr>
<td>spring.datasource.minEvictableIdleTimeMillis</td>
<td>300000</td>
<td>The minimum time a connection remains idle without being evicted</td>
</tr>
<tr>
<td>spring.datasource.validationQuery</td>
<td>SELECT 1</td>
<td>SQL to check whether the connection is valid</td>
</tr>
<tr>
<td>spring.datasource.validationQueryTimeout</td>
<td>3</td>
<td>Timeout to check if the connection is valid[seconds]</td>
</tr>
<tr>
<td>spring.datasource.testWhileIdle</td>
<td>true</td>
<td>Check when applying for connection, if idle time is greater than timeBetweenEvictionRunsMillis，Run validationQuery to check whether the connection is valid.</td>
</tr>
<tr>
<td>spring.datasource.testOnBorrow</td>
<td>true</td>
<td>Execute validationQuery to check whether the connection is valid when applying for connection</td>
</tr>
<tr>
<td>spring.datasource.testOnReturn</td>
<td>false</td>
<td>When returning the connection, execute validationQuery to check whether the connection is valid</td>
</tr>
<tr>
<td>spring.datasource.defaultAutoCommit</td>
<td>true</td>
<td>Whether to enable automatic submission</td>
</tr>
<tr>
<td>spring.datasource.keepAlive</td>
<td>true</td>
<td>For connections within the minIdle number in the connection pool, if the idle time exceeds minEvictableIdleTimeMillis, the keepAlive operation will be performed.</td>
</tr>
<tr>
<td>spring.datasource.poolPreparedStatements</td>
<td>true</td>
<td>Open PSCache</td>
</tr>
<tr>
<td>spring.datasource.maxPoolPreparedStatementPerConnectionSize</td>
<td>20</td>
<td>To enable PSCache, you must configure greater than 0, when greater than 0,PoolPreparedStatements automatically trigger modification to true.</td>
</tr>
</tbody>
</table>
<h2>3.zookeeper.properties [Zookeeper connection configuration]</h2>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Defaults</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>zookeeper.quorum</td>
<td>localhost:2181</td>
<td>zk cluster connection information</td>
</tr>
<tr>
<td>zookeeper.dolphinscheduler.root</td>
<td>/dolphinscheduler</td>
<td>DS stores root directory in zookeeper</td>
</tr>
<tr>
<td>zookeeper.session.timeout</td>
<td>60000</td>
<td>session time out</td>
</tr>
<tr>
<td>zookeeper.connection.timeout</td>
<td>30000</td>
<td>Connection timed out</td>
</tr>
<tr>
<td>zookeeper.retry.base.sleep</td>
<td>100</td>
<td>Basic retry time difference</td>
</tr>
<tr>
<td>zookeeper.retry.max.sleep</td>
<td>30000</td>
<td>Maximum retry time</td>
</tr>
<tr>
<td>zookeeper.retry.maxtime</td>
<td>10</td>
<td>Maximum number of retries</td>
</tr>
</tbody>
</table>
<h2>4.common.properties [hadoop, s3, yarn configuration]</h2>
<p>The common.properties configuration file is currently mainly used to configure hadoop/s3a related configurations.</p>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Defaults</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>resource.storage.type</td>
<td>NONE</td>
<td>Resource file storage type: HDFS,S3,NONE</td>
</tr>
<tr>
<td>resource.upload.path</td>
<td>/dolphinscheduler</td>
<td>Resource file storage path</td>
</tr>
<tr>
<td>data.basedir.path</td>
<td>/tmp/dolphinscheduler</td>
<td>Local working directory for storing temporary files</td>
</tr>
<tr>
<td>hadoop.security.authentication.startup.state</td>
<td>false</td>
<td>hadoop enable kerberos permission</td>
</tr>
<tr>
<td>java.security.krb5.conf.path</td>
<td>/opt/krb5.conf</td>
<td>kerberos configuration directory</td>
</tr>
<tr>
<td>login.user.keytab.username</td>
<td><a href="mailto:hdfs-mycluster@ESZ.COM">hdfs-mycluster@ESZ.COM</a></td>
<td>kerberos login user</td>
</tr>
<tr>
<td>login.user.keytab.path</td>
<td>/opt/hdfs.headless.keytab</td>
<td>kerberos login user keytab</td>
</tr>
<tr>
<td>resource.view.suffixs</td>
<td>txt,log,sh,conf,cfg,py,java,sql,hql,xml,properties</td>
<td>File formats supported by the resource center</td>
</tr>
<tr>
<td>hdfs.root.user</td>
<td>hdfs</td>
<td>If the storage type is HDFS, you need to configure users with corresponding operation permissions</td>
</tr>
<tr>
<td>fs.defaultFS</td>
<td>hdfs://mycluster:8020</td>
<td>Request address if resource.storage.type=S3 ,the value is similar to: s3a://dolphinscheduler. If resource.storage.type=HDFS, If hadoop configured HA, you need to copy the core-site.xml and hdfs-site.xml files to the conf directory</td>
</tr>
<tr>
<td>fs.s3a.endpoint</td>
<td></td>
<td>s3 endpoint address</td>
</tr>
<tr>
<td>fs.s3a.access.key</td>
<td></td>
<td>s3 access key</td>
</tr>
<tr>
<td>fs.s3a.secret.key</td>
<td></td>
<td>s3 secret key</td>
</tr>
<tr>
<td>yarn.resourcemanager.ha.rm.ids</td>
<td></td>
<td>yarn resourcemanager address, If the resourcemanager has HA turned on, enter the IP address of the HA (separated by commas). If the resourcemanager is a single node, the value can be empty.</td>
</tr>
<tr>
<td>yarn.application.status.address</td>
<td><a href="http://ds1:8088/ws/v1/cluster/apps/%25s">http://ds1:8088/ws/v1/cluster/apps/%s</a></td>
<td>If resourcemanager has HA enabled or resourcemanager is not used, keep the default value. If resourcemanager is a single node, you need to configure ds1 as the hostname corresponding to resourcemanager</td>
</tr>
<tr>
<td>dolphinscheduler.env.path</td>
<td>env/dolphinscheduler_env.sh</td>
<td>Run the script to load the environment variable configuration file [eg: JAVA_HOME, HADOOP_HOME, HIVE_HOME ...]</td>
</tr>
<tr>
<td>development.state</td>
<td>false</td>
<td>Is it in development mode</td>
</tr>
<tr>
<td>kerberos.expire.time</td>
<td>7</td>
<td>kerberos expiration time [hour]</td>
</tr>
</tbody>
</table>
<h2>5.application-api.properties [API service configuration]</h2>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Defaults</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>server.port</td>
<td>12345</td>
<td>API service communication port</td>
</tr>
<tr>
<td>server.servlet.session.timeout</td>
<td>7200</td>
<td>session timeout</td>
</tr>
<tr>
<td>server.servlet.context-path</td>
<td>/dolphinscheduler</td>
<td>Request path</td>
</tr>
<tr>
<td>spring.servlet.multipart.max-file-size</td>
<td>1024MB</td>
<td>Maximum upload file size</td>
</tr>
<tr>
<td>spring.servlet.multipart.max-request-size</td>
<td>1024MB</td>
<td>Maximum request size</td>
</tr>
<tr>
<td>server.jetty.max-http-post-size</td>
<td>5000000</td>
<td>Jetty service maximum send request size</td>
</tr>
<tr>
<td>spring.messages.encoding</td>
<td>UTF-8</td>
<td>Request encoding</td>
</tr>
<tr>
<td>spring.jackson.time-zone</td>
<td>GMT+8</td>
<td>Set time zone</td>
</tr>
<tr>
<td>spring.messages.basename</td>
<td>i18n/messages</td>
<td>i18n configuration</td>
</tr>
<tr>
<td>security.authentication.type</td>
<td>PASSWORD</td>
<td>Permission verification type</td>
</tr>
</tbody>
</table>
<h2>6.master.properties [Master service configuration]</h2>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Defaults</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>master.listen.port</td>
<td>5678</td>
<td>master communication port</td>
</tr>
<tr>
<td>master.exec.threads</td>
<td>100</td>
<td>Number of worker threads</td>
</tr>
<tr>
<td>master.exec.task.num</td>
<td>20</td>
<td>Number of parallel tasks</td>
</tr>
<tr>
<td>master.dispatch.task.num</td>
<td>3</td>
<td>Number of distribution tasks</td>
</tr>
<tr>
<td>master.heartbeat.interval</td>
<td>10</td>
<td>Heartbeat interval</td>
</tr>
<tr>
<td>master.task.commit.retryTimes</td>
<td>5</td>
<td>Number of task retries</td>
</tr>
<tr>
<td>master.task.commit.interval</td>
<td>1000</td>
<td>Task submission interval</td>
</tr>
<tr>
<td>master.max.cpuload.avg</td>
<td>-1</td>
<td>When the CPU is less than this configuration, the master service can work. The default value is -1 :  cpu cores * 2</td>
</tr>
<tr>
<td>master.reserved.memory</td>
<td>0.3</td>
<td>Memory threshold limit, the available memory is greater than this value, the master service can work.</td>
</tr>
</tbody>
</table>
<h2>7.worker.properties [Worker service configuration]</h2>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Defaults</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>worker.listen.port</td>
<td>1234</td>
<td>worker communication port</td>
</tr>
<tr>
<td>worker.exec.threads</td>
<td>100</td>
<td>Number of worker threads</td>
</tr>
<tr>
<td>worker.heartbeat.interval</td>
<td>10</td>
<td>Heartbeat interval</td>
</tr>
<tr>
<td>worker.max.cpuload.avg</td>
<td>-1</td>
<td>When the CPU is less than this configuration, the worker service can work. The default value is -1 :  cpu cores * 2</td>
</tr>
<tr>
<td>worker.reserved.memory</td>
<td>0.3</td>
<td>Memory threshold limit, the available memory is greater than this value, the worker service can work.</td>
</tr>
<tr>
<td>worker.group</td>
<td>default</td>
<td>Workgroup grouping configuration. <br> When the worker starts, it will automatically join the corresponding group according to the configuration.</td>
</tr>
</tbody>
</table>
<h2>8.alert.properties [Alert alert service configuration]</h2>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Defaults</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>alert.type</td>
<td>EMAIL</td>
<td>Alarm type</td>
</tr>
<tr>
<td>mail.protocol</td>
<td>SMTP</td>
<td>Mail server protocol</td>
</tr>
<tr>
<td>mail.server.host</td>
<td><a href="http://xxx.xxx.com">xxx.xxx.com</a></td>
<td>Mail server address</td>
</tr>
<tr>
<td>mail.server.port</td>
<td>25</td>
<td>Mail server port</td>
</tr>
<tr>
<td>mail.sender</td>
<td><a href="mailto:xxx@xxx.com">xxx@xxx.com</a></td>
<td>Sender mailbox</td>
</tr>
<tr>
<td>mail.user</td>
<td><a href="mailto:xxx@xxx.com">xxx@xxx.com</a></td>
<td>Sender's email name</td>
</tr>
<tr>
<td>mail.passwd</td>
<td>111111</td>
<td>Sender email password</td>
</tr>
<tr>
<td>mail.smtp.starttls.enable</td>
<td>true</td>
<td>Whether the mailbox opens tls</td>
</tr>
<tr>
<td>mail.smtp.ssl.enable</td>
<td>false</td>
<td>Whether the mailbox opens ssl</td>
</tr>
<tr>
<td>mail.smtp.ssl.trust</td>
<td><a href="http://xxx.xxx.com">xxx.xxx.com</a></td>
<td>Email ssl whitelist</td>
</tr>
<tr>
<td>xls.file.path</td>
<td>/tmp/xls</td>
<td>Temporary working directory for mailbox attachments</td>
</tr>
<tr>
<td></td>
<td>The following is the enterprise WeChat configuration[Optional]</td>
<td></td>
</tr>
<tr>
<td>enterprise.wechat.enable</td>
<td>false</td>
<td>Whether the enterprise WeChat is enabled</td>
</tr>
<tr>
<td><a href="http://enterprise.wechat.corp.id">enterprise.wechat.corp.id</a></td>
<td>xxxxxxx</td>
<td></td>
</tr>
<tr>
<td>enterprise.wechat.secret</td>
<td>xxxxxxx</td>
<td></td>
</tr>
<tr>
<td><a href="http://enterprise.wechat.agent.id">enterprise.wechat.agent.id</a></td>
<td>xxxxxxx</td>
<td></td>
</tr>
<tr>
<td>enterprise.wechat.users</td>
<td>xxxxxxx</td>
<td></td>
</tr>
<tr>
<td>enterprise.wechat.token.url</td>
<td><a href="https://qyapi.weixin.qq.com/cgi-bin/gettoken">https://qyapi.weixin.qq.com/cgi-bin/gettoken</a>?  <br /> corpid=corpId&corpsecret=secret</td>
<td></td>
</tr>
<tr>
<td>enterprise.wechat.push.url</td>
<td><a href="https://qyapi.weixin.qq.com/cgi-bin/message/send">https://qyapi.weixin.qq.com/cgi-bin/message/send</a>?  <br /> access_token=$token</td>
<td></td>
</tr>
<tr>
<td>enterprise.wechat.user.send.msg</td>
<td></td>
<td>Send message format</td>
</tr>
<tr>
<td>enterprise.wechat.team.send.msg</td>
<td></td>
<td>Group message format</td>
</tr>
<tr>
<td>plugin.dir</td>
<td>/Users/xx/your/path/to/plugin/dir</td>
<td>Plugin directory</td>
</tr>
</tbody>
</table>
<h2>9.quartz.properties [Quartz configuration]</h2>
<p>This is mainly quartz configuration, please configure it in combination with actual business scenarios &amp; resources, this article will not be expanded for the time being.</p>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Defaults</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>org.quartz.jobStore.driverDelegateClass</td>
<td>org.quartz.impl.jdbcjobstore.StdJDBCDelegate</td>
<td></td>
</tr>
<tr>
<td>org.quartz.jobStore.driverDelegateClass</td>
<td>org.quartz.impl.jdbcjobstore.PostgreSQLDelegate</td>
<td></td>
</tr>
<tr>
<td>org.quartz.scheduler.instanceName</td>
<td>DolphinScheduler</td>
<td></td>
</tr>
<tr>
<td>org.quartz.scheduler.instanceId</td>
<td>AUTO</td>
<td></td>
</tr>
<tr>
<td>org.quartz.scheduler.makeSchedulerThreadDaemon</td>
<td>true</td>
<td></td>
</tr>
<tr>
<td>org.quartz.jobStore.useProperties</td>
<td>false</td>
<td></td>
</tr>
<tr>
<td>org.quartz.threadPool.class</td>
<td>org.quartz.simpl.SimpleThreadPool</td>
<td></td>
</tr>
<tr>
<td>org.quartz.threadPool.makeThreadsDaemons</td>
<td>true</td>
<td></td>
</tr>
<tr>
<td>org.quartz.threadPool.threadCount</td>
<td>25</td>
<td></td>
</tr>
<tr>
<td>org.quartz.threadPool.threadPriority</td>
<td>5</td>
<td></td>
</tr>
<tr>
<td>org.quartz.jobStore.class</td>
<td>org.quartz.impl.jdbcjobstore.JobStoreTX</td>
<td></td>
</tr>
<tr>
<td>org.quartz.jobStore.tablePrefix</td>
<td>QRTZ_</td>
<td></td>
</tr>
<tr>
<td>org.quartz.jobStore.isClustered</td>
<td>true</td>
<td></td>
</tr>
<tr>
<td>org.quartz.jobStore.misfireThreshold</td>
<td>60000</td>
<td></td>
</tr>
<tr>
<td>org.quartz.jobStore.clusterCheckinInterval</td>
<td>5000</td>
<td></td>
</tr>
<tr>
<td>org.quartz.jobStore.acquireTriggersWithinLock</td>
<td>true</td>
<td></td>
</tr>
<tr>
<td>org.quartz.jobStore.dataSource</td>
<td>myDs</td>
<td></td>
</tr>
<tr>
<td>org.quartz.dataSource.myDs.connectionProvider.class</td>
<td>org.apache.dolphinscheduler.service.quartz.DruidConnectionProvider</td>
<td></td>
</tr>
</tbody>
</table>
<h2>10.install_config.conf [DS environment variable configuration script [for DS installation/startup]]</h2>
<p>The install_config.conf configuration file is more cumbersome.This file is mainly used in two places.</p>
<ul>
<li>1.Automatic installation of DS cluster.</li>
</ul>
<blockquote>
<p>Calling the <a href="http://install.sh">install.sh</a> script will automatically load the configuration in this file, and automatically configure the content in the above configuration file according to the content in this file.
Such as::dolphinscheduler-daemon.sh、datasource.properties、zookeeper.properties、common.properties、application-api.properties、master.properties、worker.properties、alert.properties、quartz.properties Etc..</p>
</blockquote>
<ul>
<li>2.DS cluster startup and shutdown.</li>
</ul>
<blockquote>
<p>When the DS cluster is started up and shut down, it will load the masters, workers, alertServer, apiServers and other parameters in the configuration file to start/close the DS cluster.</p>
</blockquote>
<p>The contents of the file are as follows:</p>
<pre><code class="language-bash">
<span class="hljs-comment"># Note: If the configuration file contains special characters,such as: `.*[]^${}\+?|()@#&amp;`, Please escape,</span>
<span class="hljs-comment">#      Examples: `[` Escape to `\[`</span>

<span class="hljs-comment"># Database type, currently only supports postgresql or mysql</span>
dbtype=<span class="hljs-string">"mysql"</span>

<span class="hljs-comment"># Database address &amp; port</span>
dbhost=<span class="hljs-string">"192.168.xx.xx:3306"</span>

<span class="hljs-comment"># Database Name</span>
dbname=<span class="hljs-string">"dolphinscheduler"</span>


<span class="hljs-comment"># Database Username</span>
username=<span class="hljs-string">"xx"</span>

<span class="hljs-comment"># Database Password</span>
password=<span class="hljs-string">"xx"</span>

<span class="hljs-comment"># Zookeeper address</span>
zkQuorum=<span class="hljs-string">"192.168.xx.xx:2181,192.168.xx.xx:2181,192.168.xx.xx:2181"</span>

<span class="hljs-comment"># Where to install DS, such as: /data1_1T/dolphinscheduler，</span>
installPath=<span class="hljs-string">"/data1_1T/dolphinscheduler"</span>

<span class="hljs-comment"># Which user to use for deployment</span>
<span class="hljs-comment"># Note: The deployment user needs sudo permissions and can operate hdfs.</span>
<span class="hljs-comment">#     If you use hdfs, the root directory must be created by the user. Otherwise, there will be permissions related issues.</span>
deployUser=<span class="hljs-string">"dolphinscheduler"</span>


<span class="hljs-comment"># The following is the alarm service configuration</span>
<span class="hljs-comment"># Mail server address</span>
mailServerHost=<span class="hljs-string">"smtp.exmail.qq.com"</span>

<span class="hljs-comment"># Mail Server Port</span>
mailServerPort=<span class="hljs-string">"25"</span>

<span class="hljs-comment"># Sender</span>
mailSender=<span class="hljs-string">"xxxxxxxxxx"</span>

<span class="hljs-comment"># Sending user</span>
mailUser=<span class="hljs-string">"xxxxxxxxxx"</span>

<span class="hljs-comment"># email Password</span>
mailPassword=<span class="hljs-string">"xxxxxxxxxx"</span>

<span class="hljs-comment"># TLS protocol mailbox is set to true, otherwise set to false</span>
starttlsEnable=<span class="hljs-string">"true"</span>

<span class="hljs-comment"># The mailbox with SSL protocol enabled is set to true, otherwise it is false. Note: starttlsEnable and sslEnable cannot be true at the same time</span>
sslEnable=<span class="hljs-string">"false"</span>

<span class="hljs-comment"># Mail service address value, same as mailServerHost</span>
sslTrust=<span class="hljs-string">"smtp.exmail.qq.com"</span>

<span class="hljs-comment">#Where to upload resource files such as sql used for business, you can set: HDFS, S3, NONE. If you want to upload to HDFS, please configure as HDFS; if you do not need the resource upload function, please select NONE.</span>
resourceStorageType=<span class="hljs-string">"NONE"</span>

<span class="hljs-comment"># if S3，write S3 address，HA，for example ：s3a://dolphinscheduler，</span>
<span class="hljs-comment"># Note，s3 be sure to create the root directory /dolphinscheduler</span>
defaultFS=<span class="hljs-string">"hdfs://mycluster:8020"</span>

<span class="hljs-comment"># If the resourceStorageType is S3, the parameters to be configured are as follows:</span>
s3Endpoint=<span class="hljs-string">"http://192.168.xx.xx:9010"</span>
s3AccessKey=<span class="hljs-string">"xxxxxxxxxx"</span>
s3SecretKey=<span class="hljs-string">"xxxxxxxxxx"</span>

<span class="hljs-comment"># If the ResourceManager is HA, configure it as the primary and secondary ip or hostname of the ResourceManager node, such as "192.168.xx.xx, 192.168.xx.xx", otherwise if it is a single ResourceManager or yarn is not used at all, please configure yarnHaIps="" That’s it, if yarn is not used, configure it as ""</span>
yarnHaIps=<span class="hljs-string">"192.168.xx.xx,192.168.xx.xx"</span>

<span class="hljs-comment"># If it is a single ResourceManager, configure it as the ResourceManager node ip or host name, otherwise keep the default value.</span>
singleYarnIp=<span class="hljs-string">"yarnIp1"</span>

<span class="hljs-comment"># The storage path of resource files in HDFS/S3</span>
resourceUploadPath=<span class="hljs-string">"/dolphinscheduler"</span>


<span class="hljs-comment"># HDFS/S3  Operating user</span>
hdfsRootUser=<span class="hljs-string">"hdfs"</span>

<span class="hljs-comment"># The following is the kerberos configuration</span>

<span class="hljs-comment"># Whether kerberos is turned on</span>
kerberosStartUp=<span class="hljs-string">"false"</span>
<span class="hljs-comment"># kdc krb5 config file path</span>
krb5ConfPath=<span class="hljs-string">"<span class="hljs-variable">$installPath</span>/conf/krb5.conf"</span>
<span class="hljs-comment"># keytab username</span>
keytabUserName=<span class="hljs-string">"hdfs-mycluster@ESZ.COM"</span>
<span class="hljs-comment"># username keytab path</span>
keytabPath=<span class="hljs-string">"<span class="hljs-variable">$installPath</span>/conf/hdfs.headless.keytab"</span>


<span class="hljs-comment"># api service port</span>
apiServerPort=<span class="hljs-string">"12345"</span>


<span class="hljs-comment"># Hostname of all hosts where DS is deployed</span>
ips=<span class="hljs-string">"ds1,ds2,ds3,ds4,ds5"</span>

<span class="hljs-comment"># ssh port, default 22</span>
sshPort=<span class="hljs-string">"22"</span>

<span class="hljs-comment"># Deploy master service host</span>
masters=<span class="hljs-string">"ds1,ds2"</span>

<span class="hljs-comment"># The host where the worker service is deployed</span>
<span class="hljs-comment"># Note: Each worker needs to set a worker group name, the default value is "default"</span>
workers=<span class="hljs-string">"ds1:default,ds2:default,ds3:default,ds4:default,ds5:default"</span>

<span class="hljs-comment">#  Deploy the alert service host</span>
alertServer=<span class="hljs-string">"ds3"</span>

<span class="hljs-comment"># Deploy api service host</span>
apiServers=<span class="hljs-string">"ds1"</span>
</code></pre>
<h2>11.dolphinscheduler_env.sh [Environment variable configuration]</h2>
<p>When submitting a task through a shell-like method, the environment variables in the configuration file are loaded into the host.
The types of tasks involved are: Shell tasks, Python tasks, Spark tasks, Flink tasks, Datax tasks, etc.</p>
<pre><code class="language-bash"><span class="hljs-built_in">export</span> HADOOP_HOME=/opt/soft/hadoop
<span class="hljs-built_in">export</span> HADOOP_CONF_DIR=/opt/soft/hadoop/etc/hadoop
<span class="hljs-built_in">export</span> SPARK_HOME1=/opt/soft/spark1
<span class="hljs-built_in">export</span> SPARK_HOME2=/opt/soft/spark2
<span class="hljs-built_in">export</span> PYTHON_HOME=/opt/soft/python
<span class="hljs-built_in">export</span> JAVA_HOME=/opt/soft/java
<span class="hljs-built_in">export</span> HIVE_HOME=/opt/soft/hive
<span class="hljs-built_in">export</span> FLINK_HOME=/opt/soft/flink
<span class="hljs-built_in">export</span> DATAX_HOME=/opt/soft/datax/bin/datax.py

<span class="hljs-built_in">export</span> PATH=<span class="hljs-variable">$HADOOP_HOME</span>/bin:<span class="hljs-variable">$SPARK_HOME1</span>/bin:<span class="hljs-variable">$SPARK_HOME2</span>/bin:<span class="hljs-variable">$PYTHON_HOME</span>:<span class="hljs-variable">$JAVA_HOME</span>/bin:<span class="hljs-variable">$HIVE_HOME</span>/bin:<span class="hljs-variable">$PATH</span>:<span class="hljs-variable">$FLINK_HOME</span>/bin:<span class="hljs-variable">$DATAX_HOME</span>:<span class="hljs-variable">$PATH</span>

</code></pre>
<h2>12.Service log configuration files</h2>
<table>
<thead>
<tr>
<th>Correspondence service</th>
<th>Log file name</th>
</tr>
</thead>
<tbody>
<tr>
<td>api service log configuration file</td>
<td>logback-api.xml</td>
</tr>
<tr>
<td>Master service log configuration file</td>
<td>logback-master.xml</td>
</tr>
<tr>
<td>Worker service log configuration file</td>
<td>logback-worker.xml</td>
</tr>
<tr>
<td>alert service log configuration file</td>
<td>logback-alert.xml</td>
</tr>
</tbody>
</table>
</div></section><footer class="footer-container"><div class="footer-body"><img src="/img/ds_gray.svg"/><div class="cols-container"><div class="col col-12"><h3>Disclaimer</h3><p>Apache DolphinScheduler (incubating) is an effort undergoing incubation at The Apache Software Foundation (ASF), sponsored by Incubator. 
Incubation is required of all newly accepted projects until a further review indicates 
that the infrastructure, communications, and decision making process have stabilized in a manner consistent with other successful ASF projects. 
While incubation status is not necessarily a reflection of the completeness or stability of the code, 
it does indicate that the project has yet to be fully endorsed by the ASF.</p></div><div class="col col-6"><dl><dt>Documentation</dt><dd><a href="/en-us/docs/development/architecture-design.html" target="_self">Overview</a></dd><dd><a href="/en-us/docs/1.3.4/user_doc/quick-start.html" target="_self">Quick start</a></dd><dd><a href="/en-us/docs/development/backend-development.html" target="_self">Developer guide</a></dd></dl></div><div class="col col-6"><dl><dt>ASF</dt><dd><a href="http://www.apache.org" target="_self">Foundation</a></dd><dd><a href="http://www.apache.org/licenses/" target="_self">License</a></dd><dd><a href="http://www.apache.org/events/current-event" target="_self">Events</a></dd><dd><a href="http://www.apache.org/foundation/sponsorship.html" target="_self">Sponsorship</a></dd><dd><a href="http://www.apache.org/foundation/thanks.html" target="_self">Thanks</a></dd></dl></div></div><div class="copyright"><span>Copyright © 2018-2020 The Apache Software Foundation. Apache DolphinScheduler, DolphinScheduler, and its feather logo are trademarks of The Apache Software Foundation.</span></div></div></footer></div></div>
	<script src="https://f.alicdn.com/react/15.4.1/react-with-addons.min.js"></script>
	<script src="https://f.alicdn.com/react/15.4.1/react-dom.min.js"></script>
	<script>window.rootPath = '';</script>
	<script src="/build/documentation.md.js"></script>
	<script>
	  var _hmt = _hmt || [];
	  (function() {
		var hm = document.createElement("script");
		hm.src = "https://hm.baidu.com/hm.js?4e7b4b400dd31fa015018a435c64d06f";
		var s = document.getElementsByTagName("script")[0];
		s.parentNode.insertBefore(hm, s);
	  })();
	</script>
</body>
</html>