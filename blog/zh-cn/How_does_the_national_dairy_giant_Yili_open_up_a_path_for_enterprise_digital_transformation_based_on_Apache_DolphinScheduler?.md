```yaml
title: 国民乳业巨头伊利如何基于 DolphinScheduler 开辟企业数字化转型“蹊径”？
keywords: Apache DolphinScheduler, 伊利, 数字化转型
description: 在数据驱动转型的过程中，会存在海量的数据集成任务，整体集成架构的合理性、调度的稳定性会严重影响数据流转的效率，也会制约数据的价值挖掘，伊利基于 Apache DolphinScheduler 构建了统一的调度服务与数据集成体系，加速数据流转，助力企业数字化转型。
```

![](/img/2023-10-11/1.png)

## 精彩回顾

近期，国民乳业巨头伊利集团在社区线上 Meetup 上带来了《伊利集团基于 DolphinScheduler 的探索与实践》。


伊利集团数字化中心统筹推进全集团的数字化转型工作，姜涛及其团队在数字化中心负责大数据技术能力的建设以及相关的业务支持工作。在数据驱动转型的过程中，会存在海量的数据集成任务，整体集成架构的合理性、调度的稳定性会严重影响数据流转的效率，也会制约数据的价值挖掘，伊利基于 Apache DolphinScheduler 构建了统一的调度服务与数据集成体系，加速数据流转，助力企业数字化转型。


## 作者简介

姜涛 

伊利集团 数字化中心 数据技术经理

**演讲大纲：**

背景与应用情况介绍
实践&探索
未来的规划
关于开源的思考

## 背景与应用情况介绍

### 伊利介绍

大家对伊利并不陌生，每年有13亿的国民消费者品尝过伊利的产品，平均每天有1亿包商品被消费者喝掉。伊利的业务起点可以追溯到一棵草的培育、一头牛的养殖、一杯奶的生产，最后经过复杂的供应链体系送到消费者手里，业务横跨一、二、三产业。

### 应用背景介绍

庞大的业务体量背后是复杂的应用矩阵，这对我们技术架构提出了很大的挑战。

**应用的多云分布现状，使跨云的数据搬迁与多云统一调度成为刚需**

![](/img/2023-10-11/2.png)

如今，伊利在同云服务商的合作过程中，不仅会考虑云服务商所提供的 Iaas、Paas 能力，还会考虑其背后的生态，如私域生态、电商、物流等等，所以我们的应用天然分散在多云之上，应用产生的数据也分散在多云之上，当下集中式的数据架构需要大量的数据物理搬迁。我们每日需要迁移 8000 张表，涉及 80 多个系统，在这种情况下，稳定、可扩展的多云数据集成能力就十分重要。

统一技术架构来对抗熵增，降本增效

第一个挑战是海量的搬迁需求对数据集成和调度能力易用性、稳定性、扩展性的挑战。而第二个挑战来源于大量的应用落地所带来的熵增效应，在技术资源有限的情况下，我们很难去有效控制我们的成本，并提高我们的效率，尤其我们在面对数据集成与调度的这个场景，有以下几个核心问题：


**同类工具产品重复建设：**因为缺少统一规划，导致同类功能产品存在重复建设。

**技术选型杂：**AirFlow、Azkaban、Oozie、 自研调度等。

**建设及衍生成本高：**多技术栈的人员资源储备、运维、使用培训等成本。

**扩展性问题：**本地化个性需求的扩展性支持。}

在引入 Apache DolphinScheduler 之前，我们在调度和数据集成的场景中，整体的技术架构是不统一的。为了满足我们内部的刚性需求，同时从扩展性、稳定性等维度考量，我们计划建设统一的调度&数据集成服务体系。在调研了大量调度产品后，我们决定基于 Apache DolphinScheduler 作为我们的核心引擎，并在此之上进行本地化的改造，去满足我们的需求。

### 伊利大数据调度服务平台定位&应用现状

在技术资源有限的情况下，去发起一个工具产品的研发并不容易，我们要思考清楚：谁是我们的核心用户？这个工具产品的核心定位是什么？支撑的场景有哪些？

经过充分的调研，我们明确了这个工具产品的核心定位，他不是一个简单的工作流调度平台，是满足伊利多云业务场景的一体化数据开发平台，同时，以一个轻量化的工具，面向数据、应用开发人员，支持内外部的数据集成、应用侧分布式调度需求、以及数据任务的可视化编排和调度。

从伊利目前的应用情况来看，日调度任务数达到了 1.3 万个，集群规模 15 个节点，每日搬迁表8000+。

![](/img/2023-10-11/3.png)

从上面的架构图可以看到，我们在多云大数据基础设施之上，构建了一个统一的数据集成、开发、调度和运维的数据平台，通过这个平台，去屏蔽多云大数据平台的差异性，为用户提供统一的开发体验。

**伊利大数据调度服务平台系统总览**

![](/img/2023-10-11/4.png)

我们对 2.0.2 版本的 DolphinScheduler 的整个模型做了重新抽象，项目作为最顶层的模型，同时抽象了资源、角色、工具三个概念，并绑定到项目里。其中工具集合是最重要的，所有数据开发过程中会用到的工具都会在这里去扩展，用户在平台内通过授权项目，即可完成数据集成、开发、运维、资产管理等工作。同时，我们将 Apache DolphinScheduler 的租户与大数据平台租户做了融合打通，通过大数据平台侧 Ranger+Ldap+Kerberos 的租户管理体系完成资源配额、权限的细粒度管理。

## 实践&探索

我们基于 Apache DolphinScheduler 2.0.2 版本做了三次迭代，迭代了很多的功能，但是有一个主线逻辑贯穿我们的产品设计和研发过程，那就是以满足用户的核心需求去建设新功能，以提升用户体验去优化旧功能，让产品上手容易、低门槛、平民化、动线合理。

![](/img/2023-10-11/5.png)


### 面向场景的数据集成

何为面向场景的数据集成？我们的产品完全开放给用户使用，开发人员在做数据集成时，有非常明确的上下文，比如把 Mysql 的数据同步到 Hive，把 ES 的数据同步到 StarRocks 等。所以，我们提供了大量的集成组件，可以基于配置化的方式，完成集成的工作。全过程 0 代码，提升了数据集成开发的效率。

在未规划数据集成的核心功能前，我们面临着以下几个痛点：

1.  多种数据集成组件或技术让用户难以选择
    
2.  技术架构不统一导致维护成本增加
    
3.  数据集成任务配置繁琐
    
4.  二次开发扩展性较差
    

针对这四个痛点，我们分别给出了对应的策略：

1.  只给用户一个最好的选择：多种选择往往无法选择，那干脆只提供一个最好的
    
2.  基于 DataX 统一数据集成架构，优化资源问题，降低运维成本
    
3.  面向业务应用时，通过模板生成器生成任务模板 ，简化操作
    
4.  合理的代码设计
    

### 轻量化的资产管理 

![](/img/2023-10-11/6.png)

这个功能所对应的核心诉求是这样的，应用基于原生大数据能力去构建轻量化数仓时，需要去清晰的洞察技术元数据信息，包括库、表、字段、基础属性信息，同时，需要对表打一些业务标签信息，包括主题域、主题等，方便分析人员使用数据，基于这样的诉求我们在平台上扩展了这个轻量化的资产管理功能。

**正逆向建表是核心功能**，正向建表是指支持用户在平台上创建表模型，并将表模型物化到大数据平台上。而逆向建表用的更多，很多时候用户还是以传统的开发方法， 通过ETL服务器上写脚本，提交到大数据平台上做计算，这个时候表已经提前存在了，而不是通过可视化的方式创建的，那逆向建表就是自动扫描元数据，并注册到资产平台上。

资产检索是面向开发和业务分析提供了资产检索的功能，可以按照主题域、标签、字段名等进行轻量化检索，展示资产卡片和上下游血缘信息。



### 多云任务调度

多云任务调度是为了解决跨云平台的一体化调度问题，如前边所讲，伊利的应用多云分布，而这个功能可以基于一张画布完成跨云任务编排，我们基于 Apache DolphinScheduler 做了一些扩展改造，灵活运用环境与 worker 组的绑定关系，同时大数据基础设施侧解决 Kerberos 跨域、多集群 Keytab 互信的问题。

![](/img/2023-10-11/7.png)

如示例所示，我们可以在不同的云上分别触发数据集成的任务，包括数据处理任务。处理完成之后，在另外一朵云上触发数据计算和面向业务应用的计划编排，最后提供数据服务，通过这种方式实现多云调度。


### 监控看板优化 

我们在原有 Apache DolphinScheduler 看板的基础上，做了优化和升级，面向运维侧，构建了运维工作所关注的核心指标，并将指标做了可视化展示。

整个监控看板分为**任务监控和集群服务监控**。

对于任务监控，我们设计的关键指标包括项目数、工作流（上线/未上线）、应调度任务数、已成功调度任务数、分小时运行情况概览、运行失败统计 TOP5、运行时长统计 TOP5 等。

![](/img/2023-10-11/8.png)

对于服务监控，关键指标包括 CPU、内存、平均负载、各云环境 worker 负载，分小时 worker 运行情况概览等。

![](/img/2023-10-11/9.png)


### 体验升级优化

接下来是体验上的升级优化，比如用户定时配置步骤优化，整体布局优化等。核心的出发点还是优化用户的使用体验，降低使用门槛。

![](/img/2023-10-11/10.png)


## 未来规划

最后是我们团队关于 DolphinScheduler 的未来规划。



### 长期规划

从长远来看，不管是社区，还是我们公司内部，都需要对于 DolphinScheduler 有一个清晰的定位，即它不是一个简单的工作流调度平台，而是一个一站式的智能数据开发平台，这个数据开发平台至少具备三个重要的特点：

![](/img/2023-10-11/11.png)

1.  多云统一：可以与去中心化的新型数据架构完美契合，这是一个非常重要的方向；
    
2.  低代码：从用户角度来说，可以支持全链路一站式可视化建模、开发、分析体验；
    
3.  智能化的管理：现在的数据架构基于降低数据管理复杂度为出发点，基于元数据驱动治理，实现数据质量管理智能化，也会是一个很大的命题。
    



### 短中期规划

短期来看，我们即将着手三点：

1.  云原生的结合：DolphinScheduler 社区已提供基于 k8S 部署服务，所以我们的 master、worker 等服将务基于容器化进行改造；
    
2.  引入测试、上线流程：在项目内添加开发者、审核者等角色，同时对上线动作进行管控，上线后元数据自动同步；
    
3.  质量模块：DolphinScheduler 3.0 已经加入了数据质量模块，我们将整合这一部分，并进行本地化拓展，包括对数据质量预定义、稽核，引入数据血缘等
    


## 开源的思考

![](/img/2023-10-11/12.png)

伊利引入 DolphinScheduler，与开源产品共同成长。在这个过程中，我们有了一些关于协同的思考，企业内部与开源之间要构建良好的协同方式非常重要。

我们内部会指派专人跟进开源社区的动态，研发团队会主动发现 Bug 并提交给社区，并修复后提交 PR。

同时，我们也会积极地与社区互动，通过周、月会查看社区动向。对于技术研发资源有限的企业，应该去找一个契合企业内部实际使用情况的开源产品，要真正理解并把开源精神落到实处。开源的力量非常强大，可以解决很多内部根本无法解决的问题，也会发现内部不会发现的问题。所以，企业内部需要把参与开源的流程落到实处，与社区共同成长。

我的分享就到这里，感谢！