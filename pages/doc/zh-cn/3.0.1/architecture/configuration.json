{
  "__html": "<!-- markdown-link-check-disable -->\n<h1 id=\"前言\">前言</h1>\n<p>本文档为dolphinscheduler配置文件说明文档。</p>\n<h1 id=\"目录结构\">目录结构</h1>\n<p>DolphinScheduler的目录结构如下：</p>\n<pre><code>├── LICENSE\n│\n├── NOTICE\n│\n├── licenses                                    licenses存放目录\n│\n├── bin                                         DolphinScheduler命令和环境变量配置存放目录 \n│   ├── dolphinscheduler-daemon.sh              启动/关闭DolphinScheduler服务脚本\n│   ├── env                                     环境变量配置存放目录\n│   │   ├── dolphinscheduler_env.sh             当使用`dolphinscheduler-daemon.sh`脚本起停服务时，运行此脚本加载环境变量配置文件 [如：JAVA_HOME,HADOOP_HOME, HIVE_HOME ...] \n│   │   └── install_env.sh                      当使用`install.sh` `start-all.sh` `stop-all.sh` `status-all.sh`脚本时，运行此脚本为DolphinScheduler安装加载环境变量配置 \n│   ├── install.sh                              当使用`集群`模式或`伪集群`模式部署DolphinScheduler时，运行此脚本自动安装服务  \n│   ├── remove-zk-node.sh                       清理zookeeper缓存文件脚本 \n│   ├── scp-hosts.sh                            安装文件传输脚本\n│   ├── start-all.sh                            当使用`集群`模式或`伪集群`模式部署DolphinScheduler时，运行此脚本启动所有服务\n│   ├── status-all.sh                           当使用`集群`模式或`伪集群`模式部署DolphinScheduler时，运行此脚本获取所有服务状态\n│   └── stop-all.sh                             当使用`集群`模式或`伪集群`模式部署DolphinScheduler时，运行此脚本终止所有服务\n│\n├── alert-server                                DolphinScheduler alert-server命令、配置和依赖存放目录\n│   ├── bin\n│   │   └── start.sh                            DolphinScheduler alert-server启动脚本\n│   ├── conf\n│   │   ├── application.yaml                    alert-server配置文件\n│   │   ├── common.properties                   公共服务（存储等信息）配置文件 \n│   │   ├── dolphinscheduler_env.sh             alert-server环境变量配置加载脚本\n│   │   └── logback-spring.xml                  alert-service日志配置文件\n│   └── libs                                    alert-server依赖jar包存放目录\n│\n├── api-server                                  DolphinScheduler api-server命令、配置和依赖存放目录\n│   ├── bin\n│   │   └── start.sh                            DolphinScheduler api-server启动脚本\n│   ├── conf\n│   │   ├── application.yaml                    api-server配置文件\n│   │   ├── common.properties                   公共服务（存储等信息）配置文件\n│   │   ├── dolphinscheduler_env.sh             api-server环境变量配置加载脚本\n│   │   └── logback-spring.xml                  api-service日志配置文件\n│   ├── libs                                    api-server依赖jar包存放目录\n│   └── ui                                      api-server相关前端WEB资源存放目录 \n│\n├── master-server                               DolphinScheduler master-server命令、配置和依赖存放目录\n│   ├── bin                                \n│   │   └── start.sh                            DolphinScheduler master-server启动脚本\n│   ├── conf\n│   │   ├── application.yaml                    master-server配置文件\n│   │   ├── common.properties                   公共服务（存储等信息）配置文件\n│   │   ├── dolphinscheduler_env.sh             master-server环境变量配置加载脚本\n│   │   └── logback-spring.xml                  master-service日志配置文件\n│   └── libs                                    master-server依赖jar包存放目录\n│\n├── standalone-server                           DolphinScheduler standalone-server命令、配置和依赖存放目录\n│   ├── bin\n│   │   └── start.sh                            DolphinScheduler standalone-server启动脚本\n│   ├── conf\n│   │   ├── application.yaml                    standalone-server配置文件\n│   │   ├── common.properties                   公共服务（存储等信息）配置文件\n│   │   ├── dolphinscheduler_env.sh             standalone-server环境变量配置加载脚本\n│   │   ├── logback-spring.xml                  standalone-service日志配置文件\n│   │   └── sql                                 DolphinScheduler元数据创建/升级sql文件\n│   ├── libs                                    standalone-server依赖jar包存放目录\n│   └── ui                                      standalone-server相关前端WEB资源存放目录\n│       \n├── tools                                       DolphinScheduler元数据工具命令、配置和依赖存放目录\n│   ├── bin\n│   │   └── upgrade-schema.sh                   DolphinScheduler元数据创建/升级脚本\n│   ├── conf\n│   │   ├── application.yaml                    元数据工具配置文件\n│   │   └── common.properties                   公共服务（存储等信息）配置文件\n│   ├── libs                                    元数据工具依赖jar包存放目录\n│   └── sql                                     DolphinScheduler元数据创建/升级sql文件\n│     \n├── worker-server                               DolphinScheduler worker-server命令、配置和依赖存放目录\n│       ├── bin\n│       │   └── start.sh                        DolphinScheduler worker-server启动脚本\n│       ├── conf\n│       │   ├── application.yaml                worker-server配置文件\n│       │   ├── common.properties               公共服务（存储等信息）配置文件\n│       │   ├── dolphinscheduler_env.sh         worker-server环境变量配置加载脚本\n│       │   └── logback-spring.xml              worker-service日志配置文件\n│       └── libs                                worker-server依赖jar包存放目录\n│\n└── ui                                          前端WEB资源目录\n</code></pre>\n<h1 id=\"配置文件详解\">配置文件详解</h1>\n<h2 id=\"dolphinscheduler-daemon.sh-[启动/关闭dolphinscheduler服务脚本]\">dolphinscheduler-daemon.sh [启动/关闭DolphinScheduler服务脚本]</h2>\n<p>dolphinscheduler-daemon.sh脚本负责DolphinScheduler的启动&amp;关闭.\nstart-all.sh/stop-all.sh最终也是通过dolphinscheduler-daemon.sh对集群进行启动/关闭操作.\n目前DolphinScheduler只是做了一个基本的设置,JVM参数请根据各自资源的实际情况自行设置.</p>\n<p>默认简化参数如下:</p>\n<pre><code class=\"language-bash\"><span class=\"hljs-built_in\">export</span> DOLPHINSCHEDULER_OPTS=<span class=\"hljs-string\">&quot;\n-server \n-Xmx16g \n-Xms1g \n-Xss512k \n-XX:+UseConcMarkSweepGC \n-XX:+CMSParallelRemarkEnabled \n-XX:+UseFastAccessorMethods \n-XX:+UseCMSInitiatingOccupancyOnly \n-XX:CMSInitiatingOccupancyFraction=70\n&quot;</span>\n</code></pre>\n<blockquote>\n<p>不建议设置&quot;-XX:DisableExplicitGC&quot; , DolphinScheduler使用Netty进行通讯,设置该参数,可能会导致内存泄漏.</p>\n</blockquote>\n<h2 id=\"数据库连接相关配置\">数据库连接相关配置</h2>\n<p>在DolphinScheduler中使用Spring Hikari对数据库连接进行管理，配置文件位置：</p>\n<table>\n<thead>\n<tr>\n<th>服务名称</th>\n<th>配置文件</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Master Server</td>\n<td><code>master-server/conf/application.yaml</code></td>\n</tr>\n<tr>\n<td>Api Server</td>\n<td><code>api-server/conf/application.yaml</code></td>\n</tr>\n<tr>\n<td>Worker Server</td>\n<td><code>worker-server/conf/application.yaml</code></td>\n</tr>\n<tr>\n<td>Alert Server</td>\n<td><code>alert-server/conf/application.yaml</code></td>\n</tr>\n</tbody>\n</table>\n<p>默认配置如下：</p>\n<table>\n<thead>\n<tr>\n<th>参数</th>\n<th>默认值</th>\n<th>描述</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>spring.datasource.driver-class-name</td>\n<td>org.postgresql.Driver</td>\n<td>数据库驱动</td>\n</tr>\n<tr>\n<td>spring.datasource.url</td>\n<td>jdbc:postgresql://127.0.0.1:5432/dolphinscheduler</td>\n<td>数据库连接地址</td>\n</tr>\n<tr>\n<td>spring.datasource.username</td>\n<td>root</td>\n<td>数据库用户名</td>\n</tr>\n<tr>\n<td>spring.datasource.password</td>\n<td>root</td>\n<td>数据库密码</td>\n</tr>\n<tr>\n<td>spring.datasource.hikari.connection-test-query</td>\n<td>select 1</td>\n<td>检测连接是否有效的sql</td>\n</tr>\n<tr>\n<td>spring.datasource.hikari.minimum-idle</td>\n<td>5</td>\n<td>最小空闲连接池数量</td>\n</tr>\n<tr>\n<td>spring.datasource.hikari.auto-commit</td>\n<td>true</td>\n<td>是否自动提交</td>\n</tr>\n<tr>\n<td>spring.datasource.hikari.pool-name</td>\n<td>DolphinScheduler</td>\n<td>连接池名称</td>\n</tr>\n<tr>\n<td>spring.datasource.hikari.maximum-pool-size</td>\n<td>50</td>\n<td>连接池最大连接数</td>\n</tr>\n<tr>\n<td>spring.datasource.hikari.connection-timeout</td>\n<td>30000</td>\n<td>连接超时时长</td>\n</tr>\n<tr>\n<td>spring.datasource.hikari.idle-timeout</td>\n<td>600000</td>\n<td>空闲连接存活最大时间</td>\n</tr>\n<tr>\n<td>spring.datasource.hikari.leak-detection-threshold</td>\n<td>0</td>\n<td>连接泄露检测阈值</td>\n</tr>\n<tr>\n<td>spring.datasource.hikari.initialization-fail-timeout</td>\n<td>1</td>\n<td>连接池初始化失败timeout</td>\n</tr>\n</tbody>\n</table>\n<p>DolphinScheduler同样可以通过<code>bin/env/dolphinscheduler_env.sh</code>进行数据库连接相关的配置。</p>\n<h2 id=\"zookeeper相关配置\">Zookeeper相关配置</h2>\n<p>DolphinScheduler使用Zookeeper进行集群管理、容错、事件监听等功能，配置文件位置：</p>\n<table>\n<thead>\n<tr>\n<th>服务名称</th>\n<th>配置文件</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Master Server</td>\n<td><code>master-server/conf/application.yaml</code></td>\n</tr>\n<tr>\n<td>Api Server</td>\n<td><code>api-server/conf/application.yaml</code></td>\n</tr>\n<tr>\n<td>Worker Server</td>\n<td><code>worker-server/conf/application.yaml</code></td>\n</tr>\n</tbody>\n</table>\n<p>默认配置如下：</p>\n<table>\n<thead>\n<tr>\n<th>参数</th>\n<th>默认值</th>\n<th>描述</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>registry.zookeeper.namespace</td>\n<td>dolphinscheduler</td>\n<td>Zookeeper集群使用的namespace</td>\n</tr>\n<tr>\n<td>registry.zookeeper.connect-string</td>\n<td>localhost:2181</td>\n<td>Zookeeper集群连接信息</td>\n</tr>\n<tr>\n<td>registry.zookeeper.retry-policy.base-sleep-time</td>\n<td>60ms</td>\n<td>基本重试时间差</td>\n</tr>\n<tr>\n<td>registry.zookeeper.retry-policy.max-sleep</td>\n<td>300ms</td>\n<td>最大重试时间</td>\n</tr>\n<tr>\n<td>registry.zookeeper.retry-policy.max-retries</td>\n<td>5</td>\n<td>最大重试次数</td>\n</tr>\n<tr>\n<td>registry.zookeeper.session-timeout</td>\n<td>30s</td>\n<td>session超时时间</td>\n</tr>\n<tr>\n<td>registry.zookeeper.connection-timeout</td>\n<td>30s</td>\n<td>连接超时时间</td>\n</tr>\n<tr>\n<td>registry.zookeeper.block-until-connected</td>\n<td>600ms</td>\n<td>阻塞直到连接成功的等待时间</td>\n</tr>\n<tr>\n<td>registry.zookeeper.digest</td>\n<td>{用户名:密码}</td>\n<td>如果zookeeper打开了acl，则需要填写认证信息访问znode，认证信息格式为{用户名}:{密码}。关于Zookeeper ACL详见[https://zookeeper.apache.org/doc/r3.4.14/zookeeperAdmin.html](Apache Zookeeper官方文档)</td>\n</tr>\n</tbody>\n</table>\n<p>DolphinScheduler同样可以通过<code>bin/env/dolphinscheduler_env.sh</code>进行Zookeeper相关的配置。</p>\n<h2 id=\"4.common.properties-[hadoop、s3、yarn配置]\">4.common.properties [hadoop、s3、yarn配置]</h2>\n<p>common.properties配置文件目前主要是配置hadoop/s3a相关的配置.</p>\n<table>\n<thead>\n<tr>\n<th>参数</th>\n<th>默认值</th>\n<th>描述</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>data.basedir.path</td>\n<td>/tmp/dolphinscheduler</td>\n<td>本地工作目录,用于存放临时文件</td>\n</tr>\n<tr>\n<td>resource.storage.type</td>\n<td>NONE</td>\n<td>资源文件存储类型: HDFS,S3,NONE</td>\n</tr>\n<tr>\n<td>resource.storage.upload.base.path</td>\n<td>/dolphinscheduler</td>\n<td>资源文件存储路径</td>\n</tr>\n<tr>\n<td>resource.aws.access.key.id</td>\n<td>minioadmin</td>\n<td>S3 access key</td>\n</tr>\n<tr>\n<td>resource.aws.secret.access.key</td>\n<td>minioadmin</td>\n<td>S3 secret access key</td>\n</tr>\n<tr>\n<td>resource.aws.region</td>\n<td>us-east-1</td>\n<td>S3 区域</td>\n</tr>\n<tr>\n<td>resource.aws.s3.bucket.name</td>\n<td>dolphinscheduler</td>\n<td>S3 存储桶名称</td>\n</tr>\n<tr>\n<td>resource.aws.s3.endpoint</td>\n<td>http://minio:9000</td>\n<td>s3 endpoint地址</td>\n</tr>\n<tr>\n<td>resource.hdfs.root.user</td>\n<td>hdfs</td>\n<td>如果存储类型为HDFS,需要配置拥有对应操作权限的用户</td>\n</tr>\n<tr>\n<td>resource.hdfs.fs.defaultFS</td>\n<td>hdfs://mycluster:8020</td>\n<td>请求地址如果resource.storage.type=S3,该值类似为: s3a://dolphinscheduler. 如果resource.storage.type=HDFS, 如果 hadoop 配置了 HA,需要复制core-site.xml 和 hdfs-site.xml 文件到conf目录</td>\n</tr>\n<tr>\n<td>hadoop.security.authentication.startup.state</td>\n<td>false</td>\n<td>hadoop是否开启kerberos权限</td>\n</tr>\n<tr>\n<td>java.security.krb5.conf.path</td>\n<td>/opt/krb5.conf</td>\n<td>kerberos配置目录</td>\n</tr>\n<tr>\n<td>login.user.keytab.username</td>\n<td>hdfs-mycluster@ESZ.COM</td>\n<td>kerberos登录用户</td>\n</tr>\n<tr>\n<td>login.user.keytab.path</td>\n<td>/opt/hdfs.headless.keytab</td>\n<td>kerberos登录用户keytab</td>\n</tr>\n<tr>\n<td>kerberos.expire.time</td>\n<td>2</td>\n<td>kerberos过期时间,整数,单位为小时</td>\n</tr>\n<tr>\n<td>yarn.resourcemanager.ha.rm.ids</td>\n<td></td>\n<td>yarn resourcemanager 地址, 如果resourcemanager开启了HA, 输入HA的IP地址(以逗号分隔),如果resourcemanager为单节点, 该值为空即可</td>\n</tr>\n<tr>\n<td>yarn.application.status.address</td>\n<td>http://ds1:8088/ws/v1/cluster/apps/%s</td>\n<td>如果resourcemanager开启了HA或者没有使用resourcemanager,保持默认值即可. 如果resourcemanager为单节点,你需要将ds1 配置为resourcemanager对应的hostname</td>\n</tr>\n<tr>\n<td>dolphinscheduler.env.path</td>\n<td>env/dolphinscheduler_env.sh</td>\n<td>运行脚本加载环境变量配置文件[如: JAVA_HOME,HADOOP_HOME, HIVE_HOME ...]</td>\n</tr>\n<tr>\n<td>development.state</td>\n<td>false</td>\n<td>是否处于开发模式</td>\n</tr>\n<tr>\n<td>task.resource.limit.state</td>\n<td>false</td>\n<td>是否启用资源限制模式</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"5.application-api.properties-[api服务配置]\">5.application-api.properties [API服务配置]</h2>\n<table>\n<thead>\n<tr>\n<th>参数</th>\n<th>默认值</th>\n<th>描述</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>data.basedir.path</td>\n<td>/tmp/dolphinscheduler</td>\n<td>本地工作目录,用于存放临时文件</td>\n</tr>\n<tr>\n<td>resource.storage.type</td>\n<td>NONE</td>\n<td>资源文件存储类型: HDFS,S3,NONE</td>\n</tr>\n<tr>\n<td>resource.upload.path</td>\n<td>/dolphinscheduler</td>\n<td>资源文件存储路径</td>\n</tr>\n<tr>\n<td>aws.access.key.id</td>\n<td>minioadmin</td>\n<td>S3 access key</td>\n</tr>\n<tr>\n<td>aws.secret.access.key</td>\n<td>minioadmin</td>\n<td>S3 secret access key</td>\n</tr>\n<tr>\n<td>aws.region</td>\n<td>us-east-1</td>\n<td>S3 区域</td>\n</tr>\n<tr>\n<td>aws.s3.endpoint</td>\n<td>http://minio:9000</td>\n<td>S3 endpoint地址</td>\n</tr>\n<tr>\n<td>hdfs.root.user</td>\n<td>hdfs</td>\n<td>如果存储类型为HDFS,需要配置拥有对应操作权限的用户</td>\n</tr>\n<tr>\n<td>fs.defaultFS</td>\n<td>hdfs://mycluster:8020</td>\n<td>请求地址如果resource.storage.type=S3,该值类似为: s3a://dolphinscheduler. 如果resource.storage.type=HDFS, 如果 hadoop 配置了 HA,需要复制core-site.xml 和 hdfs-site.xml 文件到conf目录</td>\n</tr>\n<tr>\n<td>hadoop.security.authentication.startup.state</td>\n<td>false</td>\n<td>hadoop是否开启kerberos权限</td>\n</tr>\n<tr>\n<td>java.security.krb5.conf.path</td>\n<td>/opt/krb5.conf</td>\n<td>kerberos配置目录</td>\n</tr>\n<tr>\n<td>login.user.keytab.username</td>\n<td>hdfs-mycluster@ESZ.COM</td>\n<td>kerberos登录用户</td>\n</tr>\n<tr>\n<td>login.user.keytab.path</td>\n<td>/opt/hdfs.headless.keytab</td>\n<td>kerberos登录用户keytab</td>\n</tr>\n<tr>\n<td>kerberos.expire.time</td>\n<td>2</td>\n<td>kerberos过期时间,整数,单位为小时</td>\n</tr>\n<tr>\n<td>yarn.resourcemanager.ha.rm.ids</td>\n<td>192.168.xx.xx,192.168.xx.xx</td>\n<td>yarn resourcemanager 地址, 如果resourcemanager开启了HA, 输入HA的IP地址(以逗号分隔),如果resourcemanager为单节点, 该值为空即可</td>\n</tr>\n<tr>\n<td>yarn.application.status.address</td>\n<td>http://ds1:8088/ws/v1/cluster/apps/%s</td>\n<td>如果resourcemanager开启了HA或者没有使用resourcemanager,保持默认值即可. 如果resourcemanager为单节点,你需要将ds1 配置为resourcemanager对应的hostname</td>\n</tr>\n<tr>\n<td>development.state</td>\n<td>false</td>\n<td>是否处于开发模式</td>\n</tr>\n<tr>\n<td>dolphin.scheduler.network.interface.preferred</td>\n<td>NONE</td>\n<td>网卡名称</td>\n</tr>\n<tr>\n<td>dolphin.scheduler.network.priority.strategy</td>\n<td>default</td>\n<td>ip获取策略 default优先获取内网</td>\n</tr>\n<tr>\n<td>resource.manager.httpaddress.port</td>\n<td>8088</td>\n<td>resource manager的端口</td>\n</tr>\n<tr>\n<td>yarn.job.history.status.address</td>\n<td>http://ds1:19888/ws/v1/history/mapreduce/jobs/%s</td>\n<td>yarn的作业历史状态URL</td>\n</tr>\n<tr>\n<td>datasource.encryption.enable</td>\n<td>false</td>\n<td>是否启用datasource 加密</td>\n</tr>\n<tr>\n<td>datasource.encryption.salt</td>\n<td>!@#$%^&amp;*</td>\n<td>datasource加密使用的salt</td>\n</tr>\n<tr>\n<td>data-quality.jar.name</td>\n<td>dolphinscheduler-data-quality-dev-SNAPSHOT.jar</td>\n<td>配置数据质量使用的jar包</td>\n</tr>\n<tr>\n<td>support.hive.oneSession</td>\n<td>false</td>\n<td>设置hive SQL是否在同一个session中执行</td>\n</tr>\n<tr>\n<td>sudo.enable</td>\n<td>true</td>\n<td>是否开启sudo</td>\n</tr>\n<tr>\n<td>alert.rpc.port</td>\n<td>50052</td>\n<td>Alert Server的RPC端口</td>\n</tr>\n<tr>\n<td>zeppelin.rest.url</td>\n<td>http://localhost:8080</td>\n<td>zeppelin RESTful API 接口地址</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"api-server相关配置\">Api-server相关配置</h2>\n<p>位置：<code>api-server/conf/application.yaml</code></p>\n<table>\n<thead>\n<tr>\n<th>参数</th>\n<th>默认值</th>\n<th>描述</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>server.port</td>\n<td>12345</td>\n<td>api服务通讯端口</td>\n</tr>\n<tr>\n<td>server.servlet.session.timeout</td>\n<td>120m</td>\n<td>session超时时间</td>\n</tr>\n<tr>\n<td>server.servlet.context-path</td>\n<td>/dolphinscheduler/</td>\n<td>请求路径</td>\n</tr>\n<tr>\n<td>spring.servlet.multipart.max-file-size</td>\n<td>1024MB</td>\n<td>最大上传文件大小</td>\n</tr>\n<tr>\n<td>spring.servlet.multipart.max-request-size</td>\n<td>1024MB</td>\n<td>最大请求大小</td>\n</tr>\n<tr>\n<td>server.jetty.max-http-post-size</td>\n<td>5000000</td>\n<td>jetty服务最大发送请求大小</td>\n</tr>\n<tr>\n<td>spring.banner.charset</td>\n<td>UTF-8</td>\n<td>请求编码</td>\n</tr>\n<tr>\n<td>spring.jackson.time-zone</td>\n<td>UTC</td>\n<td>设置时区</td>\n</tr>\n<tr>\n<td>spring.jackson.date-format</td>\n<td>&quot;yyyy-MM-dd HH:mm:ss&quot;</td>\n<td>设置时间格式</td>\n</tr>\n<tr>\n<td>spring.messages.basename</td>\n<td>i18n/messages</td>\n<td>i18n配置</td>\n</tr>\n<tr>\n<td>security.authentication.type</td>\n<td>PASSWORD</td>\n<td>权限校验类型</td>\n</tr>\n<tr>\n<td>security.authentication.ldap.user.admin</td>\n<td>read-only-admin</td>\n<td>LDAP登陆时，系统管理员账号</td>\n</tr>\n<tr>\n<td>security.authentication.ldap.urls</td>\n<td>ldap://ldap.forumsys.com:389/</td>\n<td>LDAP urls</td>\n</tr>\n<tr>\n<td>security.authentication.ldap.base.dn</td>\n<td>dc=example,dc=com</td>\n<td>LDAP base dn</td>\n</tr>\n<tr>\n<td>security.authentication.ldap.username</td>\n<td>cn=read-only-admin,dc=example,dc=com</td>\n<td>LDAP账号</td>\n</tr>\n<tr>\n<td>security.authentication.ldap.password</td>\n<td>password</td>\n<td>LDAP密码</td>\n</tr>\n<tr>\n<td>security.authentication.ldap.user.identity.attribute</td>\n<td>uid</td>\n<td>LDAP用户身份标识字段名</td>\n</tr>\n<tr>\n<td>security.authentication.ldap.user.email.attribute</td>\n<td>mail</td>\n<td>LDAP邮箱字段名</td>\n</tr>\n<tr>\n<td>traffic.control.global.switch</td>\n<td>false</td>\n<td>流量控制全局开关</td>\n</tr>\n<tr>\n<td>traffic.control.max-global-qps-rate</td>\n<td>300</td>\n<td>全局最大请求数/秒</td>\n</tr>\n<tr>\n<td>traffic.control.tenant-switch</td>\n<td>false</td>\n<td>流量控制租户开关</td>\n</tr>\n<tr>\n<td>traffic.control.default-tenant-qps-rate</td>\n<td>10</td>\n<td>默认租户最大请求数/秒限制</td>\n</tr>\n<tr>\n<td>traffic.control.customize-tenant-qps-rate</td>\n<td></td>\n<td>自定义租户最大请求数/秒限制</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"master-server相关配置\">Master Server相关配置</h2>\n<p>位置：<code>master-server/conf/application.yaml</code></p>\n<table>\n<thead>\n<tr>\n<th>参数</th>\n<th>默认值</th>\n<th>描述</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>master.listen-port</td>\n<td>5678</td>\n<td>master监听端口</td>\n</tr>\n<tr>\n<td>master.fetch-command-num</td>\n<td>10</td>\n<td>master拉取command数量</td>\n</tr>\n<tr>\n<td>master.pre-exec-threads</td>\n<td>10</td>\n<td>master准备执行任务的数量，用于限制并行的command</td>\n</tr>\n<tr>\n<td>master.exec-threads</td>\n<td>100</td>\n<td>master工作线程数量,用于限制并行的流程实例数量</td>\n</tr>\n<tr>\n<td>master.dispatch-task-number</td>\n<td>3</td>\n<td>master每个批次的派发任务数量</td>\n</tr>\n<tr>\n<td>master.host-selector</td>\n<td>lower_weight</td>\n<td>master host选择器,用于选择合适的worker执行任务,可选值: random, round_robin, lower_weight</td>\n</tr>\n<tr>\n<td>master.heartbeat-interval</td>\n<td>10</td>\n<td>master心跳间隔,单位为秒</td>\n</tr>\n<tr>\n<td>master.task-commit-retry-times</td>\n<td>5</td>\n<td>任务重试次数</td>\n</tr>\n<tr>\n<td>master.task-commit-interval</td>\n<td>1000</td>\n<td>任务提交间隔,单位为毫秒</td>\n</tr>\n<tr>\n<td>master.state-wheel-interval</td>\n<td>5</td>\n<td>轮询检查状态时间</td>\n</tr>\n<tr>\n<td>master.max-cpu-load-avg</td>\n<td>-1</td>\n<td>master最大cpuload均值,只有高于系统cpuload均值时,master服务才能调度任务. 默认值为-1: cpu cores * 2</td>\n</tr>\n<tr>\n<td>master.reserved-memory</td>\n<td>0.3</td>\n<td>master预留内存,只有低于系统可用内存时,master服务才能调度任务,单位为G</td>\n</tr>\n<tr>\n<td>master.failover-interval</td>\n<td>10</td>\n<td>failover间隔，单位为分钟</td>\n</tr>\n<tr>\n<td>master.kill-yarn-job-when-task-failover</td>\n<td>true</td>\n<td>当任务实例failover时，是否kill掉yarn job</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"worker-server相关配置\">Worker Server相关配置</h2>\n<p>位置：<code>worker-server/conf/application.yaml</code></p>\n<table>\n<thead>\n<tr>\n<th>参数</th>\n<th>默认值</th>\n<th>描述</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>worker.listen-port</td>\n<td>1234</td>\n<td>worker监听端口</td>\n</tr>\n<tr>\n<td>worker.exec-threads</td>\n<td>100</td>\n<td>worker工作线程数量,用于限制并行的任务实例数量</td>\n</tr>\n<tr>\n<td>worker.heartbeat-interval</td>\n<td>10</td>\n<td>worker心跳间隔,单位为秒</td>\n</tr>\n<tr>\n<td>worker.host-weight</td>\n<td>100</td>\n<td>派发任务时，worker主机的权重</td>\n</tr>\n<tr>\n<td>worker.tenant-auto-create</td>\n<td>true</td>\n<td>租户对应于系统的用户,由worker提交作业.如果系统没有该用户,则在参数worker.tenant.auto.create为true后自动创建。</td>\n</tr>\n<tr>\n<td>worker.max-cpu-load-avg</td>\n<td>-1</td>\n<td>worker最大cpuload均值,只有高于系统cpuload均值时,worker服务才能被派发任务. 默认值为-1: cpu cores * 2</td>\n</tr>\n<tr>\n<td>worker.reserved-memory</td>\n<td>0.3</td>\n<td>worker预留内存,只有低于系统可用内存时,worker服务才能被派发任务,单位为G</td>\n</tr>\n<tr>\n<td>worker.groups</td>\n<td>default</td>\n<td>worker分组配置,逗号分隔,例如'worker.groups=default,test' <br> worker启动时会根据该配置自动加入对应的分组</td>\n</tr>\n<tr>\n<td>worker.alert-listen-host</td>\n<td>localhost</td>\n<td>alert监听host</td>\n</tr>\n<tr>\n<td>worker.alert-listen-port</td>\n<td>50052</td>\n<td>alert监听端口</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"alert-server相关配置\">Alert Server相关配置</h2>\n<p>位置：<code>alert-server/conf/application.yaml</code></p>\n<table>\n<thead>\n<tr>\n<th>参数</th>\n<th>默认值</th>\n<th>描述</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>server.port</td>\n<td>50053</td>\n<td>Alert Server监听端口</td>\n</tr>\n<tr>\n<td>alert.port</td>\n<td>50052</td>\n<td>alert监听端口</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"quartz相关配置\">Quartz相关配置</h2>\n<p>这里面主要是quartz配置,请结合实际业务场景&amp;资源进行配置,本文暂时不做展开，配置文件位置：</p>\n<table>\n<thead>\n<tr>\n<th>服务名称</th>\n<th>配置文件</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Master Server</td>\n<td><code>master-server/conf/application.yaml</code></td>\n</tr>\n<tr>\n<td>Api Server</td>\n<td><code>api-server/conf/application.yaml</code></td>\n</tr>\n</tbody>\n</table>\n<p>默认配置如下：</p>\n<table>\n<thead>\n<tr>\n<th>参数</th>\n<th>默认值</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>spring.quartz.properties.org.quartz.threadPool.threadPriority</td>\n<td>5</td>\n</tr>\n<tr>\n<td>spring.quartz.properties.org.quartz.jobStore.isClustered</td>\n<td>true</td>\n</tr>\n<tr>\n<td>spring.quartz.properties.org.quartz.jobStore.class</td>\n<td>org.quartz.impl.jdbcjobstore.JobStoreTX</td>\n</tr>\n<tr>\n<td>spring.quartz.properties.org.quartz.scheduler.instanceId</td>\n<td>AUTO</td>\n</tr>\n<tr>\n<td>spring.quartz.properties.org.quartz.jobStore.tablePrefix</td>\n<td>QRTZ_</td>\n</tr>\n<tr>\n<td>spring.quartz.properties.org.quartz.jobStore.acquireTriggersWithinLock</td>\n<td>true</td>\n</tr>\n<tr>\n<td>spring.quartz.properties.org.quartz.scheduler.instanceName</td>\n<td>DolphinScheduler</td>\n</tr>\n<tr>\n<td>spring.quartz.properties.org.quartz.threadPool.class</td>\n<td>org.quartz.simpl.SimpleThreadPool</td>\n</tr>\n<tr>\n<td>spring.quartz.properties.org.quartz.jobStore.useProperties</td>\n<td>false</td>\n</tr>\n<tr>\n<td>spring.quartz.properties.org.quartz.threadPool.makeThreadsDaemons</td>\n<td>true</td>\n</tr>\n<tr>\n<td>spring.quartz.properties.org.quartz.threadPool.threadCount</td>\n<td>25</td>\n</tr>\n<tr>\n<td>spring.quartz.properties.org.quartz.jobStore.misfireThreshold</td>\n<td>60000</td>\n</tr>\n<tr>\n<td>spring.quartz.properties.org.quartz.scheduler.makeSchedulerThreadDaemon</td>\n<td>true</td>\n</tr>\n<tr>\n<td>spring.quartz.properties.org.quartz.jobStore.driverDelegateClass</td>\n<td>org.quartz.impl.jdbcjobstore.PostgreSQLDelegate</td>\n</tr>\n<tr>\n<td>spring.quartz.properties.org.quartz.jobStore.clusterCheckinInterval</td>\n<td>5000</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"dolphinscheduler_env.sh-[环境变量配置]\">dolphinscheduler_env.sh [环境变量配置]</h2>\n<p>通过类似shell方式提交任务的的时候，会加载该配置文件中的环境变量到主机中。涉及到的 <code>JAVA_HOME</code>、元数据库、注册中心和任务类型配置，其中任务类型主要有: Shell任务、Python任务、Spark任务、Flink任务、Datax任务等等。</p>\n<pre><code class=\"language-bash\"><span class=\"hljs-comment\"># JAVA_HOME, will use it to start DolphinScheduler server</span>\n<span class=\"hljs-built_in\">export</span> JAVA_HOME=<span class=\"hljs-variable\">${JAVA_HOME:-/opt/soft/java}</span>\n\n<span class=\"hljs-comment\"># Database related configuration, set database type, username and password</span>\n<span class=\"hljs-built_in\">export</span> DATABASE=<span class=\"hljs-variable\">${DATABASE:-postgresql}</span>\n<span class=\"hljs-built_in\">export</span> SPRING_PROFILES_ACTIVE=<span class=\"hljs-variable\">${DATABASE}</span>\n<span class=\"hljs-built_in\">export</span> SPRING_DATASOURCE_URL\n<span class=\"hljs-built_in\">export</span> SPRING_DATASOURCE_USERNAME\n<span class=\"hljs-built_in\">export</span> SPRING_DATASOURCE_PASSWORD\n\n<span class=\"hljs-comment\"># DolphinScheduler server related configuration</span>\n<span class=\"hljs-built_in\">export</span> SPRING_CACHE_TYPE=<span class=\"hljs-variable\">${SPRING_CACHE_TYPE:-none}</span>\n<span class=\"hljs-built_in\">export</span> SPRING_JACKSON_TIME_ZONE=<span class=\"hljs-variable\">${SPRING_JACKSON_TIME_ZONE:-UTC}</span>\n<span class=\"hljs-built_in\">export</span> MASTER_FETCH_COMMAND_NUM=<span class=\"hljs-variable\">${MASTER_FETCH_COMMAND_NUM:-10}</span>\n\n<span class=\"hljs-comment\"># Registry center configuration, determines the type and link of the registry center</span>\n<span class=\"hljs-built_in\">export</span> REGISTRY_TYPE=<span class=\"hljs-variable\">${REGISTRY_TYPE:-zookeeper}</span>\n<span class=\"hljs-built_in\">export</span> REGISTRY_ZOOKEEPER_CONNECT_STRING=<span class=\"hljs-variable\">${REGISTRY_ZOOKEEPER_CONNECT_STRING:-localhost:2181}</span>\n\n<span class=\"hljs-comment\"># Tasks related configurations, need to change the configuration if you use the related tasks.</span>\n<span class=\"hljs-built_in\">export</span> HADOOP_HOME=<span class=\"hljs-variable\">${HADOOP_HOME:-/opt/soft/hadoop}</span>\n<span class=\"hljs-built_in\">export</span> HADOOP_CONF_DIR=<span class=\"hljs-variable\">${HADOOP_CONF_DIR:-/opt/soft/hadoop/etc/hadoop}</span>\n<span class=\"hljs-built_in\">export</span> SPARK_HOME1=<span class=\"hljs-variable\">${SPARK_HOME1:-/opt/soft/spark1}</span>\n<span class=\"hljs-built_in\">export</span> SPARK_HOME2=<span class=\"hljs-variable\">${SPARK_HOME2:-/opt/soft/spark2}</span>\n<span class=\"hljs-built_in\">export</span> PYTHON_HOME=<span class=\"hljs-variable\">${PYTHON_HOME:-/opt/soft/python}</span>\n<span class=\"hljs-built_in\">export</span> HIVE_HOME=<span class=\"hljs-variable\">${HIVE_HOME:-/opt/soft/hive}</span>\n<span class=\"hljs-built_in\">export</span> FLINK_HOME=<span class=\"hljs-variable\">${FLINK_HOME:-/opt/soft/flink}</span>\n<span class=\"hljs-built_in\">export</span> DATAX_HOME=<span class=\"hljs-variable\">${DATAX_HOME:-/opt/soft/datax}</span>\n\n<span class=\"hljs-built_in\">export</span> PATH=<span class=\"hljs-variable\">$HADOOP_HOME</span>/bin:<span class=\"hljs-variable\">$SPARK_HOME1</span>/bin:<span class=\"hljs-variable\">$SPARK_HOME2</span>/bin:<span class=\"hljs-variable\">$PYTHON_HOME</span>/bin:<span class=\"hljs-variable\">$JAVA_HOME</span>/bin:<span class=\"hljs-variable\">$HIVE_HOME</span>/bin:<span class=\"hljs-variable\">$FLINK_HOME</span>/bin:<span class=\"hljs-variable\">$DATAX_HOME</span>/bin:<span class=\"hljs-variable\">$PATH</span>\n</code></pre>\n<h2 id=\"日志相关配置\">日志相关配置</h2>\n<table>\n<thead>\n<tr>\n<th>服务名称</th>\n<th>配置文件</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Master Server</td>\n<td><code>master-server/conf/logback-spring.xml</code></td>\n</tr>\n<tr>\n<td>Api Server</td>\n<td><code>api-server/conf/logback-spring.xml</code></td>\n</tr>\n<tr>\n<td>Worker Server</td>\n<td><code>worker-server/conf/logback-spring.xml</code></td>\n</tr>\n<tr>\n<td>Alert Server</td>\n<td><code>alert-server/conf/logback-spring.xml</code></td>\n</tr>\n</tbody>\n</table>\n",
  "location": [
    "架构设计",
    "配置文件"
  ],
  "time": "2022-9-26",
  "structure": [
    {
      "title": "dolphinscheduler-daemon.sh [启动/关闭DolphinScheduler服务脚本]",
      "children": [],
      "anchor": "dolphinscheduler-daemon.sh-[启动/关闭dolphinscheduler服务脚本]"
    },
    {
      "title": "数据库连接相关配置",
      "children": [],
      "anchor": "数据库连接相关配置"
    },
    {
      "title": "Zookeeper相关配置",
      "children": [],
      "anchor": "zookeeper相关配置"
    },
    {
      "title": "4.common.properties [hadoop、s3、yarn配置]",
      "children": [],
      "anchor": "4.common.properties-[hadoop、s3、yarn配置]"
    },
    {
      "title": "5.application-api.properties [API服务配置]",
      "children": [],
      "anchor": "5.application-api.properties-[api服务配置]"
    },
    {
      "title": "Api-server相关配置",
      "children": [],
      "anchor": "api-server相关配置"
    },
    {
      "title": "Master Server相关配置",
      "children": [],
      "anchor": "master-server相关配置"
    },
    {
      "title": "Worker Server相关配置",
      "children": [],
      "anchor": "worker-server相关配置"
    },
    {
      "title": "Alert Server相关配置",
      "children": [],
      "anchor": "alert-server相关配置"
    },
    {
      "title": "Quartz相关配置",
      "children": [],
      "anchor": "quartz相关配置"
    },
    {
      "title": "dolphinscheduler_env.sh [环境变量配置]",
      "children": [],
      "anchor": "dolphinscheduler_env.sh-[环境变量配置]"
    },
    {
      "title": "日志相关配置",
      "children": [],
      "anchor": "日志相关配置"
    }
  ],
  "title": "前言",
  "link": "/architecture/configuration"
}