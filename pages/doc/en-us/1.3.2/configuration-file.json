{
  "__html": "<!-- markdown-link-check-disable -->\n<h1 id=\"foreword\">Foreword</h1>\n<p>This document is a description of the dolphinscheduler configuration file, and the version is for dolphinscheduler-1.3.x.</p>\n<h1 id=\"directory-structure\">Directory Structure</h1>\n<p>All configuration files of dolphinscheduler are currently in the [conf] directory.</p>\n<p>For a more intuitive understanding of the location of the [conf] directory and the configuration files it contains, please see the simplified description of the dolphinscheduler installation directory below.</p>\n<p>This article mainly talks about the configuration file of dolphinscheduler. I won't go into details in other parts.</p>\n<p>[Note: The following dolphinscheduler is referred to as DS.]</p>\n<pre><code>\n├─bin                               DS command storage directory\n│  ├─dolphinscheduler-daemon.sh         Activate/deactivate DS service script\n│  ├─start-all.sh                       Start all DS services according to the configuration file\n│  ├─stop-all.sh                        Close all DS services according to the configuration file\n├─conf                              Configuration file directory\n│  ├─application-api.properties         api service configuration file\n│  ├─datasource.properties              Database configuration file\n│  ├─zookeeper.properties               zookeeper configuration file\n│  ├─master.properties                  Master service configuration file\n│  ├─worker.properties                  Worker service configuration file\n│  ├─quartz.properties                  Quartz service configuration file\n│  ├─common.properties                  Public service [storage] configuration file\n│  ├─alert.properties                   alert service configuration file\n│  ├─config                             Environment variable configuration folder\n│      ├─install_config.conf                DS environment variable configuration script [for DS installation/startup]\n│  ├─env                                Run script environment variable configuration directory\n│      ├─dolphinscheduler_env.sh            Run the script to load the environment variable configuration file [such as: JAVA_HOME, HADOOP_HOME, HIVE_HOME ...]\n│  ├─org                                mybatis mapper file directory\n│  ├─i18n                               i18n configuration file directory\n│  ├─logback-api.xml                    api service log configuration file\n│  ├─logback-master.xml                 Master service log configuration file\n│  ├─logback-worker.xml                 Worker service log configuration file\n│  ├─logback-alert.xml                  alert service log configuration file\n├─sql                               DS metadata creation and upgrade sql file\n│  ├─create                             Create SQL script directory\n│  ├─upgrade                            Upgrade SQL script directory\n│  ├─dolphinscheduler-postgre.sql       Postgre database initialization script\n│  ├─dolphinscheduler_mysql.sql         mysql database initialization version\n│  ├─soft_version                       Current DS version identification file\n├─script                            DS service deployment, database creation/upgrade script directory\n│  ├─create-dolphinscheduler.sh         DS database initialization script      \n│  ├─upgrade-dolphinscheduler.sh        DS database upgrade script                \n│  ├─monitor-server.sh                  DS service monitoring startup script               \n│  ├─scp-hosts.sh                       Install file transfer script                                                    \n│  ├─remove-zk-node.sh                  Clean Zookeeper cache file script       \n├─ui                                Front-end WEB resource directory\n├─lib                               DS dependent jar storage directory\n├─install.sh                        Automatically install DS service script\n\n\n</code></pre>\n<h1 id=\"detailed-configuration-file\">Detailed configuration file</h1>\n<table>\n<thead>\n<tr>\n<th>Serial number</th>\n<th>Service classification</th>\n<th>Configuration file</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>Activate/deactivate DS service script</td>\n<td>dolphinscheduler-daemon.sh</td>\n</tr>\n<tr>\n<td>2</td>\n<td>Database connection configuration</td>\n<td>datasource.properties</td>\n</tr>\n<tr>\n<td>3</td>\n<td>Zookeeper connection configuration</td>\n<td>zookeeper.properties</td>\n</tr>\n<tr>\n<td>4</td>\n<td>Common [storage] configuration</td>\n<td>common.properties</td>\n</tr>\n<tr>\n<td>5</td>\n<td>API service configuration</td>\n<td>application-api.properties</td>\n</tr>\n<tr>\n<td>6</td>\n<td>Master service configuration</td>\n<td>master.properties</td>\n</tr>\n<tr>\n<td>7</td>\n<td>Worker service configuration</td>\n<td>worker.properties</td>\n</tr>\n<tr>\n<td>8</td>\n<td>Alert service configuration</td>\n<td>alert.properties</td>\n</tr>\n<tr>\n<td>9</td>\n<td>Quartz configuration</td>\n<td>quartz.properties</td>\n</tr>\n<tr>\n<td>10</td>\n<td>DS environment variable configuration script [for DS installation/startup]</td>\n<td>install_config.conf</td>\n</tr>\n<tr>\n<td>11</td>\n<td>Run the script to load the environment variable configuration file <br />[for example: JAVA_HOME,HADOOP_HOME, HIVE_HOME ...</td>\n<td>dolphinscheduler_env.sh</td>\n</tr>\n<tr>\n<td>12</td>\n<td>Service log configuration files</td>\n<td>api service log configuration file : logback-api.xml  <br /> Master service log configuration file  : logback-master.xml    <br /> Worker service log configuration file : logback-worker.xml  <br /> alertService log configuration file : logback-alert.xml</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"1.dolphinscheduler-daemon.sh-[activate/deactivate-ds-service-script]\">1.dolphinscheduler-daemon.sh [Activate/deactivate DS service script]</h2>\n<p>The dolphinscheduler-daemon.sh script is responsible for DS startup &amp; shutdown\nstart-all.sh/stop-all.sh eventually starts and shuts down the cluster through dolphinscheduler-daemon.sh.\nAt present, DS has only made a basic setting. Please set the JVM parameters according to the actual situation of their resources.</p>\n<p>The default simplified parameters are as follows:</p>\n<pre><code class=\"language-bash\"><span class=\"hljs-built_in\">export</span> DOLPHINSCHEDULER_OPTS=<span class=\"hljs-string\">&quot;\n-server \n-Xmx16g \n-Xms1g \n-Xss512k \n-XX:+UseConcMarkSweepGC \n-XX:+CMSParallelRemarkEnabled \n-XX:+UseFastAccessorMethods \n-XX:+UseCMSInitiatingOccupancyOnly \n-XX:CMSInitiatingOccupancyFraction=70\n&quot;</span>\n</code></pre>\n<blockquote>\n<p>It is not recommended to set &quot;-XX:DisableExplicitGC&quot;, DS uses Netty for communication. Setting this parameter may cause memory leaks.</p>\n</blockquote>\n<h2 id=\"2.datasource.properties-[database-connectivity]\">2.datasource.properties [Database Connectivity]</h2>\n<p>Use Druid to manage the database connection in DS.The default simplified configuration is as follows.</p>\n<table>\n<thead>\n<tr>\n<th>Parameter</th>\n<th>Defaults</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>spring.datasource.driver-class-name</td>\n<td></td>\n<td>Database driver</td>\n</tr>\n<tr>\n<td>spring.datasource.url</td>\n<td></td>\n<td>Database connection address</td>\n</tr>\n<tr>\n<td>spring.datasource.username</td>\n<td></td>\n<td>Database username</td>\n</tr>\n<tr>\n<td>spring.datasource.password</td>\n<td></td>\n<td>Database password</td>\n</tr>\n<tr>\n<td>spring.datasource.initialSize</td>\n<td>5</td>\n<td>Number of initial connection pools</td>\n</tr>\n<tr>\n<td>spring.datasource.minIdle</td>\n<td>5</td>\n<td>Minimum number of connection pools</td>\n</tr>\n<tr>\n<td>spring.datasource.maxActive</td>\n<td>5</td>\n<td>Maximum number of connection pools</td>\n</tr>\n<tr>\n<td>spring.datasource.maxWait</td>\n<td>60000</td>\n<td>Maximum waiting time</td>\n</tr>\n<tr>\n<td>spring.datasource.timeBetweenEvictionRunsMillis</td>\n<td>60000</td>\n<td>Connection detection cycle</td>\n</tr>\n<tr>\n<td>spring.datasource.timeBetweenConnectErrorMillis</td>\n<td>60000</td>\n<td>Retry interval</td>\n</tr>\n<tr>\n<td>spring.datasource.minEvictableIdleTimeMillis</td>\n<td>300000</td>\n<td>The minimum time a connection remains idle without being evicted</td>\n</tr>\n<tr>\n<td>spring.datasource.validationQuery</td>\n<td>SELECT 1</td>\n<td>SQL to check whether the connection is valid</td>\n</tr>\n<tr>\n<td>spring.datasource.validationQueryTimeout</td>\n<td>3</td>\n<td>Timeout to check if the connection is valid[seconds]</td>\n</tr>\n<tr>\n<td>spring.datasource.testWhileIdle</td>\n<td>true</td>\n<td>Check when applying for connection, if idle time is greater than timeBetweenEvictionRunsMillis，Run validationQuery to check whether the connection is valid.</td>\n</tr>\n<tr>\n<td>spring.datasource.testOnBorrow</td>\n<td>true</td>\n<td>Execute validationQuery to check whether the connection is valid when applying for connection</td>\n</tr>\n<tr>\n<td>spring.datasource.testOnReturn</td>\n<td>false</td>\n<td>When returning the connection, execute validationQuery to check whether the connection is valid</td>\n</tr>\n<tr>\n<td>spring.datasource.defaultAutoCommit</td>\n<td>true</td>\n<td>Whether to enable automatic submission</td>\n</tr>\n<tr>\n<td>spring.datasource.keepAlive</td>\n<td>true</td>\n<td>For connections within the minIdle number in the connection pool, if the idle time exceeds minEvictableIdleTimeMillis, the keepAlive operation will be performed.</td>\n</tr>\n<tr>\n<td>spring.datasource.poolPreparedStatements</td>\n<td>true</td>\n<td>Open PSCache</td>\n</tr>\n<tr>\n<td>spring.datasource.maxPoolPreparedStatementPerConnectionSize</td>\n<td>20</td>\n<td>To enable PSCache, you must configure greater than 0, when greater than 0,PoolPreparedStatements automatically trigger modification to true.</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"3.zookeeper.properties-[zookeeper-connection-configuration]\">3.zookeeper.properties [Zookeeper connection configuration]</h2>\n<table>\n<thead>\n<tr>\n<th>Parameter</th>\n<th>Defaults</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>zookeeper.quorum</td>\n<td>localhost:2181</td>\n<td>zk cluster connection information</td>\n</tr>\n<tr>\n<td>zookeeper.dolphinscheduler.root</td>\n<td>/dolphinscheduler</td>\n<td>DS stores root directory in zookeeper</td>\n</tr>\n<tr>\n<td>zookeeper.session.timeout</td>\n<td>60000</td>\n<td>session time out</td>\n</tr>\n<tr>\n<td>zookeeper.connection.timeout</td>\n<td>30000</td>\n<td>Connection timed out</td>\n</tr>\n<tr>\n<td>zookeeper.retry.base.sleep</td>\n<td>100</td>\n<td>Basic retry time difference</td>\n</tr>\n<tr>\n<td>zookeeper.retry.max.sleep</td>\n<td>30000</td>\n<td>Maximum retry time</td>\n</tr>\n<tr>\n<td>zookeeper.retry.maxtime</td>\n<td>10</td>\n<td>Maximum number of retries</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"4.common.properties-[hadoop,-s3,-yarn-configuration]\">4.common.properties [hadoop, s3, yarn configuration]</h2>\n<p>The common.properties configuration file is currently mainly used to configure hadoop/s3a related configurations.</p>\n<table>\n<thead>\n<tr>\n<th>Parameter</th>\n<th>Defaults</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>resource.storage.type</td>\n<td>NONE</td>\n<td>Resource file storage type: HDFS,S3,NONE</td>\n</tr>\n<tr>\n<td>resource.upload.path</td>\n<td>/dolphinscheduler</td>\n<td>Resource file storage path</td>\n</tr>\n<tr>\n<td>data.basedir.path</td>\n<td>/tmp/dolphinscheduler</td>\n<td>Local working directory for storing temporary files</td>\n</tr>\n<tr>\n<td>hadoop.security.authentication.startup.state</td>\n<td>false</td>\n<td>hadoop enable kerberos permission</td>\n</tr>\n<tr>\n<td>java.security.krb5.conf.path</td>\n<td>/opt/krb5.conf</td>\n<td>kerberos configuration directory</td>\n</tr>\n<tr>\n<td>login.user.keytab.username</td>\n<td>hdfs-mycluster@ESZ.COM</td>\n<td>kerberos login user</td>\n</tr>\n<tr>\n<td>login.user.keytab.path</td>\n<td>/opt/hdfs.headless.keytab</td>\n<td>kerberos login user keytab</td>\n</tr>\n<tr>\n<td>resource.view.suffixs</td>\n<td>txt,log,sh,conf,cfg,py,java,sql,hql,xml,properties</td>\n<td>File formats supported by the resource center</td>\n</tr>\n<tr>\n<td>hdfs.root.user</td>\n<td>hdfs</td>\n<td>If the storage type is HDFS, you need to configure users with corresponding operation permissions</td>\n</tr>\n<tr>\n<td>fs.defaultFS</td>\n<td>hdfs://mycluster:8020</td>\n<td>Request address if resource.storage.type=S3 ,the value is similar to: s3a://dolphinscheduler. If resource.storage.type=HDFS, If hadoop configured HA, you need to copy the core-site.xml and hdfs-site.xml files to the conf directory</td>\n</tr>\n<tr>\n<td>fs.s3a.endpoint</td>\n<td></td>\n<td>s3 endpoint address</td>\n</tr>\n<tr>\n<td>fs.s3a.access.key</td>\n<td></td>\n<td>s3 access key</td>\n</tr>\n<tr>\n<td>fs.s3a.secret.key</td>\n<td></td>\n<td>s3 secret key</td>\n</tr>\n<tr>\n<td>yarn.resourcemanager.ha.rm.ids</td>\n<td></td>\n<td>yarn resourcemanager address, If the resourcemanager has HA turned on, enter the IP address of the HA (separated by commas). If the resourcemanager is a single node, the value can be empty.</td>\n</tr>\n<tr>\n<td>yarn.application.status.address</td>\n<td>http://ds1:8088/ws/v1/cluster/apps/%s</td>\n<td>If resourcemanager has HA enabled or resourcemanager is not used, keep the default value. If resourcemanager is a single node, you need to configure ds1 as the hostname corresponding to resourcemanager</td>\n</tr>\n<tr>\n<td>dolphinscheduler.env.path</td>\n<td>env/dolphinscheduler_env.sh</td>\n<td>Run the script to load the environment variable configuration file [eg: JAVA_HOME, HADOOP_HOME, HIVE_HOME ...]</td>\n</tr>\n<tr>\n<td>development.state</td>\n<td>false</td>\n<td>Is it in development mode</td>\n</tr>\n<tr>\n<td>kerberos.expire.time</td>\n<td>7</td>\n<td>kerberos expire time,integer,the unit is day</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"5.application-api.properties-[api-service-configuration]\">5.application-api.properties [API service configuration]</h2>\n<table>\n<thead>\n<tr>\n<th>Parameter</th>\n<th>Defaults</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>server.port</td>\n<td>12345</td>\n<td>API service communication port</td>\n</tr>\n<tr>\n<td>server.servlet.session.timeout</td>\n<td>7200</td>\n<td>session timeout</td>\n</tr>\n<tr>\n<td>server.servlet.context-path</td>\n<td>/dolphinscheduler</td>\n<td>Request path</td>\n</tr>\n<tr>\n<td>spring.servlet.multipart.max-file-size</td>\n<td>1024MB</td>\n<td>Maximum upload file size</td>\n</tr>\n<tr>\n<td>spring.servlet.multipart.max-request-size</td>\n<td>1024MB</td>\n<td>Maximum request size</td>\n</tr>\n<tr>\n<td>server.jetty.max-http-post-size</td>\n<td>5000000</td>\n<td>Jetty service maximum send request size</td>\n</tr>\n<tr>\n<td>spring.messages.encoding</td>\n<td>UTF-8</td>\n<td>Request encoding</td>\n</tr>\n<tr>\n<td>spring.jackson.time-zone</td>\n<td>GMT+8</td>\n<td>Set time zone</td>\n</tr>\n<tr>\n<td>spring.messages.basename</td>\n<td>i18n/messages</td>\n<td>i18n configuration</td>\n</tr>\n<tr>\n<td>security.authentication.type</td>\n<td>PASSWORD</td>\n<td>Permission verification type</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"6.master.properties-[master-service-configuration]\">6.master.properties [Master service configuration]</h2>\n<table>\n<thead>\n<tr>\n<th>Parameter</th>\n<th>Defaults</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>master.listen.port</td>\n<td>5678</td>\n<td>master listen port</td>\n</tr>\n<tr>\n<td>master.exec.threads</td>\n<td>100</td>\n<td>master execute thread number to limit process instances in parallel</td>\n</tr>\n<tr>\n<td>master.exec.task.num</td>\n<td>20</td>\n<td>master execute task number in parallel per process instance</td>\n</tr>\n<tr>\n<td>master.dispatch.task.num</td>\n<td>3</td>\n<td>master dispatch task number per batch</td>\n</tr>\n<tr>\n<td>master.host.selector</td>\n<td>LowerWeight</td>\n<td>master host selector to select a suitable worker, default value: LowerWeight. Optional values include Random, RoundRobin, LowerWeight</td>\n</tr>\n<tr>\n<td>master.heartbeat.interval</td>\n<td>10</td>\n<td>master heartbeat interval, the unit is second</td>\n</tr>\n<tr>\n<td>master.task.commit.retryTimes</td>\n<td>5</td>\n<td>master commit task retry times</td>\n</tr>\n<tr>\n<td>master.task.commit.interval</td>\n<td>1000</td>\n<td>master commit task interval, the unit is millisecond</td>\n</tr>\n<tr>\n<td>master.max.cpuload.avg</td>\n<td>-1</td>\n<td>master max cpuload avg, only higher than the system cpu load average, master server can schedule. default value -1: the number of cpu cores * 2</td>\n</tr>\n<tr>\n<td>master.reserved.memory</td>\n<td>0.3</td>\n<td>master reserved memory, only lower than system available memory, master server can schedule. default value 0.3, the unit is G</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"7.worker.properties-[worker-service-configuration]\">7.worker.properties [Worker service configuration]</h2>\n<table>\n<thead>\n<tr>\n<th>Parameter</th>\n<th>Defaults</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>worker.listen.port</td>\n<td>1234</td>\n<td>worker listen port</td>\n</tr>\n<tr>\n<td>worker.exec.threads</td>\n<td>100</td>\n<td>worker execute thread number to limit task instances in parallel</td>\n</tr>\n<tr>\n<td>worker.heartbeat.interval</td>\n<td>10</td>\n<td>worker heartbeat interval, the unit is second</td>\n</tr>\n<tr>\n<td>worker.max.cpuload.avg</td>\n<td>-1</td>\n<td>worker max cpuload avg, only higher than the system cpu load average, worker server can be dispatched tasks. default value -1: the number of cpu cores * 2</td>\n</tr>\n<tr>\n<td>worker.reserved.memory</td>\n<td>0.3</td>\n<td>worker reserved memory, only lower than system available memory, worker server can be dispatched tasks. default value 0.3, the unit is G</td>\n</tr>\n<tr>\n<td>worker.groups</td>\n<td>default</td>\n<td>worker groups separated by comma, like 'worker.groups=default,test' <br> worker will join corresponding group according to this config when startup</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"8.alert.properties-[alert-alert-service-configuration]\">8.alert.properties [Alert alert service configuration]</h2>\n<table>\n<thead>\n<tr>\n<th>Parameter</th>\n<th>Defaults</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>alert.type</td>\n<td>EMAIL</td>\n<td>Alarm type</td>\n</tr>\n<tr>\n<td>mail.protocol</td>\n<td>SMTP</td>\n<td>Mail server protocol</td>\n</tr>\n<tr>\n<td>mail.server.host</td>\n<td>xxx.xxx.com</td>\n<td>Mail server address</td>\n</tr>\n<tr>\n<td>mail.server.port</td>\n<td>25</td>\n<td>Mail server port</td>\n</tr>\n<tr>\n<td>mail.sender</td>\n<td>xxx@xxx.com</td>\n<td>Sender mailbox</td>\n</tr>\n<tr>\n<td>mail.user</td>\n<td>xxx@xxx.com</td>\n<td>Sender's email name</td>\n</tr>\n<tr>\n<td>mail.passwd</td>\n<td>111111</td>\n<td>Sender email password</td>\n</tr>\n<tr>\n<td>mail.smtp.starttls.enable</td>\n<td>true</td>\n<td>Whether the mailbox opens tls</td>\n</tr>\n<tr>\n<td>mail.smtp.ssl.enable</td>\n<td>false</td>\n<td>Whether the mailbox opens ssl</td>\n</tr>\n<tr>\n<td>mail.smtp.ssl.trust</td>\n<td>xxx.xxx.com</td>\n<td>Email ssl whitelist</td>\n</tr>\n<tr>\n<td>xls.file.path</td>\n<td>/tmp/xls</td>\n<td>Temporary working directory for mailbox attachments</td>\n</tr>\n<tr>\n<td></td>\n<td>The following is the enterprise WeChat configuration[Optional]</td>\n<td></td>\n</tr>\n<tr>\n<td>enterprise.wechat.enable</td>\n<td>false</td>\n<td>Whether the enterprise WeChat is enabled</td>\n</tr>\n<tr>\n<td>enterprise.wechat.corp.id</td>\n<td>xxxxxxx</td>\n<td></td>\n</tr>\n<tr>\n<td>enterprise.wechat.secret</td>\n<td>xxxxxxx</td>\n<td></td>\n</tr>\n<tr>\n<td>enterprise.wechat.agent.id</td>\n<td>xxxxxxx</td>\n<td></td>\n</tr>\n<tr>\n<td>enterprise.wechat.users</td>\n<td>xxxxxxx</td>\n<td></td>\n</tr>\n<tr>\n<td>enterprise.wechat.token.url</td>\n<td>https://qyapi.weixin.qq.com/cgi-bin/gettoken?  <br /> corpid=$corpId&amp;corpsecret=$secret</td>\n<td></td>\n</tr>\n<tr>\n<td>enterprise.wechat.push.url</td>\n<td>https://qyapi.weixin.qq.com/cgi-bin/message/send?  <br /> access_token=$token</td>\n<td></td>\n</tr>\n<tr>\n<td>enterprise.wechat.user.send.msg</td>\n<td></td>\n<td>Send message format</td>\n</tr>\n<tr>\n<td>enterprise.wechat.team.send.msg</td>\n<td></td>\n<td>Group message format</td>\n</tr>\n<tr>\n<td>plugin.dir</td>\n<td>/Users/xx/your/path/to/plugin/dir</td>\n<td>Plugin directory</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"9.quartz.properties-[quartz-configuration]\">9.quartz.properties [Quartz configuration]</h2>\n<p>This is mainly quartz configuration, please configure it in combination with actual business scenarios &amp; resources, this article will not be expanded for the time being.</p>\n<table>\n<thead>\n<tr>\n<th>Parameter</th>\n<th>Defaults</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>org.quartz.jobStore.driverDelegateClass</td>\n<td>org.quartz.impl.jdbcjobstore.StdJDBCDelegate</td>\n<td></td>\n</tr>\n<tr>\n<td>org.quartz.jobStore.driverDelegateClass</td>\n<td>org.quartz.impl.jdbcjobstore.PostgreSQLDelegate</td>\n<td></td>\n</tr>\n<tr>\n<td>org.quartz.scheduler.instanceName</td>\n<td>DolphinScheduler</td>\n<td></td>\n</tr>\n<tr>\n<td>org.quartz.scheduler.instanceId</td>\n<td>AUTO</td>\n<td></td>\n</tr>\n<tr>\n<td>org.quartz.scheduler.makeSchedulerThreadDaemon</td>\n<td>true</td>\n<td></td>\n</tr>\n<tr>\n<td>org.quartz.jobStore.useProperties</td>\n<td>false</td>\n<td></td>\n</tr>\n<tr>\n<td>org.quartz.threadPool.class</td>\n<td>org.quartz.simpl.SimpleThreadPool</td>\n<td></td>\n</tr>\n<tr>\n<td>org.quartz.threadPool.makeThreadsDaemons</td>\n<td>true</td>\n<td></td>\n</tr>\n<tr>\n<td>org.quartz.threadPool.threadCount</td>\n<td>25</td>\n<td></td>\n</tr>\n<tr>\n<td>org.quartz.threadPool.threadPriority</td>\n<td>5</td>\n<td></td>\n</tr>\n<tr>\n<td>org.quartz.jobStore.class</td>\n<td>org.quartz.impl.jdbcjobstore.JobStoreTX</td>\n<td></td>\n</tr>\n<tr>\n<td>org.quartz.jobStore.tablePrefix</td>\n<td>QRTZ_</td>\n<td></td>\n</tr>\n<tr>\n<td>org.quartz.jobStore.isClustered</td>\n<td>true</td>\n<td></td>\n</tr>\n<tr>\n<td>org.quartz.jobStore.misfireThreshold</td>\n<td>60000</td>\n<td></td>\n</tr>\n<tr>\n<td>org.quartz.jobStore.clusterCheckinInterval</td>\n<td>5000</td>\n<td></td>\n</tr>\n<tr>\n<td>org.quartz.jobStore.acquireTriggersWithinLock</td>\n<td>true</td>\n<td></td>\n</tr>\n<tr>\n<td>org.quartz.jobStore.dataSource</td>\n<td>myDs</td>\n<td></td>\n</tr>\n<tr>\n<td>org.quartz.dataSource.myDs.connectionProvider.class</td>\n<td>org.apache.dolphinscheduler.service.quartz.DruidConnectionProvider</td>\n<td></td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"10.install_config.conf-[ds-environment-variable-configuration-script-[for-ds-installation/startup]]\">10.install_config.conf [DS environment variable configuration script [for DS installation/startup]]</h2>\n<p>The install_config.conf configuration file is more cumbersome.This file is mainly used in two places.</p>\n<ul>\n<li>1.Automatic installation of DS cluster.</li>\n</ul>\n<blockquote>\n<p>Calling the install.sh script will automatically load the configuration in this file, and automatically configure the content in the above configuration file according to the content in this file.\nSuch as::dolphinscheduler-daemon.sh、datasource.properties、zookeeper.properties、common.properties、application-api.properties、master.properties、worker.properties、alert.properties、quartz.properties Etc..</p>\n</blockquote>\n<ul>\n<li>2.DS cluster startup and shutdown.</li>\n</ul>\n<blockquote>\n<p>When the DS cluster is started up and shut down, it will load the masters, workers, alertServer, apiServers and other parameters in the configuration file to start/close the DS cluster.</p>\n</blockquote>\n<p>The contents of the file are as follows:</p>\n<pre><code class=\"language-bash\">\n<span class=\"hljs-comment\"># Note: If the configuration file contains special characters,such as: `.*[]^${}\\+?|()@#&amp;`, Please escape,</span>\n<span class=\"hljs-comment\">#      Examples: `[` Escape to `\\[`</span>\n\n<span class=\"hljs-comment\"># Database type, currently only supports postgresql or mysql</span>\ndbtype=<span class=\"hljs-string\">&quot;mysql&quot;</span>\n\n<span class=\"hljs-comment\"># Database address &amp; port</span>\ndbhost=<span class=\"hljs-string\">&quot;192.168.xx.xx:3306&quot;</span>\n\n<span class=\"hljs-comment\"># Database Name</span>\ndbname=<span class=\"hljs-string\">&quot;dolphinscheduler&quot;</span>\n\n\n<span class=\"hljs-comment\"># Database Username</span>\nusername=<span class=\"hljs-string\">&quot;xx&quot;</span>\n\n<span class=\"hljs-comment\"># Database Password</span>\npassword=<span class=\"hljs-string\">&quot;xx&quot;</span>\n\n<span class=\"hljs-comment\"># Zookeeper address</span>\nzkQuorum=<span class=\"hljs-string\">&quot;192.168.xx.xx:2181,192.168.xx.xx:2181,192.168.xx.xx:2181&quot;</span>\n\n<span class=\"hljs-comment\"># Where to install DS, such as: /data1_1T/dolphinscheduler，</span>\ninstallPath=<span class=\"hljs-string\">&quot;/data1_1T/dolphinscheduler&quot;</span>\n\n<span class=\"hljs-comment\"># Which user to use for deployment</span>\n<span class=\"hljs-comment\"># Note: The deployment user needs sudo permissions and can operate hdfs.</span>\n<span class=\"hljs-comment\">#     If you use hdfs, the root directory must be created by the user. Otherwise, there will be permissions related issues.</span>\ndeployUser=<span class=\"hljs-string\">&quot;dolphinscheduler&quot;</span>\n\n\n<span class=\"hljs-comment\"># The following is the alarm service configuration</span>\n<span class=\"hljs-comment\"># Mail server address</span>\nmailServerHost=<span class=\"hljs-string\">&quot;smtp.exmail.qq.com&quot;</span>\n\n<span class=\"hljs-comment\"># Mail Server Port</span>\nmailServerPort=<span class=\"hljs-string\">&quot;25&quot;</span>\n\n<span class=\"hljs-comment\"># Sender</span>\nmailSender=<span class=\"hljs-string\">&quot;xxxxxxxxxx&quot;</span>\n\n<span class=\"hljs-comment\"># Sending user</span>\nmailUser=<span class=\"hljs-string\">&quot;xxxxxxxxxx&quot;</span>\n\n<span class=\"hljs-comment\"># email Password</span>\nmailPassword=<span class=\"hljs-string\">&quot;xxxxxxxxxx&quot;</span>\n\n<span class=\"hljs-comment\"># TLS protocol mailbox is set to true, otherwise set to false</span>\nstarttlsEnable=<span class=\"hljs-string\">&quot;true&quot;</span>\n\n<span class=\"hljs-comment\"># The mailbox with SSL protocol enabled is set to true, otherwise it is false. Note: starttlsEnable and sslEnable cannot be true at the same time</span>\nsslEnable=<span class=\"hljs-string\">&quot;false&quot;</span>\n\n<span class=\"hljs-comment\"># Mail service address value, same as mailServerHost</span>\nsslTrust=<span class=\"hljs-string\">&quot;smtp.exmail.qq.com&quot;</span>\n\n<span class=\"hljs-comment\">#Where to upload resource files such as sql used for business, you can set: HDFS, S3, NONE. If you want to upload to HDFS, please configure as HDFS; if you do not need the resource upload function, please select NONE.</span>\nresourceStorageType=<span class=\"hljs-string\">&quot;NONE&quot;</span>\n\n<span class=\"hljs-comment\"># if S3，write S3 address，HA，for example ：s3a://dolphinscheduler，</span>\n<span class=\"hljs-comment\"># Note，s3 be sure to create the root directory /dolphinscheduler</span>\ndefaultFS=<span class=\"hljs-string\">&quot;hdfs://mycluster:8020&quot;</span>\n\n<span class=\"hljs-comment\"># If the resourceStorageType is S3, the parameters to be configured are as follows:</span>\ns3Endpoint=<span class=\"hljs-string\">&quot;http://192.168.xx.xx:9010&quot;</span>\ns3AccessKey=<span class=\"hljs-string\">&quot;xxxxxxxxxx&quot;</span>\ns3SecretKey=<span class=\"hljs-string\">&quot;xxxxxxxxxx&quot;</span>\n\n<span class=\"hljs-comment\"># If the ResourceManager is HA, configure it as the primary and secondary ip or hostname of the ResourceManager node, such as &quot;192.168.xx.xx, 192.168.xx.xx&quot;, otherwise if it is a single ResourceManager or yarn is not used at all, please configure yarnHaIps=&quot;&quot; That’s it, if yarn is not used, configure it as &quot;&quot;</span>\nyarnHaIps=<span class=\"hljs-string\">&quot;192.168.xx.xx,192.168.xx.xx&quot;</span>\n\n<span class=\"hljs-comment\"># If it is a single ResourceManager, configure it as the ResourceManager node ip or host name, otherwise keep the default value.</span>\nsingleYarnIp=<span class=\"hljs-string\">&quot;yarnIp1&quot;</span>\n\n<span class=\"hljs-comment\"># The storage path of resource files in HDFS/S3</span>\nresourceUploadPath=<span class=\"hljs-string\">&quot;/dolphinscheduler&quot;</span>\n\n\n<span class=\"hljs-comment\"># HDFS/S3  Operating user</span>\nhdfsRootUser=<span class=\"hljs-string\">&quot;hdfs&quot;</span>\n\n<span class=\"hljs-comment\"># The following is the kerberos configuration</span>\n\n<span class=\"hljs-comment\"># Whether kerberos is turned on</span>\nkerberosStartUp=<span class=\"hljs-string\">&quot;false&quot;</span>\n<span class=\"hljs-comment\"># kdc krb5 config file path</span>\nkrb5ConfPath=<span class=\"hljs-string\">&quot;<span class=\"hljs-variable\">$installPath</span>/conf/krb5.conf&quot;</span>\n<span class=\"hljs-comment\"># keytab username</span>\nkeytabUserName=<span class=\"hljs-string\">&quot;hdfs-mycluster@ESZ.COM&quot;</span>\n<span class=\"hljs-comment\"># username keytab path</span>\nkeytabPath=<span class=\"hljs-string\">&quot;<span class=\"hljs-variable\">$installPath</span>/conf/hdfs.headless.keytab&quot;</span>\n\n\n<span class=\"hljs-comment\"># api service port</span>\napiServerPort=<span class=\"hljs-string\">&quot;12345&quot;</span>\n\n\n<span class=\"hljs-comment\"># Hostname of all hosts where DS is deployed</span>\nips=<span class=\"hljs-string\">&quot;ds1,ds2,ds3,ds4,ds5&quot;</span>\n\n<span class=\"hljs-comment\"># ssh port, default 22</span>\nsshPort=<span class=\"hljs-string\">&quot;22&quot;</span>\n\n<span class=\"hljs-comment\"># Deploy master service host</span>\nmasters=<span class=\"hljs-string\">&quot;ds1,ds2&quot;</span>\n\n<span class=\"hljs-comment\"># The host where the worker service is deployed</span>\n<span class=\"hljs-comment\"># Note: Each worker needs to set a worker group name, the default value is &quot;default&quot;</span>\nworkers=<span class=\"hljs-string\">&quot;ds1:default,ds2:default,ds3:default,ds4:default,ds5:default&quot;</span>\n\n<span class=\"hljs-comment\">#  Deploy the alert service host</span>\nalertServer=<span class=\"hljs-string\">&quot;ds3&quot;</span>\n\n<span class=\"hljs-comment\"># Deploy api service host</span>\napiServers=<span class=\"hljs-string\">&quot;ds1&quot;</span>\n</code></pre>\n<h2 id=\"11.dolphinscheduler_env.sh-[environment-variable-configuration]\">11.dolphinscheduler_env.sh [Environment variable configuration]</h2>\n<p>When submitting a task through a shell-like method, the environment variables in the configuration file are loaded into the host.\nThe types of tasks involved are: Shell tasks, Python tasks, Spark tasks, Flink tasks, Datax tasks, etc.</p>\n<pre><code class=\"language-bash\"><span class=\"hljs-built_in\">export</span> HADOOP_HOME=/opt/soft/hadoop\n<span class=\"hljs-built_in\">export</span> HADOOP_CONF_DIR=/opt/soft/hadoop/etc/hadoop\n<span class=\"hljs-built_in\">export</span> SPARK_HOME1=/opt/soft/spark1\n<span class=\"hljs-built_in\">export</span> SPARK_HOME2=/opt/soft/spark2\n<span class=\"hljs-built_in\">export</span> PYTHON_HOME=/opt/soft/python\n<span class=\"hljs-built_in\">export</span> JAVA_HOME=/opt/soft/java\n<span class=\"hljs-built_in\">export</span> HIVE_HOME=/opt/soft/hive\n<span class=\"hljs-built_in\">export</span> FLINK_HOME=/opt/soft/flink\n<span class=\"hljs-built_in\">export</span> DATAX_HOME=/opt/soft/datax/bin/datax.py\n\n<span class=\"hljs-built_in\">export</span> PATH=<span class=\"hljs-variable\">$HADOOP_HOME</span>/bin:<span class=\"hljs-variable\">$SPARK_HOME1</span>/bin:<span class=\"hljs-variable\">$SPARK_HOME2</span>/bin:<span class=\"hljs-variable\">$PYTHON_HOME</span>:<span class=\"hljs-variable\">$JAVA_HOME</span>/bin:<span class=\"hljs-variable\">$HIVE_HOME</span>/bin:<span class=\"hljs-variable\">$PATH</span>:<span class=\"hljs-variable\">$FLINK_HOME</span>/bin:<span class=\"hljs-variable\">$DATAX_HOME</span>:<span class=\"hljs-variable\">$PATH</span>\n\n</code></pre>\n<h2 id=\"12.service-log-configuration-files\">12.Service log configuration files</h2>\n<table>\n<thead>\n<tr>\n<th>Correspondence service</th>\n<th>Log file name</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>api service log configuration file</td>\n<td>logback-api.xml</td>\n</tr>\n<tr>\n<td>Master service log configuration file</td>\n<td>logback-master.xml</td>\n</tr>\n<tr>\n<td>Worker service log configuration file</td>\n<td>logback-worker.xml</td>\n</tr>\n<tr>\n<td>alert service log configuration file</td>\n<td>logback-alert.xml</td>\n</tr>\n</tbody>\n</table>\n",
  "location": [
    "Architecture Design",
    "Configuration File"
  ],
  "time": "2020-9-1",
  "structure": [
    {
      "title": "1.dolphinscheduler-daemon.sh [Activate/deactivate DS service script]",
      "children": [],
      "anchor": "1.dolphinscheduler-daemon.sh-[activate/deactivate-ds-service-script]"
    },
    {
      "title": "2.datasource.properties [Database Connectivity]",
      "children": [],
      "anchor": "2.datasource.properties-[database-connectivity]"
    },
    {
      "title": "3.zookeeper.properties [Zookeeper connection configuration]",
      "children": [],
      "anchor": "3.zookeeper.properties-[zookeeper-connection-configuration]"
    },
    {
      "title": "4.common.properties [hadoop, s3, yarn configuration]",
      "children": [],
      "anchor": "4.common.properties-[hadoop,-s3,-yarn-configuration]"
    },
    {
      "title": "5.application-api.properties [API service configuration]",
      "children": [],
      "anchor": "5.application-api.properties-[api-service-configuration]"
    },
    {
      "title": "6.master.properties [Master service configuration]",
      "children": [],
      "anchor": "6.master.properties-[master-service-configuration]"
    },
    {
      "title": "7.worker.properties [Worker service configuration]",
      "children": [],
      "anchor": "7.worker.properties-[worker-service-configuration]"
    },
    {
      "title": "8.alert.properties [Alert alert service configuration]",
      "children": [],
      "anchor": "8.alert.properties-[alert-alert-service-configuration]"
    },
    {
      "title": "9.quartz.properties [Quartz configuration]",
      "children": [],
      "anchor": "9.quartz.properties-[quartz-configuration]"
    },
    {
      "title": "10.install_config.conf [DS environment variable configuration script [for DS installation/startup]]",
      "children": [],
      "anchor": "10.install_config.conf-[ds-environment-variable-configuration-script-[for-ds-installation/startup]]"
    },
    {
      "title": "11.dolphinscheduler_env.sh [Environment variable configuration]",
      "children": [],
      "anchor": "11.dolphinscheduler_env.sh-[environment-variable-configuration]"
    },
    {
      "title": "12.Service log configuration files",
      "children": [],
      "anchor": "12.service-log-configuration-files"
    }
  ],
  "title": "Foreword",
  "link": "/configuration-file"
}