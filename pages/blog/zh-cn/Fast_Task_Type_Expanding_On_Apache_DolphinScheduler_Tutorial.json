{
  "__html": "<h1>极速开发扩充 Apache DolphinScheduler Task 类型 | 实用教程</h1>\n<div align=center>\n<img src=\"/img/2022-03-29/1.png\"/>\n</div>\n<h2>背景简介</h2>\n<p>目前在大数据生态中，调度系统是不可或缺的一个重要组件。Apache DolphinScheduler 作为一个顶级的 Apache 项目，其稳定性和易用性也可以说是名列前茅的。而对于一个调度系统来说，能够支持的可调度的任务类型同样是一个非常重要的因素，在调度、分布式、高可用、易用性解决了的情况下，随着业务的发展或者各种需求使用到的组件增多，用户自然而然会希望能够快速、方便、简洁地对 Apache Dolphinscheduler 可调度的任务类型进行扩充。本文便带大家了解如何方便、极速扩充一个 Apache DolphinScheduler Task。</p>\n<h2>作者简介</h2>\n<div align=center>\n<img src=\"/img/2022-03-29/2.jpeg\"/>\n</div>\n<p>张柏强，大数据开发工程师，主要研究方向为实时计算、元数据治理、大数据基础组件。</p>\n<h2><strong>1 什么是 SPI 服务发现(What is SPI)？</strong></h2>\n<p>SPI 全称为 (Service Provider Interface) ，是 JDK 内置的一种服务提供发现机制。大多数人可能会很少用到它，因为它的定位主要是面向开发厂商的，在 java.util.ServiceLoader 的文档里有比较详细的介绍，其抽象的概念是指动态加载某个服务实现。</p>\n<h2><strong>2 为什么要引入 SPI(Why did we introduce SPI)?</strong></h2>\n<p>不同的企业可能会有自己的组件需要通过 task 去执行，大数据生态中最为常用数仓工具 Apache Hive 来举例，不同的企业使用 Hive 方法各有不同。有的企业通过 HiveServer2 执行任务，有的企业使用 HiveClient 执行任务，而 Apache DolphinScheduler 提供的开箱即用的 Task 中并没有支持 HiveClient 的 Task，所以大部分使用者都会通过 Shell 去执行。然而，Shell 哪有天然的TaskTemplate 好用呢？所以，Apache DolphinScheduler 为了使用户能够更好地根据企业需求定制不同的 Task，便支持了 TaskSPI 化。</p>\n<p>我们首先要了解一下 Apache DolphinScheduler 的 Task 改版历程，在 DS 1.3.x 时，扩充一个 Task 需要重新编译整个 Apache DolphinScheduler，耦合严重，所以在 Apache DolphinScheduler 2.0.x 引入了 SPI。前面我们提到了 SPI 的抽象概念是动态加载某个服务的实现，这里我们具象一点，将 Apache DolphinScheduler 的 Task 看成一个执行服务，而我们需要根据使用者的选择去执行不同的服务，如果没有的服务，则需要我们自己扩充，相比于 1.3.x 我们只需要完成我们的 Task 具体实现逻辑，然后遵守 SPI 的规则，编译成 Jar 并上传到指定目录，即可使用我们自己编写的 Task。</p>\n<h2><strong>3 谁在使用它(Who is using it)?</strong></h2>\n<p>1、Apache DolphinScheduler</p>\n<ul>\n<li>\n<p>task</p>\n</li>\n<li>\n<p>datasource\n2、Apache Flink</p>\n</li>\n<li>\n<p>flink sql connector，用户实现了一个flink-connector后，Flink也是通过SPI来动态加载的\n3、Spring boot</p>\n</li>\n<li>\n<p>spring boot spi\n4、Jdbc</p>\n</li>\n<li>\n<p>jdbc4。0以前， 开发人员还需要基于Class。forName(&quot;xxx&quot;)的方式来装载驱动，jdbc4也基于spi的机制来发现驱动提供商了，可以通过META-INF/services/java。sql。Driver文件里指定实现类的方式来暴露驱动提供者\n5、更多</p>\n</li>\n<li>\n<p>dubbo</p>\n</li>\n<li>\n<p>common-logging</p>\n</li>\n</ul>\n<h2><strong>4 Apache DolphinScheduler SPI Process?</strong></h2>\n<div align=center>\n<img src=\"/img/2022-03-29/3.png\"/>\n</div>\n<p>剖析一下上面这张图，我给 Apache DolphinScheduler 分为逻辑 Task 以及物理 Task，逻辑 Task 指 DependTask，SwitchTask 这种逻辑上的 Task；物理 Task 是指 ShellTask，SQLTask 这种执行任务的 Task。而在 Apache DolphinScheduler中，我们一般扩充的都是物理 Task，而物理 Task 都是交由 Worker 去执行，所以我们要明白的是，当我们在有多台 Worker 的情况下，要将自定义的 Task 分发到每一台有 Worker 的机器上，当我们启动 Worker 服务时，worker 会去启动一个 ClassLoader 来加载相应的实现了规则的 Task lib，可以看到 HiveClient 和 SeatunnelTask 都是用户自定义的，但是只有 HiveTask 被 Apache DolphinScheduler TaskPluginManage 加载了，原因是 SeatunnelTask 并没有去遵守 SPI 的规则。SPI 的规则图上也有赘述，也可以参考 java.util.ServiceLoader 这个类，下面有一个简单的参考(摘出的一部分代码，具体可以自己去看看）</p>\n<pre><code class=\"language-plain\">public final class ServiceLoader&lt;S&gt; implements Iterable&lt;S&gt; {\n    //scanning dir prefix\n    private static final String PREFIX = &quot;META-INF/services/&quot;;\n\n    //The class or interface representing the service being loaded\n    private final Class&lt;S&gt; service;\n\n    //The class loader used to locate, load, and instantiate providers\n    private final ClassLoader loader;\n\n    //Private inner class implementing fully-lazy provider lookup\n    private class LazyIterator implements Iterator&lt;S&gt; {\n        Class&lt;S&gt; service;\n        ClassLoader loader;\n        Enumeration&lt;URL&gt; configs = null;\n        String nextName = null;\n\n        //......\n        private boolean hasNextService() {\n            if (configs == null) {\n                try {\n                    //get dir all class\n                    String fullName = PREFIX + service.getName();\n                    if (loader == null)\n                        configs = ClassLoader.getSystemResources(fullName);\n                    else\n                        configs = loader.getResources(fullName);\n                } catch (IOException x) {\n                    //......\n                }\n                //......\n            }\n        }\n    }\n}\n\n</code></pre>\n<h2><strong>5 如何扩展一个 data sourceTask or DataSource (How to extend a task or datasource)?</strong></h2>\n<h3><strong>5.1 创建 Maven 项目</strong></h3>\n<pre><code class=\"language-plain\">\nmvn archetype:generate \\\n    -DarchetypeGroupId=org.apache.dolphinscheduler \\\n    -DarchetypeArtifactId=dolphinscheduler-hive-client-task \\\n    -DarchetypeVersion=1.10.0 \\\n    -DgroupId=org.apache.dolphinscheduler \\\n    -DartifactId=dolphinscheduler-hive-client-task \\\n    -Dversion=0.1 \\\n    -Dpackage=org.apache.dolphinscheduler \\\n    -DinteractiveMode=false \n    \n    \n</code></pre>\n<h3><strong>5.2 Maven 依赖</strong></h3>\n<pre><code class=\"language-plain\">\n &lt;!--dolphinscheduler spi basic core denpendence--&gt;\n &lt;dependency&gt;\n     &lt;groupId&gt;org.apache.dolphinscheduler&lt;/groupId&gt;\n     &lt;artifactId&gt;dolphinscheduler-spi&lt;/artifactId&gt;\n     &lt;version&gt;${dolphinscheduler.lib.version}&lt;/version&gt;\n     &lt;scope&gt;${common.lib.scope}&lt;/scope&gt;\n &lt;/dependency&gt;\n &lt;dependency&gt;\n     &lt;groupId&gt;org.apache.dolphinscheduler&lt;/groupId&gt;\n     &lt;artifactId&gt;dolphinscheduler-task-api&lt;/artifactId&gt;\n     &lt;version&gt;${dolphinscheduler.lib.version}&lt;/version&gt;\n     &lt;scope&gt;${common.lib.scope}&lt;/scope&gt;\n &lt;/dependency&gt;\n    \n    \n</code></pre>\n<h3><strong>5.3 创建 Task 通道工厂(TaskChannelFactory)</strong></h3>\n<p>首先我们需要创建任务服务的工厂，其主要作用是帮助构建 TaskChannel 以及 TaskPlugin 参数，同时给出该任务的唯一标识，ChannelFactory 在 Apache DolphinScheduler 的 Task 服务组中，其作用属于是在任务组中的承上启下，交互前后端以及帮助 Worker 构建 TaskChannel。</p>\n<pre><code class=\"language-plain\">package org.apache.dolphinscheduler.plugin.task.hive;\n\nimport org.apache.dolphinscheduler.spi.params.base.PluginParams;\nimport org.apache.dolphinscheduler.spi.task.TaskChannel;\nimport org.apache.dolphinscheduler.spi.task.TaskChannelFactory;\n\nimport java.util.List;\n\npublic class HiveClientTaskChannelFactory implements TaskChannelFactory {\n    /**\n     *  创建任务通道,基于该通道执行任务\n     * @return 任务通道\n     */\n    @Override\n    public TaskChannel create() {\n        return new HiveClientTaskChannel();\n    }\n\n    /**\n     *  返回当前任务的全局唯一标识\n     * @return 任务类型名称\n     */\n    @Override\n    public String getName() {\n        return &quot;HIVE CLIENT&quot;;\n    }\n\n    /**\n     * 前端页面需要用到的渲染,主要分为\n     \n     * @return\n     */\n    @Override\n    public List&lt;PluginParams&gt; getParams() {\n        List&lt;PluginParams&gt; pluginParams = new ArrayList&lt;&gt;();\n        InputParam nodeName = InputParam.newBuilder(&quot;name&quot;, &quot;$t('Node name')&quot;)\n                .addValidate(Validate.newBuilder()\n                        .setRequired(true)\n                        .build())\n                .build();\n        PluginParams runFlag = RadioParam.newBuilder(&quot;runFlag&quot;, &quot;RUN_FLAG&quot;)\n                .addParamsOptions(new ParamsOptions(&quot;NORMAL&quot;, &quot;NORMAL&quot;, false))\n                .addParamsOptions(new ParamsOptions(&quot;FORBIDDEN&quot;, &quot;FORBIDDEN&quot;, false))\n                .build();\n\n        PluginParams build = CheckboxParam.newBuilder(&quot;Hive SQL&quot;, &quot;Test HiveSQL&quot;)\n                .setDisplay(true)\n                .setValue(&quot;-- author: \\n --desc:&quot;)\n                .build();\n\n        pluginParams.add(nodeName);\n        pluginParams.add(runFlag);\n        pluginParams.add(build);\n\n        return pluginParams;\n    }\n}\n</code></pre>\n<h3><strong>5.4 创建 TaskChannel</strong></h3>\n<p>有了工厂之后，我们会根据工厂创建出 TaskChannel，TaskChannel 包含如下两个方法，一个是取消，一个是创建，目前不需要关注取消，主要关注创建任务。</p>\n<pre><code class=\"language-plain\">    void cancelApplication(boolean status);\n\n    /**\n     * 构建可执行任务\n     */\n    AbstractTask createTask(TaskRequest taskRequest);\n    public class HiveClientTaskChannel implements TaskChannel {\n    @Override\n    public void cancelApplication(boolean b) {\n        //do nothing\n    }\n\n    @Override\n    public AbstractTask createTask(TaskRequest taskRequest) {\n        return new HiveClientTask(taskRequest);\n    }\n}\n\n</code></pre>\n<h3><strong>5.5 构建 Task 实现</strong></h3>\n<p>通过 TaskChannel 我们得到了可执行的物理 Task，但是我们需要给当前 Task 添加相应的实现，才能够让Apache DolphinScheduler 去执行你的任务，首先在编写 Task 之前我们需要先了解一下 Task 之间的关系：</p>\n<div align=center>\n<img src=\"/img/2022-03-29/4.png\"/>\n</div>\n<p>通过上图我们可以看到，基于 Yarn 执行任务的 Task 都会去继承 AbstractYarnTask，不需要经过 Yarn 执行的都会去直接继承 AbstractTaskExecutor，主要是包含一个 AppID，以及 CanalApplication setMainJar 之类的方法，想知道的小伙伴可以自己去深入研究一下，如上可知我们实现的 HiveClient 就需要继承 AbstractYarnTask，在构建 Task 之前，我们需要构建一下适配 HiveClient 的 Parameters 对象用来反序列化JsonParam。</p>\n<pre><code class=\"language-plain\">  package com.jegger.dolphinscheduler.plugin.task.hive;\n\nimport org.apache.dolphinscheduler.spi.task.AbstractParameters;\nimport org.apache.dolphinscheduler.spi.task.ResourceInfo;\n\nimport java.util.List;\n\npublic class HiveClientParameters extends AbstractParameters {\n    /**\n     * 用HiveClient执行,最简单的方式就是将所有SQL全部贴进去即可,所以我们只需要一个SQL参数\n     */\n    private String sql;\n\n    public String getSql() {\n        return sql;\n    }\n\n    public void setSql(String sql) {\n        this.sql = sql;\n    }\n\n    @Override\n    public boolean checkParameters() {\n        return sql != null;\n    }\n\n    @Override\n    public List&lt;ResourceInfo&gt; getResourceFilesList() {\n        return null;\n    }\n}\n\n</code></pre>\n<p>实现了 Parameters 对象之后，我们具体实现 Task，例子中的实现比较简单，就是将用户的参数写入到文件中，通过 Hive -f 去执行任务。</p>\n<pre><code class=\"language-plain\"> package org.apache.dolphinscheduler.plugin.task.hive;\n\nimport org.apache.dolphinscheduler.plugin.task.api.AbstractYarnTask;\nimport org.apache.dolphinscheduler.spi.task.AbstractParameters;\nimport org.apache.dolphinscheduler.spi.task.request.TaskRequest;\nimport org.apache.dolphinscheduler.spi.utils.JSONUtils;\n\nimport java.io.BufferedWriter;\nimport java.io.IOException;\nimport java.nio.charset.StandardCharsets;\nimport java.nio.file.Files;\nimport java.nio.file.Path;\nimport java.nio.file.Paths;\n\n\n\npublic class HiveClientTask extends AbstractYarnTask {\n\n    /**\n     * hive client parameters\n     */\n    private HiveClientParameters hiveClientParameters;\n\n    /**\n     * taskExecutionContext\n     */\n    private final TaskRequest taskExecutionContext;\n\n\n\n    public HiveClientTask(TaskRequest taskRequest) {\n        super(taskRequest);\n        this.taskExecutionContext = taskRequest;\n    }\n\n    /**\n     * task init method\n     */\n    @Override\n    public void init() {\n        logger.info(&quot;hive client task param is {}&quot;, JSONUtils.toJsonString(taskExecutionContext));\n        this.hiveClientParameters = JSONUtils.parseObject(taskExecutionContext.getTaskParams(), HiveClientParameters.class);\n\n        if (this.hiveClientParameters != null &amp;&amp; !hiveClientParameters.checkParameters()) {\n            throw new RuntimeException(&quot;hive client task params is not valid&quot;);\n        }\n    }\n\n    /**\n     * build task execution command\n     *\n     * @return task execution command or null\n     */\n    @Override\n    protected String buildCommand() {\n        String filePath = getFilePath();\n        if (writeExecutionContentToFile(filePath)) {\n            return &quot;hive -f &quot; + filePath;\n        }\n        return null;\n    }\n\n    /**\n     * get hive sql write path\n     *\n     * @return file write path\n     */\n    private String getFilePath() {\n        return String.format(&quot;%s/hive-%s-%s.sql&quot;, this.taskExecutionContext.getExecutePath(), this.taskExecutionContext.getTaskName(), this.taskExecutionContext.getTaskInstanceId());\n    }\n\n    @Override\n    protected void setMainJarName() {\n        //do nothing\n    }\n\n    /**\n     * write hive sql to filepath\n     *\n     * @param filePath file path\n     * @return write success?\n     */\n    private boolean writeExecutionContentToFile(String filePath) {\n        Path path = Paths.get(filePath);\n        try (BufferedWriter writer = Files.newBufferedWriter(path, StandardCharsets.UTF_8)) {\n            writer.write(this.hiveClientParameters.getSql());\n            logger.info(&quot;file:&quot; + filePath + &quot;write success.&quot;);\n            return true;\n        } catch (IOException e) {\n            logger.error(&quot;file:&quot; + filePath + &quot;write failed.please path auth.&quot;);\n            e.printStackTrace();\n            return false;\n        }\n\n    }\n\n    @Override\n    public AbstractParameters getParameters() {\n        return this.hiveClientParameters;\n    }\n}\n\n</code></pre>\n<h4><strong>5.6 遵守 SPI 规则</strong></h4>\n<pre><code class=\"language-plain\"> # 1,Resource下创建META-INF/services文件夹,创建接口全类名相同的文件\nzhang@xiaozhang resources % tree ./\n./\n└── META-INF\n    └── services\n        └── org.apache.dolphinscheduler.spi.task.TaskChannelFactory\n# 2,在文件中写入实现类的全限定类名\nzhang@xiaozhang resources % more META-INF/services/org.apache.dolphinscheduler.spi.task.TaskChannelFactory \norg.apache.dolphinscheduler.plugin.task.hive.HiveClientTaskChannelFactory\n\n</code></pre>\n<h4><strong>5.7 打包和部署</strong></h4>\n<pre><code class=\"language-plain\">## 1,打包\nmvn clean install\n## 2,部署\ncp ./target/dolphinscheduler-task-hiveclient-1.0.jar $DOLPHINSCHEDULER_HOME/lib/\n## 3,restart dolphinscheduler server\n\n</code></pre>\n<p>以上操作完成后，我们查看 worker 日志 tail -200f $Apache DolphinScheduler_HOME/log/Apache DolphinScheduler-worker.log</p>\n<div align=center>\n<img src=\"/img/2022-03-29/5.png\"/>\n</div>\n<p>Apache DolphinScheduler 的插件开发就到此完成~涉及到前端的修改可以参考：</p>\n<p>Apache DolphinScheduler-ui/src/js/conf/home/pages/dag/_source/formModel/</p>\n",
  "time": "2022-4-14",
  "author": "Debra Chen",
  "title": "极速开发扩充 Apache DolphinScheduler Task 类型 | 实用教程",
  "type": "tutorial",
  "label": "教程"
}