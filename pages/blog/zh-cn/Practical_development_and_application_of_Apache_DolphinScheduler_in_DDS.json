{
  "__html": "<p><img src=\"/img/2023-9-6/1.png\" alt=\"\"></p>\n<p>​</p>\n<p>这次在 7月 Meetup 为大家带来的是基于DolphinScheduler的智能调度引擎在DDS的应用，这场演讲主要会跟大家介绍宇动源-DDS（自研的图形化数据开发工作室）、大数据架构、DDS产品和使用中遇到的问题，包括在迁移过程中的调研情况、遇到的困难、解决方案以及针对需求的优化，还有一些心得体会，希望你有所收获。</p>\n<p>​</p>\n<p><strong>王子健</strong></p>\n<p>宇动源大数据平台开发工程师</p>\n<p>原搜狐畅游数据仓库开发工程师</p>\n<p><strong>本次演讲主要包含四个部分：</strong></p>\n<ul>\n<li>\n<p>关于宇动源-DDS</p>\n</li>\n<li>\n<p>全新调度引擎的迁移-DS</p>\n</li>\n<li>\n<p>引擎功能优化</p>\n</li>\n<li>\n<p>总结与计划</p>\n</li>\n</ul>\n<h1><strong>关于宇动源-DDS</strong></h1>\n<p><img src=\"/img/2023-9-6/2.png\" alt=\"\"></p>\n<p>😀​宇动源DDS架构图</p>\n<h2>01 <strong>什么是BDP？</strong></h2>\n<p>BDP是宇动源自研的大数据基础平台，类似的商业的应用主要有<strong>fusioninsget</strong> 和 <strong>EMR</strong>，都是在工业互联网领域比较领先的大数据平台，他们也都对现有开源大数据底层组件的封装和统一管理，使其更适用于工业领域的<strong>实时数据、时序数据、生产监控数据</strong>等，为DDS上层应用提供一个使用更方便、更容易使用的基础平台。</p>\n<p><strong>主要提供的功能</strong>：统一计算调度及管理、计算节点管理、存储节点管理、数据统一访问接口、统一权限控制、全局智能运维</p>\n<p>有了BDP之后，我们不需要手动的安装/维护这些组件，包括我们DDS所有的组件也都是通过BDP进行安装和维护。</p>\n<h2>02 <strong>关于DDS</strong></h2>\n<p>DDS实际上是对底层的调度引擎的优化，主要是使用的<strong>workflow code 和Stream code</strong> 的两种开发方式，利用拖拉拽快速完成大数据开发。</p>\n<p>除此之外还支持<strong>Notebook 交互式</strong>开发方式，当我们使用Shell SQL节点的时候可以在线编辑。</p>\n<p>最终在执行过程，其实和我们平时使用DolphinScheduler一样，在运行后，也会生成一个调度任务，并且可以在调度管理中查看/管理。</p>\n<h2>03 <strong>缺点与不足</strong></h2>\n<p><strong>案例一：某能源集团火力发电远程告警系统</strong></p>\n<p>问题：基于上一代调度引擎在性能、权限控制等方面存在缺陷，导致出现告警延迟、无法精准控制权限等问题。</p>\n<p><strong>案例二：某石油加工集团云边端设备采集项目</strong></p>\n<p>问题：DDS与Hadoop架构紧密耦合，不仅前期需要额外部署Hadoop集群（即使客户不使用），后期Hadoop集群维护也增加了运维成本。</p>\n<p><strong>案例三：某军部数字化建设项目</strong></p>\n<p>问题：无法对整个集群的运行状态进行统计，比如1000个任务，在运行过程中，我们不知道哪些任务是正常运行的，哪些任务挂掉了；</p>\n<p>DDS中老调度引擎无法获取日志（日志的粒度依赖oozie 的日志）从而增加了<strong>调试维护成本</strong>，在开发过程中，命令行的方式也不是很友好，XML配置文件容易出错，开发效率低，无法更全面的统计与维护。</p>\n<p>综上所诉的这些缺点和问题，导致了我们需要迭代一个新的版本，<strong>在DDS的后续版本准备对调度引擎进行替换</strong>，来解决这些使用当中的痛点。</p>\n<h1><strong>全新调度引擎的迁移</strong></h1>\n<h2>01<strong>调研阶段</strong></h2>\n<p>接下来跟大家分享的就是在迁移过程当中，我们的一些调研工作、遇到的问题以及解决方案。</p>\n<p>我们调研了oozie，azkaban，Airflow， 还有DolphinScherduler，当然还有一些其他的调度，这个表格里就没整理，在整个调研的阶段，我们特别重视的指标主要是资源的监控和分布式和日志，还有权限等方面的控制。</p>\n<p><img src=\"/img/2023-9-6/3.png\" alt=\"\"></p>\n<p>​</p>\n<h2><strong>为什么选择DolphinScheduler ？</strong></h2>\n<p><strong>资源方面</strong>，DolphinsScheduler 可以有自己的数据中心，可以对master worker运行状态和指标实时监控；</p>\n<p><strong>分布式方面</strong>，支持HA，是去中心化的，支持多Master多worker；</p>\n<p>**日志方面，**通过DolphinsScheduler我们能准确的定位到每一个task任务执行的日志。也可以监控在执行过程当中启动时间，停止时间，然后运行的机器所在的运行阶段；</p>\n<p><strong>容错机制</strong>也很有特色；</p>\n<p><strong>支持多租户</strong>。DolphinsScheduler的租户能和Hadoop的用户能实现映射关系，实现对资源的精确管理；</p>\n<p><img src=\"/img/2023-9-6/4.png\" alt=\"\"></p>\n<p>​</p>\n<h2>02 <strong>引擎接入方案(dds-adaptor)</strong></h2>\n<h3><strong>接入方案-典型问题</strong></h3>\n<p>在迁移的过程当中，<strong>我们遇到了一个典型的问题</strong>：DolphinScheduler中的描述文件（json）无法与DDS的工作流描述文件（xml）兼容。就是DDS中的工作流是用xml的格式来绘制描述的。而DolphinScheduler中是使用json格式来描述的，<strong>这样就会导致于现有的前端生成的XML，无法兼容DolphinScheduler。</strong></p>\n<h3><strong>问题解决方案</strong></h3>\n<p>我们在DDS和DolphinScheduler中间，加入了DDS-adaptor服务，它有一个自己的API，DDS前端绘制完工作流，会将XML格式的请求体，通过API接口的形式发送到parser-engine，parser-engine收到了带有XML参数的请求后，会将它解析成JSON格式 ，当然这个JSON就是我们DS引擎能解析和兼容的。这样就解决了保留DDS前端框架不变的情况下，将原有的XML描述方式，适配到DolphinScheduler的json方式。</p>\n<p><strong>这样也就实现了我们在DDS前端创建task 任务，在DS的后端会生成DolphinScheduler task 规则的任务。</strong></p>\n<p>也就是说可能有个客户DDS使用了几年。上面配了几千个任务，用这个架构接入方案它就不需要重新的做任务的迁移，可以无缝的实现底层调度引擎的迁移。</p>\n<h2>03 <strong>实现简介</strong></h2>\n<h3><strong>DDS_adaptor架构</strong></h3>\n<p>DDS_adaptor项目里边包含两个子项目，一个<strong>dsengine-core和external-model</strong>，那么前面说的API是在controller层里，当我们接收到xml的请求，会通过engine-core去对它进行解析。</p>\n<h3><strong>具体的实现</strong></h3>\n<p><img src=\"/img/2023-9-6/5.png\" alt=\"\"></p>\n<p>​</p>\n<p><strong>实现流程：</strong></p>\n<p>1.前端先发送XML文件到HTTP接口</p>\n<p>2.HTTP接到之后会创建一个解析工厂也就是SchedulerParserFactory</p>\n<p>3.解析工厂生成一个IParser接口</p>\n<p>4.然后实现Dds2DolphinModelParser，也就是模型解析实现类</p>\n<p>5.其中parser方法实际上是XML格式的字符串，里面调用的是核心方法、核心类</p>\n<p>6.DdsDolphinModelAdaptor，即模型适配器。在接收parser传进来的参数后会有两个方法，<a href=\"http://xn--from-pg9fth21n4t8b.to\">分别是from和.to</a>，from是将DDS的Graph转换成中间对象的Graph。.to是将中间对象的Graph转换成Dolphin的Graph。</p>\n<p>7.创建SystemConvertDepartmentFactory，它同时会创建DDS转换成Dolphin特有的转换方法，分别有3个：</p>\n<p><strong>方法一：</strong></p>\n<p>INodeConvertercreateNodeConverter（nodeType）：<strong>创建节点转换器</strong></p>\n<p><strong>方法二：</strong></p>\n<p>AdaptorNodeTypeconvertNodeType2Adaptor(nodeType) ：<strong>目标节点转为中间节点</strong></p>\n<p><strong>方法三：</strong></p>\n<p>StringconvertAaptor2NodeType(AdaptorNodeType)：<strong>中间节点转为目标节点</strong></p>\n<p>在第一步中需要将DDS Graph 转为 Adaptor Graph ，这个实际上执行的时是AdaptorNodeType convertNodeType2Adaptor(nodeType) 方法，将Graph做转换，</p>\n<p>但是每个Graph 中包含很多组件，因此每个组件都需要进行转换，需要调用到的方法是</p>\n<p>convertAdpator2Node(AdaptorNode , OutputNode)</p>\n<p>convertNode2Adaptor(AdaptorNodeBuilder,InputNode)，针对每个组件进行转换，实现了将DDS Graph 转为 Adaptor Graph。</p>\n<p><strong>第二步是中间对象转换成目标对象</strong>，我们想要的是Dolphin的Graph，这个时候实际上就是将中间组件转换成目标组件，这样就实现了中间的Graph转换成目标Graph，中间的Graph就是Adaptor-Garph，目标组件就是Dolphin-Graph，这样就实现了前端以XML的方式发送，引擎解析出来是Dolphin支持的json格式</p>\n<h1><strong>引擎功能优化（更智能）</strong></h1>\n<p>主要介绍扩展的两个功能，第一个是节点推荐机制，第二个是重跑控制策略。</p>\n<h2><strong>节点推荐机制</strong></h2>\n<p><img src=\"/img/2023-9-6/6.png\" alt=\"\"></p>\n<p>​</p>\n<p>在DDS调度启动之前，可以进行一个调度策略的设置，分别有一个分配策略和推荐节点；</p>\n<p>在分配策略的时候，我们可以根据实际情况来选择，比如你是采集任务还是计算任务？是让它网络优先，还是IO优先，在这里你可以根据不同的情况自定义选择。</p>\n<h2><strong>时间架构</strong></h2>\n<p><img src=\"/img/2023-9-6/7.png\" alt=\"\"></p>\n<p>​</p>\n<p>这里没有展示时间关系代码，主要依赖是基于DDS-monitor。在每一个子节点上部署 agent，那么agent它会采集系统的各种信息，比如说我们的系统版本，CPU，内存，磁盘等。</p>\n<p>agent会将这些信息上报给server端，sever端将这些指标全部存在时序数据库里，数据库主要有两个用途，一个是我们监控数据，我们可以监控每一个agent上面的信息，另一个就是分析计算，指标分析计算后，根据我们的策略规则，会将符合功能策略的节点推荐返回给server，从而实现了节点的推荐机制。</p>\n<h2><strong>分析指标</strong></h2>\n<p>我们指标分析计算里面涉及到的一些指标，有系统版本、CPU、内存、磁盘、进程、端口、网络io等等</p>\n<p><img src=\"/img/2023-9-6/8.png\" alt=\"\"></p>\n<p>​</p>\n<p>那么配置规则里有IO相关的配置，有符合我们特定业务类型的配置。</p>\n<p><img src=\"/img/2023-9-6/9.png\" alt=\"\"></p>\n<p>​</p>\n<h2><strong>重跑控制策略</strong></h2>\n<p>我们对调度的是否重跑可以进行控制。比如说当任务运行到一半的时候，节点重启，所有的任务都失败了，有一些任务可以直接进行重跑覆盖，但是有一些任务重跑会影响它的结果，所以对这些重跑的限制也是针对需求来进行优化的点。</p>\n<h1><strong>总结与计划</strong></h1>\n<p>一方面，不管是基于DolphinScheduler引擎去开发自己的调度系统，还是直接使用DolphinScheduler进行二次开发，都是需要根据自己的开发环境来实际操作，<strong>比如说公司的环境要求、规范、前后端技术栈、开发环境等等</strong>，不要拿过来就开发，需要多方面的考虑。</p>\n<p>另一方面，我们在devops过程当中需要收集和整理产生的这些缺陷、缺点和一些用户的痛点, 我们需要在这个版本的迭代当中，有针对性的去处理这些问题。</p>\n<p>我们后续也有很多功能在实现当中，给大家列举一下，比如说后续的<strong>Task组件节点之间结果集的传递、SQL 运行后传递给后续节点等</strong>，然后还需要集成一些热门的时序数据库，比如说influxdb、open plant等。</p>\n<p>等实现之后希望还有机会和大家一起交流分享，谢谢大家。</p>\n",
  "time": "2023-9-6",
  "author": "Niko Zeng",
  "title": "小海豚“变身”全新智能调度引擎，深入浅出在DDS的实践开发应用？",
  "type": "user",
  "label": "用户案例"
}